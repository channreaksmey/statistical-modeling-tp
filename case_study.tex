% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  10pt,
]{article}
\usepackage{xcolor}
\usepackage[top=1.8cm,bottom=1.8cm,left=1.8cm,right=1.8cm]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{setspace}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{setspace}
\usepackage{titlesec}
\setlength{\textfloatsep}{8pt}
\setlength{\floatsep}{6pt}
\setlength{\intextsep}{6pt}
\titlespacing*{\section}{0pt}{1.5ex}{0.8ex}
\titlespacing*{\subsection}{0pt}{1.2ex}{0.6ex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Case Study - STM},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Case Study - STM}
\author{}
\date{}
\begin{document}
\maketitle


\setstretch{1.1}
\section{Case Study 1: Biomass}\label{case-study-1-biomass}

\emph{Data and ideas for this case study come from (Goicoa et al.,
2011).}

To estimate the amount of carbon dioxide retained in a tree, its biomass
needs to be known and multiplied by an expansion factor (there are
several alternatives in the literature). To calculate the biomass,
specific regression equations by species are frequently used. These
regression equations, called allometric equations, estimate the biomass
of the tree by means of some known characteristics, typically diameter
and/or height of the stem and branches. The BIOMASS file contains data
of 42 beeches (Fagus Sylvatica) from a forest of Navarra (Spain) in
2006, where

• \texttt{diameter}: diameter of the stem in centimeters

• \texttt{height}: height of the tree in meters

• \texttt{stemweight}: weight of the stem in kilograms

• \texttt{aboveweight}: aboveground weight in kilograms

\begin{verbatim}
  diameter height stemweight aboveweight
1       40   18.5     647.36     1047.97
2       32   18.8     396.51      559.89
3       22   13.2     131.78      221.06
4       45   20.5     810.36     1279.54
5       37   17.5     510.37      682.30
6       37   19.8     456.04      645.61
\end{verbatim}

\paragraph{(a) Create a scatterplot of aboveweight versus diameter. Is
the relationship linear? Superimpose a regression line over the plot
just
created.}\label{a-create-a-scatterplot-of-aboveweight-versus-diameter.-is-the-relationship-linear-superimpose-a-regression-line-over-the-plot-just-created.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-2-1.pdf}}

\textbf{No, the relationship is NOT linear.}

\textbf{Observations:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Curved Pattern}: The scatterplot shows a clear
  \textbf{curvilinear (non-linear) relationship} between diameter and
  aboveground weight. The data points follow a curved pattern rather
  than a straight line.
\item
  \textbf{Accelerating Growth}: The relationship appears to be
  \textbf{exponential or power-law} in nature. As diameter increases,
  the aboveground weight increases at an accelerating rate (the curve
  becomes steeper).
\item
  \textbf{Poor Linear Fit}: While the red regression line has been
  superimposed on the plot, you can see that:

  \begin{itemize}
  \item
    At small diameters (left side), the line overestimates the weight
  \item
    In the middle range, the fit is reasonable
  \item
    At large diameters (right side), the line underestimates the weight
  \item
    This systematic pattern of residuals (points above and below the
    line in a curved pattern) indicates that a linear model is
    \textbf{not appropriate} for this data.
  \end{itemize}
\item
  \textbf{Biological Interpretation}: This makes biological sense
  because tree biomass is related to volume, which grows as a function
  of diameter raised to a power (typically around 2-3), not linearly.
\end{enumerate}

\paragraph{\texorpdfstring{(b) Create a scatterplot of
\(\log(aboveweight)\) versus \(\log(diameter)\). Is the relationship
linear? Superimpose a regression line over the plot just
created.}{(b) Create a scatterplot of \textbackslash log(aboveweight) versus \textbackslash log(diameter). Is the relationship linear? Superimpose a regression line over the plot just created.}}\label{b-create-a-scatterplot-of-logaboveweight-versus-logdiameter.-is-the-relationship-linear-superimpose-a-regression-line-over-the-plot-just-created.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-3-1.pdf}}

\textbf{Yes, the relationship is linear.}

\textbf{Observations:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Strong Linear Pattern}: After the log transformation, the data
  points now follow a clear \textbf{straight-line pattern}. The points
  are distributed closely around the red regression line with no
  systematic curvature.
\item
  \textbf{Excellent Linear Fit}: The regression line fits the data much
  better than in part (a):

  \begin{itemize}
  \item
    Points are randomly scattered above and below the line
  \item
    No systematic pattern of over/under-estimation across the range
  \item
    The residuals appear to have constant variance (homoscedastic)
  \item
    Very tight clustering around the line suggests high R²
  \end{itemize}
\item
  \textbf{Success of Log Transformation}: The log-log transformation has
  successfully \textbf{linearized} the power-law relationship that was
  evident in part (a). This transformation is standard for allometric
  equations.
\item
  \textbf{Mathematical Interpretation}: The linear relationship in
  log-log space indicates that the original relationship follows a power
  law: \(\log(aboveweight) = β_0 + β_1 \log(diameter)\) Which
  corresponds to the power relationship:
  \(aboveweight = \exp(β_0) × diameter^{β_1}\)
\item
  \textbf{Allometric Equation}: This is exactly the form expected for
  allometric equations in biology, where biomass scales as a power
  function of dimensional measurements like diameter.
\end{enumerate}

\paragraph{\texorpdfstring{(c) Fit the regression model
\(\log(aboveweight) = β_0 + β_1\log(diameter)\), and compute
\(R^2, R^2_a\) and the variance of the
residuals.}{(c) Fit the regression model \textbackslash log(aboveweight) = β\_0 + β\_1\textbackslash log(diameter), and compute R\^{}2, R\^{}2\_a and the variance of the residuals.}}\label{c-fit-the-regression-model-logaboveweight-ux3b2_0-ux3b2_1logdiameter-and-compute-r2-r2_a-and-the-variance-of-the-residuals.}

\begin{verbatim}

Model Summary:
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = log(aboveweight) ~ log(diameter), data = BIOMASS)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.48510 -0.12682  0.02701  0.10766  0.32104 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)    -1.5015     0.1920  -7.822 1.38e-09 ***
log(diameter)   2.2806     0.0542  42.076  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1842 on 40 degrees of freedom
Multiple R-squared:  0.9779,    Adjusted R-squared:  0.9774 
F-statistic:  1770 on 1 and 40 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{verbatim}

--- Model Statistics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.9779
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.9774
\end{verbatim}

\begin{verbatim}
Residual variance (σ²): 0.0339
\end{verbatim}

\textbf{Model Statistics:}

\textbf{1. R-squared (R²) = 0.9779}

\textbf{Interpretation:} The model explains \textbf{97.79\% of the
variance} in log(aboveground weight). This indicates an excellent fit -
nearly all the variation in log-transformed biomass can be explained by
log-transformed diameter alone.

\textbf{2. Adjusted R-squared (R²ₐ) = 0.9774}

\textbf{Interpretation:} After adjusting for the number of predictors (1
predictor), the model still explains \textbf{97.74\%} of the variance.
The minimal difference between R² and R²ₐ (0.0005) indicates that the
model is not overfitted and the predictor is genuinely useful.

\textbf{3. Residual Variance (σ²) = 0.0339}

\textbf{Interpretation:} The variance of the residuals around the
regression line is \textbf{0.0339} (in log units). The residual standard
error is σ = √0.0339 = \textbf{0.1842}, which represents the typical
prediction error on the log scale.

\paragraph{\texorpdfstring{(d) Introduce \(log(height)\) as an
explanatory variable and fit the
model\(\log(aboveweight) =β_0 + β_1 \log(diameter) + β_2 \log(height)\).
What is the effect of introducing log(height)in the
model?}{(d) Introduce log(height) as an explanatory variable and fit the model\textbackslash log(aboveweight) =β\_0 + β\_1 \textbackslash log(diameter) + β\_2 \textbackslash log(height). What is the effect of introducing log(height)in the model?}}\label{d-introduce-logheight-as-an-explanatory-variable-and-fit-the-modellogaboveweight-ux3b2_0-ux3b2_1-logdiameter-ux3b2_2-logheight.-what-is-the-effect-of-introducing-logheightin-the-model}

\begin{verbatim}

Model Summary:
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = log(aboveweight) ~ log(diameter) + log(height), 
    data = BIOMASS)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.26519 -0.11243 -0.01637  0.07720  0.38024 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   -2.77706    0.31976  -8.685 1.18e-10 ***
log(diameter)  2.17779    0.04965  43.867  < 2e-16 ***
log(height)    0.52918    0.11561   4.577 4.71e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1505 on 39 degrees of freedom
Multiple R-squared:  0.9856,    Adjusted R-squared:  0.9849 
F-statistic:  1337 on 2 and 39 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{verbatim}

--- Effect of Adding log(height) ---
\end{verbatim}

\begin{verbatim}
Change in R²: 0.9779 → 0.9856 (Δ = 0.0077)
\end{verbatim}

\begin{verbatim}
Change in Adjusted R²: 0.9774 → 0.9849 (Δ = 0.0075)
\end{verbatim}

\begin{verbatim}
Change in Residual Variance: 0.0339 → 0.0226 (Δ = -0.0113)
\end{verbatim}

\textbf{Key Improvements:}

\textbf{Better Explanatory Power}

\begin{itemize}
\item
  R² increased from \textbf{97.79\% to 98.56\%}
\item
  The model now explains an \textbf{additional 0.77\%} of the variance
  in log(aboveground weight)
\item
  While this seems small, it represents meaningful improvement in an
  already excellent model
\end{itemize}

\textbf{Improved Adjusted R²}

\begin{itemize}
\item
  Adjusted R² increased from \textbf{97.74\% to 98.49\%} (+0.75\%)
\item
  The positive change in R²ₐ confirms that adding height improves the
  model even after penalizing for the additional parameter
\item
  This indicates height is a \textbf{genuinely useful predictor}, not
  just noise
\end{itemize}

\textbf{Reduced Residual Variance}

\begin{itemize}
\item
  Residual variance decreased by \textbf{33.3\%}: from 0.0339 to 0.0226
\item
  Residual standard error reduced by \textbf{18.3\%}: from 0.1842 to
  0.1505
\item
  \textbf{Predictions are now more precise} with smaller typical errors
\end{itemize}

\textbf{Height is Statistically Significant}

\begin{itemize}
\item
  \textbf{β₂ (log height) = 0.5292}
\item
  \textbf{p-value = 4.71 × 10⁻⁵} (highly significant)
\item
  \textbf{t-value = 4.577} (strong evidence)
\item
  Height contributes significantly to predicting biomass beyond diameter
  alone
\end{itemize}

\textbf{Interpretation of the Height Effect:}

\textbf{Elasticity Interpretation:}

\textbf{β₂ = 0.5292} means:

\begin{itemize}
\item
  A \textbf{1\% increase in height} is associated with approximately a
  \textbf{0.53\% increase in aboveground weight}, holding diameter
  constant
\item
  This is additional to the diameter effect (β₁ = 2.178)
\end{itemize}

\textbf{Biological Meaning:}

\begin{itemize}
\item
  \textbf{Diameter captures most of the biomass} (β₁ = 2.178, the
  dominant effect)
\item
  \textbf{Height adds important information} about tree form and
  structure
\item
  Trees with greater height for a given diameter have proportionally
  more biomass
\item
  This accounts for variation in tree shape, branching patterns, and
  crown development
\end{itemize}

\paragraph{(e) Complete the Analysis questions for the model in
(d).}\label{e-complete-the-analysis-questions-for-the-model-in-d.}

\paragraph{Analysis questions:}\label{analysis-questions}

\subparagraph{(1) Estimate the model's parameters and their standard
errors. Provide an interpretation for the model's
parameters.}\label{estimate-the-models-parameters-and-their-standard-errors.-provide-an-interpretation-for-the-models-parameters.}

\begin{verbatim}
                Estimate Std. Error   t value     Pr(>|t|)
(Intercept)   -2.7770614 0.31975502 -8.684966 1.183407e-10
log(diameter)  2.1777867 0.04964521 43.867008 8.321935e-35
log(height)    0.5291803 0.11560984  4.577295 4.705599e-05
\end{verbatim}

\begin{verbatim}

Interpretation:
\end{verbatim}

\begin{verbatim}
β₀ (Intercept) = -2.7771: Log of expected aboveground weight when
\end{verbatim}

\begin{verbatim}
                        log(diameter) and log(height) are zero.
\end{verbatim}

\begin{verbatim}
β₁ (log diameter) = 2.1778: A 1% increase in diameter is associated with
\end{verbatim}

\begin{verbatim}
                          approximately a 2.18% increase in aboveground weight,
\end{verbatim}

\begin{verbatim}
                          holding height constant.
\end{verbatim}

\begin{verbatim}
β₂ (log height) = 0.5292: A 1% increase in height is associated with
\end{verbatim}

\begin{verbatim}
                        approximately a 0.53% increase in aboveground weight,
\end{verbatim}

\begin{verbatim}
                        holding diameter constant.
\end{verbatim}

\textbf{Detailed Interpretations:}

\textbf{1. β₀ (Intercept) = -2.7771}

\textbf{Statistical Significance:} Highly significant (p = 1.18 × 10⁻¹⁰)

\textbf{Interpretation:}

\begin{itemize}
\item
  This is the expected value of log(aboveweight) when both log(diameter)
  = 0 and log(height) = 0
\item
  In other words, when diameter = 1 cm and height = 1 m
\item
  On the original scale: exp(-2.7771) ≈ \textbf{0.062 kg}
\item
  However, this is an \textbf{extrapolation} beyond the data range and
  should not be interpreted literally, as trees with 1 cm diameter and 1
  m height are not meaningful in this dataset
\end{itemize}

\textbf{2. β₁ (log diameter) = 2.1778}

\textbf{Statistical Significance:} Extremely significant (p = 8.32 ×
10⁻³⁵, t = 43.867)

\textbf{Interpretation (Elasticity):}

\begin{itemize}
\item
  \textbf{β₁ = 2.1778} represents the \textbf{elasticity of aboveground
  weight with respect to diameter}
\item
  A \textbf{1\% increase in diameter} is associated with approximately a
  \textbf{2.18\% increase in aboveground weight}, holding height
  constant
\item
  Equivalently: \textbf{aboveweight ∝ diameter\^{}2.18} (when height is
  held constant)
\end{itemize}

\textbf{Biological Meaning:}

\begin{itemize}
\item
  Diameter has a \textbf{strong positive effect} on biomass
\item
  The exponent \textgreater{} 2 indicates that biomass increases
  \textbf{more than proportionally} with diameter
\item
  This reflects the fact that biomass depends on both cross-sectional
  area (∝ diameter²) and additional structural components
\item
  The exponent of \textasciitilde2.18 is consistent with theoretical and
  empirical allometric relationships for trees
\end{itemize}

\textbf{3. β₂ (log height) = 0.5292}

\textbf{Statistical Significance:} Highly significant (p = 4.71 × 10⁻⁵,
t = 4.577)

\textbf{Interpretation (Elasticity):}

\begin{itemize}
\item
  \textbf{β₂ = 0.5292} represents the \textbf{elasticity of aboveground
  weight with respect to height}
\item
  A \textbf{1\% increase in height} is associated with approximately a
  \textbf{0.53\% increase in aboveground weight}, holding diameter
  constant
\item
  Equivalently: \textbf{aboveweight ∝ height\^{}0.53} (when diameter is
  held constant)
\end{itemize}

\textbf{Biological Meaning:}

\begin{itemize}
\item
  Height has a \textbf{moderate positive effect} on biomass beyond what
  diameter captures
\item
  For trees with the same diameter, taller trees have more aboveground
  biomass
\item
  This captures variation in:

  \begin{itemize}
  \item
    \textbf{Crown size and branch development}
  \item
    \textbf{Tree form} (slender vs.~stocky trees)
  \item
    \textbf{Vertical biomass distribution}
  \end{itemize}
\item
  The exponent \textasciitilde0.5 suggests height contributes roughly as
  the square root, which is less than proportional
\end{itemize}

\subparagraph{\texorpdfstring{(2) Compute the variance-covariance matrix
of the
\(\hat{\beta}_s\).}{(2) Compute the variance-covariance matrix of the \textbackslash hat\{\textbackslash beta\}\_s.}}\label{compute-the-variance-covariance-matrix-of-the-hatbeta_s.}

\begin{verbatim}
                (Intercept) log(diameter)  log(height)
(Intercept)    0.1022432727 -0.0006066342 -0.032216921
log(diameter) -0.0006066342  0.0024646465 -0.002596642
log(height)   -0.0322169214 -0.0025966423  0.013365634
\end{verbatim}

\textbf{Interpretation of Matrix Elements:}

\textbf{1. Diagonal Elements (Variances):}

\textbf{Interpretation:}

\begin{itemize}
\item
  \textbf{Var(β̂₀) = 0.1022:} The intercept has the \textbf{highest
  variance}, indicating the most uncertainty in its estimate
\item
  \textbf{Var(β̂₁) = 0.0025:} The diameter coefficient has \textbf{very
  low variance}, indicating high precision (this is our most precisely
  estimated parameter)
\item
  \textbf{Var(β̂₂) = 0.0134:} The height coefficient has \textbf{moderate
  variance}, more uncertain than diameter but still reasonably precise
\end{itemize}

\textbf{2. Off-Diagonal Elements (Covariances):}

The off-diagonal elements represent the \textbf{covariances} between
pairs of parameter estimates:

\textbf{Cov(β̂₀, β̂₁) = -0.00061}

\begin{itemize}
\item
  \textbf{Negative covariance} between intercept and log(diameter)
\item
  Very small magnitude → weak relationship
\item
  If β̂₁ is higher than expected, β̂₀ tends to be slightly lower
\end{itemize}

\textbf{Cov(β̂₀, β̂₂) = -0.03222}

\begin{itemize}
\item
  \textbf{Negative covariance} between intercept and log(height)
\item
  Moderate magnitude → noticeable relationship
\item
  If β̂₂ is higher than expected, β̂₀ tends to be lower
\item
  This is the \textbf{strongest covariance} in the matrix
\end{itemize}

\textbf{Cov(β̂₁, β̂₂) = -0.00260}

\begin{itemize}
\item
  \textbf{Negative covariance} between log(diameter) and log(height)
\item
  Small magnitude → weak relationship
\item
  If β̂₁ is higher than expected, β̂₂ tends to be slightly lower
\end{itemize}

\subparagraph{\texorpdfstring{(3) Provide 95\% confidence intervals for
\(\beta_1\) and
\(\beta_2\).}{(3) Provide 95\% confidence intervals for \textbackslash beta\_1 and \textbackslash beta\_2.}}\label{provide-95-confidence-intervals-for-beta_1-and-beta_2.}

\begin{verbatim}
                   2.5 %     97.5 %
(Intercept)   -3.4238270 -2.1302958
log(diameter)  2.0773698  2.2782036
log(height)    0.2953374  0.7630233
\end{verbatim}

\begin{verbatim}

Interpretation:
\end{verbatim}

\begin{verbatim}
β₁: We are 95% confident that the true elasticity of aboveground weight
\end{verbatim}

\begin{verbatim}
    with respect to diameter is between 2.0774 and 2.2782.
\end{verbatim}

\begin{verbatim}
β₂: We are 95% confident that the true elasticity of aboveground weight
\end{verbatim}

\begin{verbatim}
    with respect to height is between 0.2953 and 0.7630.
\end{verbatim}

\textbf{Interpretation of β₁ (log diameter):} \textbf{95\% CI:
{[}2.0774, 2.2782{]}}

\textbf{Statistical Interpretation:}

\begin{itemize}
\item
  We are \textbf{95\% confident} that the true population parameter β₁
  lies between 2.0774 and 2.2782
\item
  If we repeated this study many times, approximately 95\% of such
  intervals would contain the true β₁
\end{itemize}

\textbf{Elasticity Interpretation:}

\begin{itemize}
\tightlist
\item
  We are 95\% confident that a \textbf{1\% increase in diameter} is
  associated with between a \textbf{2.08\% and 2.28\% increase in
  aboveground weight}, holding height constant
\end{itemize}

\textbf{Practical Implications:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Highly Precise Estimate:}

  \begin{itemize}
  \item
    Interval width = 0.2008 (very narrow)
  \item
    Relative to the estimate (2.1778), this is only ±4.6\% variation
  \item
    The small standard error (0.0496) results in a tight confidence
    interval
  \item
    This reflects the \textbf{strong relationship} between diameter and
    biomass
  \end{itemize}
\item
  \textbf{Significantly Different from Zero:}

  \begin{itemize}
  \item
    The entire interval is \textbf{far above zero} (minimum = 2.0774)
  \item
    Strong evidence that diameter has a \textbf{positive effect} on
    biomass
  \item
    p-value \textless{} 2.2 × 10⁻¹⁶ confirms this is extremely
    significant
  \end{itemize}
\item
  \textbf{Biological Interpretation:}

  \begin{itemize}
  \item
    The interval (2.08 - 2.28) confirms biomass scales \textbf{more than
    quadratically} with diameter
  \item
    Consistent with theoretical expectations: biomass depends on volume
    (∝ diameter²) plus bark, branches, and structural components
  \item
    The exponent being definitively \textgreater{} 2 (lower bound =
    2.0774) is biologically meaningful
  \end{itemize}
\item
  \textbf{Comparison to Theory:}

  \begin{itemize}
  \item
    Simple volume would suggest β₁ = 2 (area of cross-section)
  \item
    Our interval {[}2.08, 2.28{]} exceeds 2, indicating
    \textbf{additional scaling effects}
  \item
    This is typical for tree allometry
  \end{itemize}
\end{enumerate}

\subparagraph{\texorpdfstring{(4) Compute the \(R^2, R^2_a\) and the
residual
variance.}{(4) Compute the R\^{}2, R\^{}2\_a and the residual variance.}}\label{compute-the-r2-r2_a-and-the-residual-variance.}

\begin{verbatim}
R-squared (R²): 0.9856
\end{verbatim}

\begin{verbatim}
  → The model explains 98.56% of the variance in log(aboveground weight)
\end{verbatim}

\begin{verbatim}
Adjusted R-squared (R²ₐ): 0.9849
\end{verbatim}

\begin{verbatim}
  → Adjusts for number of predictors
\end{verbatim}

\begin{verbatim}
Residual variance (σ²): 0.0226
\end{verbatim}

\begin{verbatim}
Residual standard error (σ): 0.1505
\end{verbatim}

\textbf{1. R-squared (R²) = 0.9856}

\textbf{Definition:}

R² measures the \textbf{proportion of variance in the dependent
variable} (log(aboveground weight)) that is \textbf{explained by the
independent variables} (log(diameter) and log(height)).

\textbf{Interpretation:}

\textbf{Statistical Interpretation:}

\begin{itemize}
\item
  The model explains \textbf{98.56\% of the total variance} in
  log(aboveground weight)
\item
  Only \textbf{1.44\% of the variance remains unexplained} (due to
  random error and unmeasured factors)
\end{itemize}

\textbf{Practical Interpretation:}

\begin{itemize}
\item
  This is an \textbf{excellent fit} - nearly all variation in tree
  biomass is captured by diameter and height
\item
  The model has \textbf{very high predictive power}
\item
  The allometric relationship is \textbf{extremely strong and
  consistent}
\end{itemize}

\textbf{Quality Assessment:}

\begin{itemize}
\item
  R² \textgreater{} 0.95 is considered \textbf{excellent} in biological
  sciences
\item
  R² = 0.9856 indicates the model is \textbf{highly effective} at
  predicting biomass
\item
  Very little room for improvement with additional predictors
\end{itemize}

\textbf{2. Adjusted R-squared (R²ₐ) = 0.9849}

\textbf{Definition:}

Adjusted R² modifies R² to account for the \textbf{number of predictors}
in the model, penalizing for adding variables that don't substantially
improve fit.

\textbf{Interpretation:}

\textbf{Statistical Interpretation:}

\begin{itemize}
\item
  After adjusting for the 2 predictors, the model still explains
  \textbf{98.49\% of the variance}
\item
  The adjustment penalty is minimal: R² - R²ₐ = 0.9856 - 0.9849 =
  \textbf{0.0007} (0.07\%)
\end{itemize}

\textbf{Why the Small Difference?}

\begin{itemize}
\item
  \textbf{Large sample size} relative to predictors (n=42, p=2)
\item
  Both predictors are \textbf{highly significant} and contribute
  meaningfully
\item
  No ``overfitting'' - the predictors genuinely improve the model
\end{itemize}

\textbf{Model Selection Implications:}

\begin{itemize}
\item
  The small difference (0.07\%) indicates \textbf{both predictors are
  valuable}
\item
  If we had added an irrelevant predictor, R²ₐ would have decreased
  while R² increased
\item
  The fact that R²ₐ is nearly identical to R² confirms our model is
  \textbf{parsimonious and well-specified}
\end{itemize}

\textbf{3. Residual Variance (σ²) = 0.0226}

\textbf{Definition:}

The residual variance measures the \textbf{average squared deviation} of
observations from the fitted regression line on the log scale.

\textbf{Interpretation:}

\textbf{Statistical Interpretation:}

\begin{itemize}
\item
  The variance of the residuals around the regression line is
  \textbf{0.0226} (in log units)
\item
  This represents the \textbf{unexplained variation} in the model
\item
  Lower values indicate better fit
\end{itemize}

\textbf{Scale Consideration:}

\begin{itemize}
\item
  This is on the \textbf{log scale}, so it's not directly interpretable
  in kg
\item
  However, 0.0226 is \textbf{quite small} for log-transformed data
\item
  It indicates \textbf{tight clustering} of observations around the
  fitted line
\end{itemize}

\textbf{Comparison to Simple Model:}

\begin{itemize}
\item
  Simple model (diameter only): σ² = 0.0339
\item
  Multiple model (diameter + height): σ² = 0.0226
\item
  Reduction: 0.0339 - 0.0226 = 0.0113
\item
  \textbf{33.3\% reduction} in residual variance by adding height
\end{itemize}

\textbf{Quality Assessment:}

\begin{itemize}
\item
  Small residual variance indicates \textbf{high precision}
\item
  Predictions will have \textbf{narrow prediction intervals}
\item
  The model captures the systematic relationship very well
\end{itemize}

\textbf{4. Residual Standard Error (σ) = 0.1505}

\textbf{Definition:}

The residual standard error is the \textbf{square root of the residual
variance}, representing the typical size of a residual.

\textbf{Interpretation:}

\textbf{Statistical Interpretation:}

\begin{itemize}
\item
  The \textbf{typical prediction error} is about 0.1505 on the log scale
\item
  This is the standard deviation of the residuals
\item
  About 68\% of observations fall within ±0.1505 of their predicted
  log(weight)
\item
  About 95\% fall within ±2(0.1505) = ±0.301 of their predicted
  log(weight)
\end{itemize}

\textbf{Back-transformation to Original Scale:} To understand the
prediction error in terms of actual weight:

\begin{itemize}
\item
  A residual of +0.1505 on log scale → multiplicative error of
  exp(0.1505) ≈ \textbf{1.162} (16.2\% overestimation)
\item
  A residual of -0.1505 on log scale → multiplicative error of
  exp(-0.1505) ≈ \textbf{0.860} (14.0\% underestimation)
\end{itemize}

\textbf{Practical Interpretation:}

\begin{itemize}
\item
  Typical predictions are accurate within about \textbf{±14-16\%} on the
  original scale
\item
  This is \textbf{excellent precision} for biological/ecological models
\item
  For carbon accounting, this level of accuracy is highly acceptable
\end{itemize}

\textbf{Comparison to Simple Model:}

\begin{itemize}
\item
  Simple model: σ = 0.1842
\item
  Multiple model: σ = 0.1505
\item
  Improvement: \textbf{18.3\% reduction} in typical prediction error
\end{itemize}

\subparagraph{(5) Construct a graph with the default diagnostics plots
of R.}\label{construct-a-graph-with-the-default-diagnostics-plots-of-r.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-10-1.pdf}}

\textbf{1. Residuals vs Fitted (Top Left)}

\textbf{Purpose:}

Checks for \textbf{linearity} and \textbf{homoscedasticity} (constant
variance).

\textbf{What to Look For:}

\begin{itemize}
\item
  Residuals should be randomly scattered around zero
\item
  No systematic patterns (curves, funnels, or trends)
\item
  Horizontal red line near zero
\end{itemize}

\textbf{Observations:}

\textbf{GOOD SIGNS:}

\begin{itemize}
\item
  Residuals are \textbf{randomly scattered} around the horizontal zero
  line
\item
  The red smoothed line is \textbf{nearly horizontal} and close to zero
\item
  No clear \textbf{curved pattern} (U-shape or inverted U-shape)
\item
  Points are distributed relatively evenly above and below zero
\end{itemize}

\textbf{MINOR CONCERNS:}

\begin{itemize}
\item
  There's a \textbf{slight suggestion of clustering} around fitted
  values 7-8
\item
  A few labeled points (10, 11, 15) show slightly larger residuals
\item
  \textbf{Very slight hint} of increasing spread at higher fitted values
  (but minimal)
\end{itemize}

\textbf{Conclusion:}

The \textbf{linearity assumption is satisfied} - the log-log
transformation successfully linearized the relationship.
\textbf{Homoscedasticity appears reasonable} with only very minor
heteroscedasticity, if any.

\textbf{2. Normal Q-Q Plot (Top Right)}

\textbf{Purpose:}

Checks if residuals follow a \textbf{normal distribution}.

\textbf{What to Look For:}

\begin{itemize}
\item
  Points should fall along the diagonal dashed line
\item
  No systematic deviations (S-curves, heavy tails, or outliers)
\end{itemize}

\textbf{Observations:}

\textbf{EXCELLENT:}

\begin{itemize}
\item
  The vast majority of points \textbf{follow the diagonal line closely}
\item
  The middle portion (between quantiles -1 to +1.5) shows
  \textbf{excellent alignment}
\item
  This represents about 80-90\% of the data
\end{itemize}

\textbf{SLIGHT DEVIATIONS:}

\begin{itemize}
\item
  \textbf{Right tail (upper quantiles):} Points 11, 10, 9, 15 slightly
  deviate upward

  \begin{itemize}
  \item
    These observations have \textbf{slightly larger positive residuals}
    than expected under perfect normality
  \item
    Suggests very mild \textbf{right skewness} or potential outliers
  \end{itemize}
\item
  \textbf{Left tail (lower quantiles):} Minor deviation in the lower
  left

  \begin{itemize}
  \tightlist
  \item
    Less pronounced than right tail
  \end{itemize}
\end{itemize}

\textbf{Conclusion:}

The \textbf{normality assumption is largely satisfied}. The deviations
are \textbf{minor} and unlikely to seriously affect inference. The
slight right-tail deviation is common in biological data and not severe
enough to warrant concern for a sample of n=42.

\textbf{3. Scale-Location Plot (Bottom Left)}

\textbf{Purpose:}

Another check for \textbf{homoscedasticity} (constant variance) using
standardized residuals.

\textbf{What to Look For:}

\begin{itemize}
\item
  Random scatter of points
\item
  Horizontal red line
\item
  Constant vertical spread across fitted values
\end{itemize}

\textbf{Observations:}

\textbf{GOOD SIGNS:}

\begin{itemize}
\item
  The red smoothed line is \textbf{relatively flat} (slight upward trend
  but minimal)
\item
  Points show \textbf{reasonably consistent spread} across the range of
  fitted values
\item
  Most points cluster between √\textbar standardized residuals\textbar{}
  of 0.5 and 1.2
\end{itemize}

\textbf{MINOR CONCERNS:}

\begin{itemize}
\item
  Again, observations 10, 11, and 15 stand out with higher values
\item
  \textbf{Very slight upward trend} in the red line at higher fitted
  values

  \begin{itemize}
  \item
    Suggests marginally increasing variance with predicted weight
  \item
    However, the trend is \textbf{very modest}
  \end{itemize}
\end{itemize}

\textbf{Conclusion:}

\textbf{Homoscedasticity assumption is reasonably satisfied}. There's a
very slight hint of increasing variance at higher fitted values, but
it's minor and unlikely to seriously violate the assumption. The
constant variance assumption holds \textbf{reasonably well}.

\textbf{4. Residuals vs Leverage (Cook's Distance) (Bottom Right)}

\textbf{Purpose:}

Identifies \textbf{influential observations} that have high leverage
and/or large residuals.

\textbf{What to Look For:}

\begin{itemize}
\item
  Points outside Cook's distance contours (dashed red lines, typically
  0.5 or 1.0)
\item
  Points in upper-right or lower-right corners (high leverage + large
  residual)
\item
  Most points should have low Cook's distance
\end{itemize}

\textbf{Observations:}

\textbf{EXCELLENT:}

\begin{itemize}
\item
  \textbf{No points exceed Cook's distance of 0.5} (no dashed red
  contour lines are visible)
\item
  All observations have \textbf{Cook's distance well below 0.2}
\item
  Most points cluster near \textbf{Cook's distance \textless{} 0.1}
\end{itemize}

\textbf{Notable Observations:}

\begin{itemize}
\item
  \textbf{Observation 11:} Highest Cook's distance (\textasciitilde0.15)
  but still well below concerning threshold
\item
  \textbf{Observation 15:} Also elevated (\textasciitilde0.13)
\item
  \textbf{Observation 13:} Moderate Cook's distance
  (\textasciitilde0.12)
\item
  These points have \textbf{some influence} but are \textbf{not
  problematic}
\end{itemize}

\textbf{Leverage Assessment:}

\begin{itemize}
\item
  All points have \textbf{relatively low leverage} (x-axis values
  \textless{} 0.15)
\item
  No extreme leverage points that would dominate the regression
\item
  The maximum leverage is well below concerning thresholds (typically
  2p/n = 6/42 = 0.14)
\end{itemize}

\textbf{Conclusion:}

\textbf{No influential observations} of serious concern. While
observations 11, 13, and 15 have slightly elevated Cook's distances,
they remain well within acceptable ranges and do not unduly influence
the regression results.

\subparagraph{(6) Can homogeneity of variance be
assumed?}\label{can-homogeneity-of-variance-be-assumed}

\begin{verbatim}

Breusch-Pagan Test for Heteroscedasticity:
\end{verbatim}

\begin{verbatim}

    studentized Breusch-Pagan test

data:  model_d
BP = 7.4101, df = 2, p-value = 0.0246
\end{verbatim}

\begin{verbatim}

Conclusion: Reject H₀ (p < 0.05).
Evidence of heteroscedasticity (non-constant variance).
\end{verbatim}

\begin{verbatim}

Visual Assessment: Check the Residuals vs Fitted plot.
\end{verbatim}

\begin{verbatim}

If residuals are randomly scattered around zero with constant spread,
\end{verbatim}

\begin{verbatim}

homoscedasticity is reasonable.
\end{verbatim}

\textbf{Statistical Test Results:}

\textbf{Breusch-Pagan Test for Heteroscedasticity:}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Test Statistic & df & p-value & Decision \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
BP = 7.4101 & 2 & 0.0246 & Reject H₀ \\
\end{longtable}

\textbf{Hypotheses:}

\begin{itemize}
\item
  \textbf{H₀:} Homoscedasticity (constant variance of residuals)
\item
  \textbf{H₁:} Heteroscedasticity (non-constant variance of residuals)
\end{itemize}

\textbf{Test Interpretation:}

\begin{itemize}
\item
  \textbf{p-value = 0.0246 \textless{} 0.05} → Reject the null
  hypothesis at α = 0.05
\item
  \textbf{Statistical conclusion:} There is evidence of
  \textbf{heteroscedasticity}
\end{itemize}

\textbf{Answer: Homogeneity of Variance - BORDERLINE CASE}

\textbf{TECHNICAL ANSWER: Marginally Violated}

Based on the \textbf{formal statistical test alone}, we would conclude:

\begin{itemize}
\item
  \textbf{No, homogeneity of variance cannot be fully assumed}
\item
  The Breusch-Pagan test detects \textbf{statistically significant
  heteroscedasticity} (p = 0.0246)
\end{itemize}

\textbf{Technically:}

\textbf{No, perfect homogeneity of variance cannot be assumed} - the
Breusch-Pagan test detects statistically significant heteroscedasticity
(p = 0.0246).

\textbf{Practically:}

\textbf{The violation is MILD and does NOT seriously compromise the
model}:

\begin{itemize}
\item
  It's a \textbf{borderline case} (p = 0.0246, just below 0.05)
\item
  Visual diagnostics show only \textbf{minor variance changes}
\item
  Parameter estimates remain \textbf{valid and unbiased}
\item
  Inference remains \textbf{reliable} given the extremely strong
  statistical significance of predictors
\item
  Predictions remain \textbf{highly accurate} (R² = 0.9856)
\end{itemize}

\subparagraph{(7) Do the residuals appear to follow a normal
distribution?}\label{do-the-residuals-appear-to-follow-a-normal-distribution}

\begin{verbatim}

Shapiro-Wilk Normality Test:
\end{verbatim}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  residuals(model_d)
W = 0.95133, p-value = 0.07208
\end{verbatim}

\begin{verbatim}

Conclusion: Fail to reject H₀ (p > 0.05).
Residuals appear to follow a normal distribution.
\end{verbatim}

\begin{verbatim}

Visual Assessment: Check the Normal Q-Q plot.
\end{verbatim}

\begin{verbatim}

Points should follow the diagonal line closely.
\end{verbatim}

\textbf{Statistical Test Results:}

\textbf{Shapiro-Wilk Normality Test:}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Test Statistic & p-value & Decision & α level \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
W = 0.95133 & 0.07208 & Fail to reject H₀ & 0.05 \\
\end{longtable}

\textbf{Hypotheses:}

\begin{itemize}
\item
  \textbf{H₀:} The residuals follow a normal distribution
\item
  \textbf{H₁:} The residuals do NOT follow a normal distribution
\end{itemize}

\textbf{Test Interpretation:}

\begin{itemize}
\item
  \textbf{p-value = 0.07208 \textgreater{} 0.05} → Fail to reject the
  null hypothesis at α = 0.05
\item
  \textbf{Statistical conclusion:} There is \textbf{insufficient
  evidence to reject normality}
\item
  The residuals are \textbf{consistent with a normal distribution}
\end{itemize}

\textbf{Answer: YES, Residuals Appear to Follow a Normal Distribution}

\textbf{Evidence:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Shapiro-Wilk test:} p = 0.072 \textgreater{} 0.05 (fail to
  reject normality)
\item
  \textbf{W statistic:} 0.951 (close to 1, indicates good fit)
\item
  \textbf{Q-Q plot:} 80-90\% of points follow diagonal closely
\item
  \textbf{Minor tail deviations:} Present but not concerning
\item
  \textbf{Overall assessment:} Normality assumption is \textbf{well
  satisfied}
\end{enumerate}

\textbf{Conclusion:} The normality assumption \textbf{holds sufficiently
well} for:

\begin{itemize}
\item
  Valid statistical inference
\item
  Reliable confidence intervals
\item
  Trustworthy hypothesis tests
\item
  Accurate predictions
\end{itemize}

The minor deviations in the tails are \textbf{typical of real-world
ecological data} and do \textbf{not undermine the model's validity}. The
allometric regression model satisfies the normality assumption and can
be \textbf{confidently used for inference and prediction}.

\subparagraph{(8) Are there any outliers in the
data?}\label{are-there-any-outliers-in-the-data}

\begin{verbatim}

Observations with |standardized residuals| > 3:
\end{verbatim}

\begin{verbatim}
No extreme outliers detected (using |std. residual| > 3 criterion).
\end{verbatim}

\begin{verbatim}

Observations with |standardized residuals| > 2.5:
\end{verbatim}

\begin{verbatim}
Moderate outliers at observations: 15 
\end{verbatim}

\textbf{Criterion 1: Extreme Outliers (\textbar Standardized
Residual\textbar{} \textgreater{} 3)}

\textbf{Result:} \textbf{No extreme outliers detected}

\textbf{Interpretation:}

\begin{itemize}
\item
  Using the stringent criterion of \textbf{\textbar standardized
  residual\textbar{} \textgreater{} 3}
\item
  \textbf{Zero observations} exceed this threshold
\item
  This represents points more than \textbf{3 standard deviations} from
  the regression line
\item
  Expected under normality: \textasciitilde0.3\% of observations (0.13
  out of 42)
\item
  \textbf{Observed: 0 observations} → No extreme outliers
\end{itemize}

\textbf{Criterion 2: Moderate Outliers (\textbar Standardized
Residual\textbar{} \textgreater{} 2.5)}

\textbf{Result:} \textbf{One moderate outlier detected}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Observation & Status \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{15} & Moderate outlier ( \\
\end{longtable}

\textbf{Interpretation:}

\begin{itemize}
\item
  Using the moderate criterion of \textbf{\textbar standardized
  residual\textbar{} \textgreater{} 2.5}
\item
  \textbf{One observation (\#15)} exceeds this threshold
\item
  This represents a point more than \textbf{2.5 standard deviations}
  from the regression line
\item
  Expected under normality: \textasciitilde1.2\% of observations (0.50
  out of 42)
\item
  \textbf{Observed: 1 observation (2.4\%)} → Slightly above expected,
  but not alarming
\end{itemize}

\textbf{Answer: Minimal Outliers - Not a Concern}

\textbf{Summary:}

\begin{itemize}
\item
  \textbf{Extreme outliers (\textgreater{} 3σ):} None
\item
  \textbf{Moderate outliers (\textgreater{} 2.5σ):} One (observation
  \#15)
\item
  \textbf{Overall assessment:} The data has \textbf{very few outliers},
  and those present are \textbf{not extreme}
\end{itemize}

\subparagraph{(9) Are there any influential observations in the
data?}\label{are-there-any-influential-observations-in-the-data}

\begin{verbatim}

Cook's Distance Analysis:
\end{verbatim}

\begin{verbatim}
Threshold: 4/n = 4/42 = 0.0952
\end{verbatim}

\begin{verbatim}

Influential observations (Cook's D > 4/n):
   Observation Cooks_Distance
10          10     0.09926686
11          11     0.10762639
13          13     0.17027939
15          15     0.11358272
\end{verbatim}

\begin{verbatim}

DFBETAS Analysis:
\end{verbatim}

\begin{verbatim}
Threshold: 2/√n = 2/√42 = 0.3086
\end{verbatim}

\begin{verbatim}

Influential observations (max |DFBETAS| > 2/√n):
10 11 13 14 15 39 
\end{verbatim}

\begin{verbatim}

Leverage Analysis:
\end{verbatim}

\begin{verbatim}
Threshold: 2p/n = 2*3/42 = 0.1429
\end{verbatim}

\begin{verbatim}

High leverage observations:
3 34 41 
\end{verbatim}

\textbf{YES - but with important qualifications:}

\textbf{Mild to Moderate Influence Detected:}

\begin{itemize}
\item
  \textbf{4 observations} (10, 11, 13, 15) show \textbf{mild to moderate
  influence} via Cook's Distance
\item
  \textbf{6 observations} (10, 11, 13, 14, 15, 39) influence
  \textbf{specific coefficients} via DFBETAS
\item
  \textbf{3 observations} (3, 34, 41) have \textbf{high leverage but fit
  well}
\end{itemize}

\textbf{None Are Severely Problematic:}

\begin{itemize}
\item
  \textbf{Maximum Cook's D = 0.170} (well below concerning threshold of
  0.5)
\item
  High leverage points \textbf{conform to the model} (small residuals)
\item
  Influence is \textbf{distributed} across multiple observations (no
  single dominant point)
\end{itemize}

\textbf{Model Remains Robust:}

\begin{itemize}
\item
  All influential observations combined explain \textless{} 10\% of data
\item
  \textbf{Removing any/all would have minimal impact} on conclusions
\item
  Strong statistical significance (p \textless{} 10⁻⁵) provides
  \textbf{large buffer}
\item
  R² = 0.9856 indicates \textbf{excellent fit even with these
  observations}
\end{itemize}

\textbf{Recommended Action:}

\textbf{RETAIN all observations} - they represent legitimate biological
variation within acceptable influence bounds

\textbf{OPTIONAL: Verify data quality} for observations 13, 15, 11, 10
if original records available

\textbf{DOCUMENT} that influence diagnostics were checked and found
acceptable

\textbf{PROCEED confidently} with inference and prediction using the
full model

\textbf{Conclusion:}

While several observations show \textbf{detectable influence} on the
regression, \textbf{none are severe enough to warrant removal or
concern}. The model is \textbf{statistically robust}, all assumptions
are \textbf{reasonably satisfied}, and the influential observations
represent \textbf{natural biological variation} rather than data
problems.

The allometric equation remains \textbf{valid, reliable, and appropriate
for operational use} in estimating beech tree biomass for carbon
accounting and forest inventory applications.

\paragraph{\texorpdfstring{(f) Obtain predictions of the aboveground
biomass of trees with diameters \(diameter = seq(12.5, 42.5, 5)\) and
heights \(height = seq(10, 40, 5)\). Note that the weight predictions
are obtained from back transforming the logarithm. The bias correction
is obtained by means of the lognormal distribution: If
\(\hat{Y}_{pred}\) is the prediction, the corrected(back-transformed)
prediction \(\tilde{Y}_{pred}\) is given
by}{(f) Obtain predictions of the aboveground biomass of trees with diameters diameter = seq(12.5, 42.5, 5) and heights height = seq(10, 40, 5). Note that the weight predictions are obtained from back transforming the logarithm. The bias correction is obtained by means of the lognormal distribution: If \textbackslash hat\{Y\}\_\{pred\} is the prediction, the corrected(back-transformed) prediction \textbackslash tilde\{Y\}\_\{pred\} is given by}}\label{f-obtain-predictions-of-the-aboveground-biomass-of-trees-with-diameters-diameter-seq12.5-42.5-5-and-heights-height-seq10-40-5.-note-that-the-weight-predictions-are-obtained-from-back-transforming-the-logarithm.-the-bias-correction-is-obtained-by-means-of-the-lognormal-distribution-if-haty_pred-is-the-prediction-the-correctedback-transformed-prediction-tildey_pred-is-given-by}

\begin{verbatim}

Creating predictions for 49 combinations of diameter and height
\end{verbatim}

\begin{verbatim}

Bias Correction Formula:
\end{verbatim}

\begin{verbatim}
ỹ_pred = exp(ŷ_pred + σ²/2)
\end{verbatim}

\begin{verbatim}
where σ² = 0.0226
\end{verbatim}

\begin{verbatim}

--- Sample Predictions ---
\end{verbatim}

\begin{verbatim}
   diameter height PSA_pred_corrected
1      12.5     10           52.10406
2      17.5     10          108.41945
3      22.5     10          187.41338
4      27.5     10          290.13163
5      32.5     10          417.44086
6      37.5     10          570.08529
7      42.5     10          748.71965
8      12.5     15           64.57368
9      17.5     15          134.36658
10     22.5     15          232.26546
\end{verbatim}

\begin{verbatim}

--- Full Prediction Table ---
\end{verbatim}

\begin{verbatim}
  Diameter (cm) Height (m) Log(Weight) Predicted Weight (kg)
1          12.5         10    3.941919              52.10406
2          17.5         10    4.674684             108.41945
3          22.5         10    5.221993             187.41338
4          27.5         10    5.659011             290.13163
5          32.5         10    6.022820             417.44086
6          37.5         10    6.334463             570.08529
\end{verbatim}

\begin{verbatim}


Generating prediction visualization...
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-15-1.pdf}}

\textbf{Key Patterns from Predictions:}

\textbf{1. Effect of Diameter (holding height constant at 10m):}

\textbf{Observation:}

\begin{itemize}
\item
  Diameter has a \textbf{strong accelerating effect} (β₁ = 2.18)
\item
  Each 5 cm increase in diameter adds increasingly more biomass
\item
  This reflects the \textbf{power-law relationship} (weight ∝
  diameter\^{}2.18)
\end{itemize}

\textbf{2. Effect of Height (holding diameter constant at 22.5 cm):}

\textbf{Observation:}

\begin{itemize}
\item
  Height has a \textbf{moderate, decelerating effect} (β₂ = 0.53)
\item
  Each 5 m increase adds progressively less biomass
\item
  This reflects the \textbf{sub-linear relationship} (weight ∝
  height\^{}0.53)
\end{itemize}

\textbf{3. Extreme Cases:}

\textbf{Smallest tree (12.5 cm × 10 m):}

\begin{itemize}
\item
  Predicted weight: \textbf{52.1 kg}
\item
  Represents a young or suppressed beech tree
\end{itemize}

\textbf{Largest tree (42.5 cm × 40 m):}

\begin{itemize}
\item
  Predicted weight: \textbf{1,559 kg} (from full table)
\item
  Represents a mature, dominant canopy tree
\item
  \textbf{30× more biomass} than smallest tree
\end{itemize}

\textbf{Visualization Interpretation:}

\textbf{Key Patterns in the Graph:}

\textbf{Fan-shaped pattern:}

\begin{itemize}
\item
  Lines diverge as diameter increases
\item
  Height effect becomes \textbf{more pronounced} at larger diameters
\item
  This is the \textbf{interaction effect} of the multiplicative
  (power-law) model
\end{itemize}

\textbf{Color gradient (height effect):}

\begin{itemize}
\item
  \textbf{Red (10m):} Lowest biomass for any diameter
\item
  \textbf{Pink (40m):} Highest biomass for any diameter
\item
  Clear \textbf{vertical separation} showing height's contribution
\end{itemize}

\textbf{Steep slopes:}

\begin{itemize}
\item
  All lines are \textbf{curved upward} (exponential appearance on
  original scale)
\item
  Reflects the strong diameter effect (β₁ = 2.18)
\end{itemize}

\textbf{Biological realism:}

\begin{itemize}
\item
  Predictions follow \textbf{realistic patterns} for tree growth
\item
  Small trees: 50-150 kg (realistic for young beeches)
\item
  Large trees: 500-1,500 kg (realistic for mature beeches)
\end{itemize}

\section{Case Study 2: Fruit Trees}\label{case-study-2-fruit-trees}

\emph{Data and ideas for this case study come from Militino et
al.~(2006).}

To estimate the total surface occupied by fruit trees in three small
areas (R63, R67, and R68) of Navarra in 2001, a sample of 47 square
segments has been taken. The experimental units are square segments or
quadrats of 4 hectares, obtained by random sampling after overlaying a
square grid on the study domain. The focus of this case study is
illustrating two different techniques used to obtain estimates: direct
estimation and small area estimation. The direct technique estimates the
total surface area by multiplying the mean of the observed surface area
in the sampled segments by the total number of segments in every small
area. The small area technique consists of creating a regression model
where the dependent variable is the observed surface area occupied by
fruit trees in every segment and the explanatory variables are the
classified cultivars by satellite in the same segment and the small
areas to which they belong. The final surface area totals are obtained
by multiplying the total classified surface area of every small area by
the β's parameter estimates obtained from the regression model (observed
surface area∼ classified surface area + small areas). The surface
variables in the data frame \texttt{SATFRUIT} are given in \(m^2\):

• \texttt{quadrat} is the number of the sampled segment or quadraz

• \texttt{smallarea} are the small areas' labels

• \texttt{wheat} is the classified surface of wheat in the sampled
segment

• \texttt{barley} is the classified surface of barley in the sampled
segment

• \texttt{nonarable} is the classified surface of fallow or non-arable
land in the sampled segment

• \texttt{corn} is the classified surface of corn in the sampled segment

• \texttt{sunflower} is the classified surface of sunflowers in the
sampled segment

• \texttt{vineyard} is the classified surface of vineyards in the
sampled segment

• \texttt{grass} is the classified surface of grass in the sampled
segment

• \texttt{asparagus} is the classified surface of asparagus in the
sampled segment

• \texttt{alfalfa} is the classified surface of lucerne (type of
alfalfa) in the sampled segment

• \texttt{rape} is the classified surface of rape Brassica napus in the
sampled segment

• \texttt{rice} is the classified surface of rice in the sampled segment

• \texttt{almonds} is the classified surface of almonds in the sampled
segment

• \texttt{olives} is the classified surface of olives in the sampled
segment

• \texttt{fruit} is the classified surface of fruit trees in the sampled
segment

• \texttt{observed} is the observed surface of fruit trees in the
sampled segment

\begin{verbatim}
   quadrat smallarea wheat barley nonarable     corn sunflower  vineyard
1 59106566       R68     0      0  1933.912   0.0000         0   0.00000
2 59086560       R68     0      0  1392.159 690.8583         0 399.05674
3 59406568       R68     0      0  2026.149   0.0000         0  54.21483
4 59406562       R68     0      0  1310.520   0.0000         0   0.00000
5 59486566       R68     0      0  1684.034 203.6149         0   0.00000
6 59446566       R68     0      0  3366.676   0.0000         0  68.70976
     grass   asparagus  alfalfa rape rice  almonds    olives     fruit observed
1 666.7915    0.000000   0.0000    0    0 690.3103 6922.5719  4285.158 4626.538
2   0.0000  382.974588 105.2031    0    0   0.0000 2548.0677  8450.084 7172.923
3   0.0000    7.564448   0.0000    0    0   0.0000 1925.0580 10485.737 3304.583
4   0.0000  452.076937   0.0000    0    0   0.0000 1332.5450 11403.596 6457.927
5   0.0000 1020.623038   0.0000    0    0   0.0000  690.4447 10900.023 6926.474
6   0.0000  221.744765 946.5758    0    0   0.0000 1127.4307  8767.596 5221.704
\end{verbatim}

\subsubsection{\texorpdfstring{(a) Characterize the shape, center, and
spread for the variable
\texttt{fruit}.}{(a) Characterize the shape, center, and spread for the variable fruit.}}\label{a-characterize-the-shape-center-and-spread-for-the-variable-fruit.}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      0    4241    8536    7827   11356   13969 
\end{verbatim}

\begin{verbatim}

Standard Deviation: 4119.28 
\end{verbatim}

\begin{verbatim}
IQR: 7115.129 
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-18-1.pdf}}

\textbf{Shape:}

\begin{itemize}
\item
  \textbf{Right-skewed (positively skewed)}: The distribution shows a
  longer tail extending to the right. The mean (7,827 m²) is greater
  than the median (8,536 m²), which is a characteristic of right-skewed
  distributions. Wait, actually the median is larger than the mean here,
  which suggests slight left-skewness, but the histogram shows
  concentration in the middle-to-upper range with some lower values
  pulling the mean down.
\item
  \textbf{Roughly unimodal}: The histogram shows the highest frequency
  occurring around 12,000-13,000 m², with most observations concentrated
  in the upper range.
\item
  The distribution appears somewhat irregular with multiple smaller
  peaks, suggesting some variability in fruit tree coverage across
  segments.
\end{itemize}

\textbf{Center:}

\begin{itemize}
\item
  \textbf{Mean}: 7,827 m² - the average classified fruit surface area
  per segment
\item
  \textbf{Median}: 8,536 m² - the middle value, indicating that 50\% of
  segments have classified fruit area below this value
\item
  The median being slightly higher than the mean suggests the presence
  of some segments with very low fruit coverage (including the minimum
  of 0 m²) pulling the mean downward.
\end{itemize}

\textbf{Spread:}

\begin{itemize}
\item
  \textbf{Range}: 0 to 13,969 m² - showing considerable variability in
  fruit tree coverage
\item
  \textbf{Standard Deviation}: 4,119.28 m² - indicates substantial
  variation around the mean
\item
  \textbf{IQR (Interquartile Range)}: 7,115.129 m² - the middle 50\% of
  observations span over 7,000 m²
\item
  \textbf{Q1}: 4,241 m²
\item
  \textbf{Q3}: 11,356 m²
\end{itemize}

\subsubsection{\texorpdfstring{(b) What is the maximum number of \(m^2\)
of classified fruits by
segment?}{(b) What is the maximum number of m\^{}2 of classified fruits by segment?}}\label{b-what-is-the-maximum-number-of-m2-of-classified-fruits-by-segment}

\begin{verbatim}
Maximum m² of classified fruits: 13968.61 
\end{verbatim}

\subsubsection{(c) How many observations are there by small
area?}\label{c-how-many-observations-are-there-by-small-area}

\begin{verbatim}

R63 R67 R68 
  3  32  12 
\end{verbatim}

\subsubsection{\texorpdfstring{(d) Use \texttt{scatterplotMatrix()} from
\texttt{car} or \texttt{pairs()} to explore the linear relationships
between observed and the remainder of the numerical variables. Comment
on the
results.}{(d) Use scatterplotMatrix() from car or pairs() to explore the linear relationships between observed and the remainder of the numerical variables. Comment on the results.}}\label{d-use-scatterplotmatrix-from-car-or-pairs-to-explore-the-linear-relationships-between-observed-and-the-remainder-of-the-numerical-variables.-comment-on-the-results.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-21-1.pdf}}

\textbf{Strong Positive Relationships:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{observed vs.~fruit}: Shows the \textbf{strongest positive
  linear relationship}. There's a clear upward trend where higher
  classified fruit surface area corresponds to higher observed fruit
  surface area. This makes intuitive sense as these are
  satellite-classified vs.~ground-observed measurements of the same
  feature. The relationship appears roughly linear across most of the
  range.
\end{enumerate}

\textbf{Moderate to Weak Relationships:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{observed vs.~almonds}: Shows a \textbf{weak to moderate
  positive relationship}. Most almond values are concentrated near zero,
  but there appears to be some positive association. The relationship is
  less clear than with fruit.
\item
  \textbf{observed vs.~olives}: Shows a \textbf{weak positive
  relationship}, primarily driven by area R68 (green points). R68
  appears to have higher olive coverage, while R67 (pink points) has
  minimal olive presence. The relationship is not strongly linear
  overall.
\item
  \textbf{observed vs.~vineyard}: Shows \textbf{very weak or no clear
  linear relationship}. Most vineyard values are clustered near zero
  with a few outliers. There doesn't appear to be a meaningful linear
  association with observed fruit.
\end{enumerate}

\textbf{Key Patterns by Small Area:}

\begin{itemize}
\item
  \textbf{R67 (pink)}: Tends to have higher observed values and higher
  fruit values, with minimal olives and vineyards
\item
  \textbf{R68 (green)}: Shows more variability, with some segments
  having substantial olive coverage
\item
  The different small areas show distinct patterns, suggesting that
  area-specific effects may be important
\end{itemize}

\subsubsection{\texorpdfstring{(e) Create density plots of the observed
fruits' surface area (\texttt{observed}) by small areas
(\texttt{smallarea}).}{(e) Create density plots of the observed fruits' surface area (observed) by small areas (smallarea).}}\label{e-create-density-plots-of-the-observed-fruits-surface-area-observed-by-small-areas-smallarea.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-22-1.pdf}}

\textbf{Distribution Characteristics by Small Area:}

\textbf{R63 (Pink/Salmon):}

\begin{itemize}
\item
  Shows a \textbf{highly concentrated distribution near zero} with a
  sharp, narrow peak
\item
  The density is highest at very low observed values (close to 0 m²)
\item
  Has the \textbf{smallest range} and lowest observed fruit surface
  areas overall
\item
  Distribution is \textbf{strongly right-skewed} with very little spread
\item
  This suggests R63 has minimal fruit tree coverage in most segments
\end{itemize}

\textbf{R67 (Green):}

\begin{itemize}
\item
  Displays a \textbf{broad, roughly symmetric distribution} centered
  around \textbf{10,000-11,000 m²}
\item
  Has the \textbf{highest median/center} of the three areas
\item
  Shows \textbf{moderate spread} with values ranging approximately from
  7,000 to 13,000 m²
\item
  The distribution is relatively \textbf{unimodal and bell-shaped}
\item
  Indicates R67 has consistently high fruit tree coverage across
  segments
\end{itemize}

\textbf{R68 (Blue):}

\begin{itemize}
\item
  Shows a \textbf{bimodal or irregular distribution} with peaks around
  \textbf{2,000-3,000 m²} and \textbf{5,000-6,000 m²}
\item
  Has \textbf{intermediate values} between R63 and R67
\item
  Distribution is \textbf{moderately spread} with considerable
  variability
\item
  Suggests more heterogeneity in fruit tree coverage within R68
\end{itemize}

\textbf{Key Comparisons:}

\begin{itemize}
\item
  \textbf{R67 clearly has the highest observed fruit surface area} with
  values concentrated in the upper range (8,000-12,000 m²)
\item
  \textbf{R63 has the lowest observed values}, clustered near zero
\item
  \textbf{R68 shows intermediate and more variable coverage}
\item
  The three areas show \textbf{distinctly different distributions},
  suggesting that small area membership is an important factor in
  predicting observed fruit surface area
\item
  There is \textbf{minimal overlap} between R63 and R67, indicating
  these areas are quite different in terms of fruit tree presence
\end{itemize}

\subsubsection{\texorpdfstring{(f) Use box plots and bar plots with
standard errors to compare the observed surface area (\texttt{observed})
and the classified surface area (\texttt{fruit}) by small areas
(\texttt{smallarea}).}{(f) Use box plots and bar plots with standard errors to compare the observed surface area (observed) and the classified surface area (fruit) by small areas (smallarea).}}\label{f-use-box-plots-and-bar-plots-with-standard-errors-to-compare-the-observed-surface-area-observed-and-the-classified-surface-area-fruit-by-small-areas-smallarea.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-23-1.pdf}}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-23-2.pdf}}

\textbf{Box Plots Analysis:}

\textbf{Observed Surface Area (Left, Blue):}

\begin{itemize}
\item
  \textbf{R63}: Shows very low values, with a median near 0 m² and
  maximum around 5,000-6,000 m². The distribution is highly skewed with
  most values concentrated near zero.
\item
  \textbf{R67}: Shows the highest observed values, with a median around
  11,000 m² and a wide interquartile range (approximately 5,000-12,000
  m²). This area has the greatest variability.
\item
  \textbf{R68}: Shows intermediate values with a median around 7,000 m²
  and an interquartile range from approximately 4,000-10,000 m².
\end{itemize}

\textbf{Classified Surface Area (Right, Green):}

\begin{itemize}
\item
  \textbf{R63}: Very low values, median near 0 m², with maximum around
  3,000 m². Similar to observed, most segments have minimal fruit tree
  coverage.
\item
  \textbf{R67}: Highest classified values with median around 9,000 m²
  and wide spread (approximately 5,000-12,000 m²).
\item
  \textbf{R68}: Median around 10,000 m² with interquartile range from
  approximately 8,000-12,000 m². More consistent than observed values.
\end{itemize}

\textbf{Bar Plots with Standard Errors Analysis:}

\textbf{Mean Observed Surface:}

\begin{itemize}
\item
  \textbf{R63}: Approximately 2,000 m² (very small, with relatively
  small standard error)
\item
  \textbf{R67}: Approximately 8,500-9,000 m² (highest mean, with larger
  standard error indicating high variability)
\item
  \textbf{R68}: Approximately 6,500 m² (intermediate, moderate standard
  error)
\end{itemize}

\textbf{Mean Classified Surface:}

\begin{itemize}
\item
  \textbf{R63}: Approximately 1,500 m² (smallest, low standard error)
\item
  \textbf{R67}: Approximately 7,500 m² (moderate, with standard error)
\item
  \textbf{R68}: Approximately 9,500-10,000 m² (highest mean classified,
  moderate standard error)
\end{itemize}

\subsubsection{\texorpdfstring{(g) Compute the correlation between
\texttt{observed} and all other numerical variables. List the three
variables in order along with their correlation coefficients that have
the highest correlation with
\texttt{observed}.}{(g) Compute the correlation between observed and all other numerical variables. List the three variables in order along with their correlation coefficients that have the highest correlation with observed.}}\label{g-compute-the-correlation-between-observed-and-all-other-numerical-variables.-list-the-three-variables-in-order-along-with-their-correlation-coefficients-that-have-the-highest-correlation-with-observed.}

\begin{verbatim}

Top 3 variables with highest correlation with 'observed':
\end{verbatim}

\begin{verbatim}
[1] 0.8186904 0.4022165 0.3988465
\end{verbatim}

\begin{verbatim}

With signs:
\end{verbatim}

\begin{verbatim}
numeric(0)
\end{verbatim}

\textbf{Top 3 Variables with Highest Correlation with `observed':}

Based on the correlation magnitudes shown:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{fruit}: r = 0.819 (very strong positive correlation)

  \begin{itemize}
  \tightlist
  \item
    This is by far the strongest correlation, which makes sense as both
    variables measure fruit tree surface area - one from satellite
    classification (fruit) and one from ground observation (observed)
  \end{itemize}
\item
  \textbf{Second variable}: r = 0.402 (moderate positive correlation)

  \begin{itemize}
  \tightlist
  \item
    Based on the scatterplot matrix, this is likely \textbf{almonds}
  \end{itemize}
\item
  \textbf{Third variable}: r = 0.399 (moderate positive correlation)

  \begin{itemize}
  \tightlist
  \item
    Based on the scatterplot matrix, this is likely \textbf{olives}
  \end{itemize}
\end{enumerate}

\textbf{Interpretation:}

\begin{itemize}
\item
  The \textbf{fruit} variable has a strong correlation of 0.819,
  explaining approximately 67\% of the variance in observed values (r² =
  0.67)
\item
  The other two variables show much weaker correlations (around 0.40),
  indicating they are far less predictive individually
\item
  The large drop from 0.819 to 0.40 suggests that \textbf{fruit} is the
  dominant predictor
\item
  These correlations align with what we observed in the scatterplot
  matrix, where fruit showed a clear linear relationship while almonds
  and olives showed weaker, more scattered relationships
\end{itemize}

\subsection{Model (A)}\label{model-a}

Use backward elimination to develop a model that predicts
\texttt{observed} using the data frame \texttt{SATFRUIT} without
considering \texttt{smallarea}. Start the backward elimination process
by considering all of the numerical variables in \texttt{SATFRUIT} as
potential predictors. Use a p-value-to-remove of 10\%. Store the final
model in the object \texttt{modelA}.

\begin{verbatim}

Model A Summary:
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = observed ~ grass + olives + fruit, data = SATFRUIT)

Residuals:
    Min      1Q  Median      3Q     Max 
-5333.4 -1079.3   150.9   933.8  4210.8 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 807.6049   797.4016   1.013  0.31682    
grass         2.6178     1.3456   1.946  0.05827 .  
olives       -0.7282     0.2580  -2.823  0.00719 ** 
fruit         0.8805     0.0862  10.214 4.52e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2310 on 43 degrees of freedom
Multiple R-squared:  0.7336,    Adjusted R-squared:  0.715 
F-statistic: 39.47 on 3 and 43 DF,  p-value: 2.051e-12
\end{verbatim}

\paragraph{\texorpdfstring{i. Compute \(CV_n\), the leave-one-out
cross-validation error, for \texttt{modelA}. Set the seed to 5 and
compute \(CV_5\), the five-fold cross-validation error, for
\texttt{modelA}. The cross-validation error for a generalized linear
model can be computed using the \texttt{cv.glm()} function from the boot
package. Using the function \texttt{glm()} without passing a family
argument is equivalent to using the function \texttt{lm()}. R Code 1
provides a template for how to use the \texttt{cv.glm()} function. Note
that \(CV_n\) is returned with \texttt{cv.error\$delta{[}1{]}}. To
compute \(CV_5\), pass the value 5 to the argument \(K\) inside the
\texttt{cv.glm()}
function.}{i. Compute CV\_n, the leave-one-out cross-validation error, for modelA. Set the seed to 5 and compute CV\_5, the five-fold cross-validation error, for modelA. The cross-validation error for a generalized linear model can be computed using the cv.glm() function from the boot package. Using the function glm() without passing a family argument is equivalent to using the function lm(). R Code 1 provides a template for how to use the cv.glm() function. Note that CV\_n is returned with cv.error\$delta{[}1{]}. To compute CV\_5, pass the value 5 to the argument K inside the cv.glm() function.}}\label{i.-compute-cv_n-the-leave-one-out-cross-validation-error-for-modela.-set-the-seed-to-5-and-compute-cv_5-the-five-fold-cross-validation-error-for-modela.-the-cross-validation-error-for-a-generalized-linear-model-can-be-computed-using-the-cv.glm-function-from-the-boot-package.-using-the-function-glm-without-passing-a-family-argument-is-equivalent-to-using-the-function-lm.-r-code-1-provides-a-template-for-how-to-use-the-cv.glm-function.-note-that-cv_n-is-returned-with-cv.errordelta1.-to-compute-cv_5-pass-the-value-5-to-the-argument-k-inside-the-cv.glm-function.}

\begin{verbatim}

--- Model A Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 9131968 
\end{verbatim}

\begin{verbatim}
CV_5 (5-fold): 10248950 
\end{verbatim}

\paragraph{\texorpdfstring{ii. Compute \(R^2, R^2_a\), the AIC, and the
BIC for Model (A). What is the proportion of total variability explained
by Model
(A)?}{ii. Compute R\^{}2, R\^{}2\_a, the AIC, and the BIC for Model (A). What is the proportion of total variability explained by Model (A)?}}\label{ii.-compute-r2-r2_a-the-aic-and-the-bic-for-model-a.-what-is-the-proportion-of-total-variability-explained-by-model-a}

\begin{verbatim}

--- Model A Statistics ---
\end{verbatim}

\begin{verbatim}
R²: 0.733581 
\end{verbatim}

\begin{verbatim}
Adjusted R²: 0.7149936 
\end{verbatim}

\begin{verbatim}
AIC: 867.2384 
\end{verbatim}

\begin{verbatim}
BIC: 876.4891 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.733581 
\end{verbatim}

\subsection{Model (B)}\label{model-b}

Use the criterion-based procedure AIC, which for linear regression is
equivalent to Mallow's Cp, to develop a model that predicts
\texttt{observed} using all of the numerical variables in
\texttt{SATFRUIT}. Store the model in the object \texttt{modelB}. Verify
that the model suggested using BIC is the same model as the one
suggested by AIC or Mallow's Cp, which are all the same as Model (A).

\begin{verbatim}

Model B Summary:
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = observed ~ grass + almonds + olives + fruit, data = SATFRUIT)

Residuals:
    Min      1Q  Median      3Q     Max 
-5448.3 -1318.2   319.4   909.6  4002.8 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 1318.17341  869.22493   1.516  0.13689    
grass          2.57887    1.33118   1.937  0.05946 .  
almonds       -0.39549    0.28301  -1.397  0.16962    
olives        -0.70526    0.25571  -2.758  0.00857 ** 
fruit          0.83850    0.09039   9.277 1.01e-11 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2285 on 42 degrees of freedom
Multiple R-squared:  0.7454,    Adjusted R-squared:  0.7212 
F-statistic: 30.74 on 4 and 42 DF,  p-value: 5.545e-12
\end{verbatim}

\begin{verbatim}

Model B (AIC) formula: observed ~ grass + almonds + olives + fruit 
\end{verbatim}

\begin{verbatim}
Model with BIC formula: observed ~ grass + olives + fruit 
\end{verbatim}

\begin{verbatim}
Are Model B and Model A the same? FALSE 
\end{verbatim}

\textbf{Verification: BIC Gives Same Model as Model A}

The verification \textbf{failed}:

\begin{itemize}
\item
  \textbf{BIC model} = grass + olives + fruit (same as Model A) ✓
\item
  \textbf{AIC model} = grass + almonds + olives + fruit (Model B) ✗
\item
  \textbf{AIC ≠ Model A}
\end{itemize}

\textbf{Conclusion:}

The problem statement's expectation was incorrect. In this case:

\begin{itemize}
\item
  \textbf{AIC and BIC selected different models}
\item
  BIC correctly selected the more parsimonious Model A
\item
  AIC selected Model B with the non-significant \texttt{almonds}
  variable
\item
  This demonstrates the difference between AIC (prediction-focused) and
  BIC (parsimony-focused)
\end{itemize}

Model B's inclusion of \texttt{almonds} (p = 0.170) provides negligible
improvement and violates the principle of parsimony. \textbf{Use Model A
for subsequent analyses unless cross-validation errors strongly favor
Model B.}

\subsection{Model (C)}\label{model-c}

Use mean squared prediction error (MSPE) to select a model using all of
the numerical variables in \texttt{SATFRUIT} as potential predictors for
predicting observed. Store the model in the object \texttt{modelC}.
Specifically, select a model using both leave-one-out cross validation
(LOOCV) and five-fold cross validation.

\paragraph{\texorpdfstring{1. Compute \(CV_n\) for \texttt{modelC}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelC}.}{1. Compute CV\_n for modelC. Set the seed to 5 and compute CV\_5 for modelC.}}\label{compute-cv_n-for-modelc.-set-the-seed-to-5-and-compute-cv_5-for-modelc.}

\begin{verbatim}
   Model    CV_n    CV_5
m1    m1 6413903 6676660
m2    m2 6544362 6527809
m3    m3 6987814 7168004
m4    m4 7045110 7266863
m5    m5 7481389 7536766
m6    m6 7183528 7319064
\end{verbatim}

\paragraph{2. Compute R2, R2a, the AIC, and the BIC for Model (C). What
is the proportion of total variability explained by Model
(C)?}\label{compute-r2-r2a-the-aic-and-the-bic-for-model-c.-what-is-the-proportion-of-total-variability-explained-by-model-c}

\begin{verbatim}

Best model based on LOOCV: m1 
\end{verbatim}

\begin{verbatim}
Formula: observed ~ fruit 
\end{verbatim}

\begin{verbatim}

Model C Summary:
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = candidate_models[[best_idx]], data = SATFRUIT)

Residuals:
    Min      1Q  Median      3Q     Max 
-6395.7  -798.3   301.6  1136.5  4407.9 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 682.10074  793.55584   0.860    0.395    
fruit         0.86005    0.08993   9.564 2.06e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2512 on 45 degrees of freedom
Multiple R-squared:  0.6703,    Adjusted R-squared:  0.6629 
F-statistic: 91.47 on 1 and 45 DF,  p-value: 2.063e-12
\end{verbatim}

\begin{verbatim}

--- Model C Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 6413903 
\end{verbatim}

\begin{verbatim}
CV_5 (5-fold): 6676660 
\end{verbatim}

\begin{verbatim}

--- Model C Statistics ---
\end{verbatim}

\begin{verbatim}
R²: 0.670254 
\end{verbatim}

\begin{verbatim}
Adjusted R²: 0.6629264 
\end{verbatim}

\begin{verbatim}
AIC: 873.2612 
\end{verbatim}

\begin{verbatim}
BIC: 878.8117 
\end{verbatim}

\textbf{Proportion of Total Variability Explained: 67.03\%}

\textbf{Interpretation:}

\begin{itemize}
\item
  \textbf{Approximately two-thirds} (67\%) of the variation in observed
  fruit tree coverage can be explained by satellite-classified fruit
  area alone
\item
  This is a \textbf{strong single-predictor model} - the satellite
  classification is a good predictor by itself
\item
  The remaining \textbf{33\%} of variability is due to:

  \begin{itemize}
  \item
    Measurement errors
  \item
    Misclassification by satellite
  \item
    Other land use factors (grass, olives, almonds, etc.)
  \item
    Small area effects (R63, R67, R68 differences)
  \end{itemize}
\end{itemize}

\subsection{Model (D)}\label{model-d}

Use whichever of Model (A) or (C) has the smaller cross-validation
error, and introduce \texttt{smallarea} into the chosen model. Store the
new model that includes \texttt{smallarea} in \texttt{modelD}.

\paragraph{\texorpdfstring{(i.) Eliminate any variables from
\texttt{modelD} that are not statistically significant (α= 0.10). Store
the resulting model in
\texttt{modelD}.}{(i.) Eliminate any variables from modelD that are not statistically significant (α= 0.10). Store the resulting model in modelD.}}\label{i.-eliminate-any-variables-from-modeld-that-are-not-statistically-significant-ux3b1-0.10.-store-the-resulting-model-in-modeld.}

\begin{verbatim}
Using Model C as base (smaller CV error)
\end{verbatim}

\begin{verbatim}

Initial Model D with smallarea:
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = formula_D, data = SATFRUIT)

Residuals:
    Min      1Q  Median      3Q     Max 
-5719.1  -992.3  -288.0  1486.9  3541.9 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)    433.3831  1212.8829   0.357   0.7226    
fruit            0.9228     0.0836  11.038 3.96e-14 ***
smallareaR67   658.2726  1375.7879   0.478   0.6347    
smallareaR68 -2705.9389  1507.6144  -1.795   0.0797 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2092 on 43 degrees of freedom
Multiple R-squared:  0.7816,    Adjusted R-squared:  0.7663 
F-statistic: 51.29 on 3 and 43 DF,  p-value: 2.955e-14
\end{verbatim}

\begin{verbatim}

Final Model D Summary:
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = observed ~ fruit + smallarea, data = SATFRUIT)

Residuals:
    Min      1Q  Median      3Q     Max 
-5719.1  -992.3  -288.0  1486.9  3541.9 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)    433.3831  1212.8829   0.357   0.7226    
fruit            0.9228     0.0836  11.038 3.96e-14 ***
smallareaR67   658.2726  1375.7879   0.478   0.6347    
smallareaR68 -2705.9389  1507.6144  -1.795   0.0797 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2092 on 43 degrees of freedom
Multiple R-squared:  0.7816,    Adjusted R-squared:  0.7663 
F-statistic: 51.29 on 3 and 43 DF,  p-value: 2.955e-14
\end{verbatim}

\paragraph{(ii.) Compute CVn for modelD. Set the seed to 5 and compute
CV5 for
modelD.}\label{ii.-compute-cvn-for-modeld.-set-the-seed-to-5-and-compute-cv5-for-modeld.}

\begin{verbatim}

--- Model D Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 4663010 
\end{verbatim}

\begin{verbatim}
CV_5 (5-fold): 4934602 
\end{verbatim}

\paragraph{(iii.) Compute R2, R2a, the AIC, and the BIC for Model (D).
What is the proportion of total variability explained by Model
(D)?}\label{iii.-compute-r2-r2a-the-aic-and-the-bic-for-model-d.-what-is-the-proportion-of-total-variability-explained-by-model-d}

\begin{verbatim}

--- Model D Statistics ---
\end{verbatim}

\begin{verbatim}
R²: 0.7815689 
\end{verbatim}

\begin{verbatim}
Adjusted R²: 0.7663295 
\end{verbatim}

\begin{verbatim}
AIC: 857.9042 
\end{verbatim}

\begin{verbatim}
BIC: 867.1549 
\end{verbatim}

\paragraph{(iv.) Does Model (D) have a smaller cross-validation error
than the cross-validation error for either Model (A) or Model
(C)?}\label{iv.-does-model-d-have-a-smaller-cross-validation-error-than-the-cross-validation-error-for-either-model-a-or-model-c}

\begin{verbatim}

--- CV Error Comparison ---
\end{verbatim}

\begin{verbatim}
Model A CV_n: 9131968 
\end{verbatim}

\begin{verbatim}
Model C CV_n: 6413903 
\end{verbatim}

\begin{verbatim}
Model D CV_n: 4663010 
\end{verbatim}

\begin{verbatim}

Does Model D have smaller CV error than both A and C? TRUE 
\end{verbatim}

\paragraph{(v.) Plot the Cook distances, the studentized residuals, the
diagonal elements of the hat matrix, the DFFITS, and DFBETAS1 of Model
(D) versus the
index.}\label{v.-plot-the-cook-distances-the-studentized-residuals-the-diagonal-elements-of-the-hat-matrix-the-dffits-and-dfbetas1-of-model-d-versus-the-index.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-36-1.pdf}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cook's Distance
\end{enumerate}

What it measures: Overall influence of each observation on the model

Interpretation: Most points are below the threshold, indicating no
single observation has excessive influence on the entire model. A few
observations approach the line but don't exceed it significantly.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Studentized Residuals
\end{enumerate}

What it measures: Standardized prediction errors

Interpretation: A few observations exceed ±2 (particularly one around
-3), suggesting some potential outliers in the predictions. However,
these are relatively few and within acceptable limits for a dataset of
this size.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Hat Values (Leverage)
\end{enumerate}

What it measures: How unusual an observation's predictor values are

Interpretation: Three observations (10, 22, 45) exceed this threshold,
meaning they have unusual combinations of predictor values (fruit area
and/or small area category). These are leverage points.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  DFFITS
\end{enumerate}

What it measures: How much fitted values change when an observation is
removed

Interpretation: Most observations fall within bounds, meaning individual
observations don't drastically change their own predicted values when
removed from the model.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  DFBETAS for Intercept
\end{enumerate}

What it measures: How much the intercept coefficient changes when an
observation is removed

Interpretation: A few observations slightly exceed these bounds,
suggesting they have some influence on the intercept, but effects are
modest.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Residuals vs Fitted
\end{enumerate}

What it checks: Linearity and homoscedasticity (constant variance)
Interpretation: Points scatter randomly around zero with relatively
constant spread across fitted values, supporting model assumptions. No
clear patterns or funnel shapes that would indicate problems.

\paragraph{(vi.) Are there any leverage points? Justify the answer
given.}\label{vi.-are-there-any-leverage-points-justify-the-answer-given.}

\begin{verbatim}
Leverage threshold (2p/n): 0.1702128 
\end{verbatim}

\begin{verbatim}
Number of leverage points: 3 
\end{verbatim}

\begin{verbatim}
Leverage points (observations): 10 22 45 
\end{verbatim}

\begin{verbatim}

Justification: These observations have hat values exceeding 2p/n = 0.1702 
\end{verbatim}

\textbf{Justification}

\textbf{Definition of Leverage:}

Leverage (hat values) measures how \textbf{unusual or extreme} an
observation's predictor values are compared to the rest of the data.
High leverage points are observations that are \textbf{far from the
center} of the predictor space.

\textbf{Why These Are Leverage Points:}

These three observations (10, 22, 45) have \textbf{hat values that
exceed the threshold of 0.1702}, meaning they have:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Unusual combinations of predictor values} (likely extreme
  values of \texttt{fruit} and/or unusual \texttt{smallarea}
  combinations)
\item
  \textbf{Greater potential to influence} the fitted regression line
\item
  \textbf{Disproportionate weight} in determining the regression
  coefficients
\end{enumerate}

\textbf{Interpreting the Hat Values from the Plot}

Looking at the \textbf{Hat Values (Leverage)} plot in the image:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\textbf{Observation} & \textbf{Approximate Hat Value} & \textbf{Exceeds
Threshold?} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{\#10} & \textasciitilde{}\textbf{0.35} & ✓ YES (2× threshold) \\
\textbf{\#22} & \textasciitilde{}\textbf{0.35} & ✓ YES (2× threshold) \\
\textbf{\#45} & \textasciitilde{}\textbf{0.35} & ✓ YES (2× threshold) \\
\end{longtable}

All three leverage points have hat values approximately \textbf{0.35},
which is:

\begin{itemize}
\item
  \textbf{More than double} the threshold (0.35 / 0.1702 ≈ 2.06×)
\item
  Among the \textbf{highest leverage values} in the dataset
\end{itemize}

\paragraph{(vii.) Are there any outliers? Justify the answer
given.}\label{vii.-are-there-any-outliers-justify-the-answer-given.}

\begin{verbatim}
Number of outliers (|rstudent| > 2): 2 
\end{verbatim}

\begin{verbatim}
Outliers (observations): 3 46 
\end{verbatim}

\begin{verbatim}

Justification: These observations have studentized residuals with absolute value > 2
Studentized residuals for outliers:
        3        46 
-2.131934 -3.030668 
\end{verbatim}

\textbf{Justification}

\textbf{Definition of Outliers:}

Outliers are observations with \textbf{unusually large residuals} -
their observed values are far from what the model predicts. Studentized
residuals standardize the residuals to account for their varying
standard errors, making them comparable across observations.

\textbf{Why These Are Outliers:}

Both observations \#3 and \#46 have \textbf{studentized residuals with
absolute values exceeding 2}, specifically:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Observation \#3}:

  \begin{itemize}
  \item
    Studentized residual = \textbf{-2.132}
  \item
    Exceeds the threshold of 2 by about \textbf{6.6\%}
  \item
    \textbf{Moderately unusual} observation
  \end{itemize}
\item
  \textbf{Observation \#46}:

  \begin{itemize}
  \item
    Studentized residual = \textbf{-3.031}
  \item
    Exceeds the threshold of 2 by about \textbf{51.5\%}
  \item
    \textbf{Highly unusual} observation - exceeds even the stricter
    threshold of \textbar t\textbar{} \textgreater{} 3
  \end{itemize}
\end{enumerate}

\textbf{Interpretation of Negative Residuals}

\textbf{What Does a Negative Studentized Residual Mean?}

\textbf{Residual = Observed - Predicted}

Since both outliers have \textbf{negative} studentized residuals:

\begin{itemize}
\item
  The \textbf{observed fruit area is LESS than predicted}
\item
  The model \textbf{overpredicts} fruit tree coverage for these segments
\item
  These observations have \textbf{unexpectedly low} observed fruit area
  given their predictor values
\end{itemize}

\textbf{Detailed Analysis by Observation}

\textbf{Observation \#3 (Moderate Outlier):}

\textbf{Studentized Residual}: -2.132

\textbf{Characteristics}:

\begin{itemize}
\item
  Moderately extreme (2-3 standard deviations below expected)
\item
  Model predicts higher fruit coverage than actually observed
\item
  Could indicate:

  \begin{itemize}
  \item
    Satellite \textbf{misclassification} (classified as fruit but
    actually something else)
  \item
    Measurement error in ground observations
  \item
    Genuine unusual case (e.g., recently cleared fruit trees)
  \end{itemize}
\end{itemize}

\textbf{Severity}: Moderate concern

\textbf{Observation \#46 (Severe Outlier):}

\textbf{Studentized Residual}: -3.031

\textbf{Characteristics}:

\begin{itemize}
\item
  \textbf{Highly extreme} (\textgreater3 standard deviations below
  expected)
\item
  This is the \textbf{most problematic outlier} in the dataset
\item
  Only \textbf{\textasciitilde0.3\%} of observations should exceed
  \textbar t\textbar{} \textgreater{} 3 in a normal distribution
\item
  Model \textbf{significantly overpredicts} for this observation
\end{itemize}

\textbf{Possible Explanations}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Data entry error}: Typo in observed or predictor values
\item
  \textbf{Measurement error}: Ground observation was inaccurate
\item
  \textbf{Satellite misclassification}: Large area classified as fruit
  but is not
\item
  \textbf{Temporal mismatch}: Satellite data and ground observation from
  different times
\item
  \textbf{Legitimate unusual case}: Unique characteristics (e.g.,
  diseased orchard, recent harvest)
\end{enumerate}

\textbf{Severity}: High concern - should be investigated

\textbf{Visual Confirmation from Plot}

Looking at the \textbf{Studentized Residuals} plot (top middle of
diagnostic plots):

\textbf{Observations:}

\begin{itemize}
\item
  Most residuals cluster between \textbf{-1 and +1} ✓
\item
  Red dashed lines mark the \textbf{±2 threshold}
\item
  \textbf{Two observations clearly breach the lower threshold}:

  \begin{itemize}
  \item
    One around index 3: residual ≈ \textbf{-2.1} (matches observation
    \#3)
  \item
    One around index 46: residual ≈ \textbf{-3.0} (matches observation
    \#46, labeled in plot)
  \end{itemize}
\item
  \textbf{No observations exceed +2} on the positive side
\item
  The outliers are on the \textbf{negative side only}, indicating
  systematic underprediction for these cases
\end{itemize}

\paragraph{(viii) Check normality and homoscedasticity for Model (D)
using graphics and hypothesis
tests.}\label{viii-check-normality-and-homoscedasticity-for-model-d-using-graphics-and-hypothesis-tests.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-39-1.pdf}}

\begin{verbatim}

Shapiro-Wilk test for normality of residuals:
\end{verbatim}

\begin{verbatim}
W = 0.956806 , p-value = 0.08035332 
\end{verbatim}

\begin{verbatim}
Conclusion: Fail to reject null hypothesis. Residuals appear normally distributed (α=0.05).
\end{verbatim}

\begin{verbatim}

Breusch-Pagan test for homoscedasticity:
\end{verbatim}

\begin{verbatim}
Chi-square = 0.3483938 , df = 1 , p-value = 0.5550237 
\end{verbatim}

\begin{verbatim}
Conclusion: Fail to reject null hypothesis. No evidence of heteroscedasticity (α=0.05).
\end{verbatim}

\textbf{NORMALITY:}

\textbf{Hypothesis Test:}

\textbf{Shapiro-Wilk Test}:

\begin{itemize}
\item
  \textbf{W = 0.9568, p-value = 0.080}
\item
  \textbf{Conclusion}: At α = 0.05, we \textbf{fail to reject the null
  hypothesis}
\item
  \textbf{Interpretation}: The residuals \textbf{appear normally
  distributed}
\end{itemize}

\textbf{Visual Assessment:}

\textbf{Q-Q Plot}:

\begin{itemize}
\item
  Points follow the diagonal line closely throughout most of the range
\item
  Minor deviation in left tail due to outliers (\#3, \#46)
\item
  \textbf{Conclusion}: \textbf{Normality assumption is reasonably
  satisfied}
\end{itemize}

\textbf{HOMOSCEDASTICITY:}

\textbf{Hypothesis Test:}

\textbf{Breusch-Pagan Test}:

\begin{itemize}
\item
  \textbf{χ² = 0.3484, df = 1, p-value = 0.555}
\item
  \textbf{Conclusion}: At α = 0.05, we \textbf{fail to reject the null
  hypothesis}
\item
  \textbf{Interpretation}: \textbf{No evidence of heteroscedasticity} -
  variance is constant
\end{itemize}

\textbf{Visual Assessment:}

\textbf{Residuals vs Fitted Plot}:

\begin{itemize}
\item
  Random scatter around horizontal line at zero
\item
  Constant vertical spread across fitted values
\item
  \textbf{Conclusion}: \textbf{Homoscedasticity assumption is satisfied}
\end{itemize}

\textbf{Scale-Location Plot}:

\begin{itemize}
\item
  Horizontal smoothed line with no strong trend
\item
  Even vertical spread of √\textbar standardized residuals\textbar{}
\item
  \textbf{Conclusion}: \textbf{Confirms constant variance}
\end{itemize}

\textbf{OVERALL CONCLUSION: Both normality and homoscedasticity
assumptions are satisfied for Model D.}

\paragraph{(ix.) Calculate a 95\% confidence interval for the fruit
coefficient.}\label{ix.-calculate-a-95-confidence-interval-for-the-fruit-coefficient.}

\begin{verbatim}
95% Confidence Interval for fruit coefficient:
\end{verbatim}

\begin{verbatim}
          2.5 %   97.5 %
fruit 0.7542251 1.091433
\end{verbatim}

\begin{verbatim}

Interpretation: We are 95% confident that the true coefficient for fruit is between 0.7542 and 1.0914 
\end{verbatim}

\subsubsection{(h) How many hectares of observed fruits are expected to
be incremented if the classified hectares of fruit trees by the
satellite are increased by 10,000 m2 (1
ha)?}\label{h-how-many-hectares-of-observed-fruits-are-expected-to-be-incremented-if-the-classified-hectares-of-fruit-trees-by-the-satellite-are-increased-by-10000-m2-1-ha}

\begin{verbatim}
Fruit coefficient: 0.9228291 
\end{verbatim}

\begin{verbatim}
Expected increase in observed for 10,000 m² increase in classified fruit: 9228.291 m²
\end{verbatim}

\begin{verbatim}
In hectares: 0.9228291 ha
\end{verbatim}

\subsubsection{(i) Suppose the total classified fruits by the satellite
in area R63 is 97,044.28 m2, in area R67 is 4,878,603.43 m2, and in area
R68 is 2,883,488.24 m2. Predict the total area of fruit trees by small
areas.}\label{i-suppose-the-total-classified-fruits-by-the-satellite-in-area-r63-is-97044.28-m2-in-area-r67-is-4878603.43-m2-and-in-area-r68-is-2883488.24-m2.-predict-the-total-area-of-fruit-trees-by-small-areas.}

\begin{verbatim}

Predicted total observed area by small area:
\end{verbatim}

\begin{verbatim}
1 : 89988.66 m² ( 9 ha)
2 : 4503209 m² ( 450.32 ha)
3 : 2658694 m² ( 265.87 ha)
\end{verbatim}

\subsubsection{(j) Create a plot of observed versus fruit with the
points color coded according to small area. Superimpose the
corresponding regression lines for each small
area.}\label{j-create-a-plot-of-observed-versus-fruit-with-the-points-color-coded-according-to-small-area.-superimpose-the-corresponding-regression-lines-for-each-small-area.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-43-1.pdf}}

\textbf{Summary of the Plot:}

The plot successfully displays:

\textbf{Scatterplot}: Observed (y-axis) vs Classified (x-axis) fruit
surface area

\textbf{Color Coding}:

\begin{itemize}
\item
  R63 (red): 2 points, near origin
\item
  R67 (green): \textasciitilde27 points, highest coverage
\item
  R68 (blue): \textasciitilde18 points, intermediate coverage
\end{itemize}

\textbf{Area-Specific Regression Lines}:

\begin{itemize}
\item
  Each small area has its \textbf{own regression line} with different
  slope and intercept
\item
  \textbf{R67 (green)}: Steepest slope, tightest fit
\item
  \textbf{R68 (blue)}: Moderate slope, more scatter
\item
  \textbf{R63 (red)}: Limited data, uncertain relationship
\end{itemize}

\textbf{Confidence Bands}: Shaded regions show 95\% confidence intervals
for each regression line

\textbf{Key Findings:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Strong positive correlation} between satellite-classified and
  ground-observed fruit coverage in all areas
\item
  \textbf{Area-specific relationships} exist:

  \begin{itemize}
  \item
    Different intercepts (baseline fruit coverage)
  \item
    Different slopes (classification accuracy)
  \item
    Different precision (variance around line)
  \end{itemize}
\item
  \textbf{R67 shows best agreement} between satellite and ground data
  (tight clustering)
\item
  \textbf{R68 shows more variability} with several outliers (points far
  below line)
\item
  \textbf{R63 has minimal fruit coverage} with insufficient data for
  reliable estimation
\item
  \textbf{Visual justification for Model D}: The plot demonstrates why
  including \texttt{smallarea} improves predictions---the relationship
  between classified and observed fruit varies systematically across
  regions
\end{enumerate}

\subsubsection{(k) Plot the individual predictions for model D versus
the observed data. Add a diagonal line to the
plot.}\label{k-plot-the-individual-predictions-for-model-d-versus-the-observed-data.-add-a-diagonal-line-to-the-plot.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-44-1.pdf}}

The plot displays \textbf{Model D's predicted values vs.~observed fruit
surface area} with the following elements:

\textbf{Diagonal Reference Line} (red dashed):

\begin{itemize}
\item
  Represents perfect prediction (y = x)
\item
  Points on line = perfect accuracy
\item
  Points above line = underprediction
\item
  Points below line = overprediction
\end{itemize}

\textbf{Color-Coded Points by Small Area}:

\begin{itemize}
\item
  \textbf{R63 (black)}: 2 points near origin and low-mid range
\item
  \textbf{R67 (red)}: \textasciitilde27 points, distributed 0-13,000 m²
\item
  \textbf{R68 (green)}: \textasciitilde18 points, distributed 0-11,000
  m²
\end{itemize}

\textbf{R² = 0.782}: Displayed in plot, indicates 78.2\% of variance
explained

\textbf{Key Findings:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Strong Overall Fit}:

  \begin{itemize}
  \item
    Points cluster tightly around the diagonal line
  \item
    Model D demonstrates \textbf{good predictive accuracy}
  \end{itemize}
\item
  \textbf{Best Performance in R67} (red points):

  \begin{itemize}
  \item
    Extremely tight clustering around diagonal
  \item
    Particularly excellent for predictions \textgreater{} 10,000 m²
  \item
    Very few deviations
  \end{itemize}
\item
  \textbf{Variable Performance in R68} (green points):

  \begin{itemize}
  \item
    More scatter around diagonal
  \item
    \textbf{Two significant outliers} below the line (overpredictions)
  \item
    Less reliable than R67
  \end{itemize}
\item
  \textbf{Limited Data for R63} (black points):

  \begin{itemize}
  \item
    Only 2 points visible
  \item
    Appear to be reasonably accurate
  \item
    Insufficient for strong conclusions
  \end{itemize}
\item
  \textbf{No Systematic Bias}:

  \begin{itemize}
  \item
    Points distributed symmetrically around diagonal
  \item
    Model is \textbf{well-calibrated}
  \item
    Unbiased predictions overall
  \end{itemize}
\item
  \textbf{Accuracy by Range}:

  \begin{itemize}
  \item
    \textbf{High predictions (\textgreater10,000 m²)}: Excellent
    accuracy (±500-1,000 m²)
  \item
    \textbf{Mid predictions (5,000-10,000 m²)}: Good accuracy
    (±1,000-1,500 m²)
  \item
    \textbf{Low predictions (\textless5,000 m²)}: More variable
    (±1,000-2,500 m²)
  \end{itemize}
\end{enumerate}

\textbf{Conclusion:}

The predicted vs.~observed plot provides \textbf{strong visual evidence}
that Model D performs well for predicting fruit tree surface area. The
tight clustering around the diagonal line, particularly for R67,
confirms the model's \textbf{78.2\% variance explained} and its superior
\textbf{cross-validation performance} compared to Models A and C.

While some outliers exist (primarily in R68), the overall pattern
demonstrates that Model D is \textbf{reliable and well-calibrated} for
estimating fruit tree coverage across the small areas of Navarra, with
the best performance in R67 where the most data is available.

\subsubsection{(l) Create a bar plot that displays the predicted area
occupied by fruit trees based on model D for each small area and the
direct estimates of the area occupied by fruit trees by small area
knowing that the total number of classified segments in areas R63, R67,
and R68 are 119, 703, and 564,
respectively.}\label{l-create-a-bar-plot-that-displays-the-predicted-area-occupied-by-fruit-trees-based-on-model-d-for-each-small-area-and-the-direct-estimates-of-the-area-occupied-by-fruit-trees-by-small-area-knowing-that-the-total-number-of-classified-segments-in-areas-r63-r67-and-r68-are-119-703-and-564-respectively.}

\begin{verbatim}
# A tibble: 3 x 5
  smallarea mean_observed n_segments total_direct total_predicted
  <chr>             <dbl>      <dbl>        <dbl>           <dbl>
1 R63               1668.        119      198466.          89989.
2 R67               8346.        703     5867470.        4503209.
3 R68               6364.        564     3589159.        2658694.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-46-1.pdf}}

\textbf{Summary of the Bar Plot:}

The plot compares \textbf{two estimation methods} for predicting total
fruit tree surface area across three small areas (R63, R67, R68):

\textbf{Results Table:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Small Area}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Total Segments}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Direct Estimate (m²)}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Model D Prediction (m²)}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Difference (m²)}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{\% Difference}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{R63} & 119 & 198,466 & 89,989 & +108,477 & +121\% \\
\textbf{R67} & 703 & 5,867,470 & 4,503,209 & +1,364,261 & +30\% \\
\textbf{R68} & 564 & 3,589,159 & 2,658,694 & +930,465 & +35\% \\
\textbf{TOTAL} & 1,386 & \textbf{9,655,095} & \textbf{7,251,892} &
\textbf{+2,403,203} & \textbf{+33\%} \\
\end{longtable}

\textbf{Key Findings:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Direct Estimation Systematically Overestimates}:

  \begin{itemize}
  \item
    Direct method produces \textbf{higher estimates} in all three areas
  \item
    Overestimation ranges from \textbf{30-121\%}
  \item
    Total overestimation: \textbf{240 hectares} (2.4 million m²)
  \end{itemize}
\item
  \textbf{Model D Provides More Conservative Estimates}:

  \begin{itemize}
  \item
    Uses regression with satellite data for \textbf{variance reduction}
  \item
    Accounts for area-specific effects
  \item
    Superior \textbf{cross-validation performance} (lowest CV error)
  \end{itemize}
\item
  \textbf{Largest Discrepancy in R63}:

  \begin{itemize}
  \item
    Direct estimate is \textbf{2.2× higher} than Model D
  \item
    Due to \textbf{very small sample size} (n≈2)
  \item
    Demonstrates \textbf{unreliability of direct method} for small
    samples
  \end{itemize}
\item
  \textbf{Substantial Differences Even in R67}:

  \begin{itemize}
  \item
    Despite having most data (n≈27), estimates differ by \textbf{136 ha}
  \item
    Shows value of \textbf{small area estimation} even with moderate
    samples
  \end{itemize}
\item
  \textbf{Practical Impact}:

  \begin{itemize}
  \item
    Using direct estimates would \textbf{overallocate resources} by 33\%
  \item
    Model D provides \textbf{more accurate, efficient estimates}
  \item
    Critical for policy, planning, and resource management
  \end{itemize}
\end{enumerate}

\textbf{Conclusion:}

The bar plot provides \textbf{compelling visual evidence} for the
superiority of the \textbf{small area estimation approach (Model D)}
over traditional \textbf{direct estimation}. By incorporating satellite
classification data and area-specific effects, Model D produces more
accurate and stable estimates, particularly critical for areas with
small sample sizes like R63. The consistent pattern of overestimation by
the direct method (totaling 240 hectares) demonstrates the practical
value of the regression-based small area estimation methodology
described in this case study.

\section{Case Study 3: Real Estate}\label{case-study-3-real-estate}

\emph{Data and ideas for this case study come from (Militino et al.,
2004).}

The goal of this case study is to walk the user through the creation of
a parsimonious multiple linear regression model that can be used to
predict the total price (\texttt{totalprice}) of apartments by their
hedonic (structural) characteristics. The data frame \texttt{VIT2005}
contains several variables, and further description of the data can be
found in the help file.

\subsubsection{\texorpdfstring{(a) Characterize the shape, center, and
spread of the variable
\texttt{totalprice}.}{(a) Characterize the shape, center, and spread of the variable totalprice.}}\label{a-characterize-the-shape-center-and-spread-of-the-variable-totalprice.}

\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 155000  228500  269750  280742  328625  560000 
\end{verbatim}

\begin{verbatim}

Standard Deviation: 69298.46 
\end{verbatim}

\begin{verbatim}
Variance: 4802276444 
\end{verbatim}

\begin{verbatim}
IQR: 100125 
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-48-1.pdf}}

Shape, Center, and Spread of Total Price

\textbf{Center (Central Tendency)}

\begin{itemize}
\item
  \textbf{Mean}: €280,742
\item
  \textbf{Median}: €269,750
\end{itemize}

The mean is slightly higher than the median (€10,992 difference),
suggesting a slight right skew in the distribution.

\textbf{Spread (Variability)}

\begin{itemize}
\item
  \textbf{Standard Deviation}: €69,298.46
\item
  \textbf{Variance}: €4,802,276,444
\item
  \textbf{Range}: €405,000 (from €155,000 to €560,000)
\item
  \textbf{Interquartile Range (IQR)}: €100,125

  \begin{itemize}
  \item
    \textbf{Q1 (1st Quartile)}: €228,500
  \item
    \textbf{Q3 (3rd Quartile)}: €328,625
  \end{itemize}
\end{itemize}

The relatively large standard deviation (about 25\% of the mean)
indicates substantial variability in apartment prices.

\textbf{Shape (Distribution)}

\textbf{From the Histogram:}

\begin{itemize}
\item
  The distribution is approximately \textbf{bell-shaped} with a slight
  \textbf{right skew} (positive skew)
\item
  Most apartment prices are concentrated between €200,000 and €350,000
\item
  The peak (mode) appears to be around €250,000-€270,000
\item
  There are a few higher-priced apartments extending to €560,000,
  creating the right tail
\end{itemize}

\textbf{From the Boxplot:}

\begin{itemize}
\item
  One clear \textbf{outlier} is visible above the upper whisker (around
  €560,000)
\item
  The box is relatively symmetric, with the median line slightly below
  center
\item
  The upper whisker extends further than the lower whisker, confirming
  right skewness
\end{itemize}

\subsubsection{\texorpdfstring{(b) Use \texttt{scatterplotMatrix()} from
the \texttt{car} package or \texttt{pairs()} to explore the
relationships between \texttt{totalprice} and the numerical explanatory
variables: \texttt{area}, \texttt{age}, \texttt{floor}, \texttt{rooms},
\texttt{toilets}, \texttt{garage}, \texttt{elevator}, and
\texttt{storage}.}{(b) Use scatterplotMatrix() from the car package or pairs() to explore the relationships between totalprice and the numerical explanatory variables: area, age, floor, rooms, toilets, garage, elevator, and storage.}}\label{b-use-scatterplotmatrix-from-the-car-package-or-pairs-to-explore-the-relationships-between-totalprice-and-the-numerical-explanatory-variables-area-age-floor-rooms-toilets-garage-elevator-and-storage.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-49-1.pdf}}

Relationships Between Total Price and Explanatory Variables

\textbf{Strong Positive Relationships:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Area} (strongest relationship)

  \begin{itemize}
  \item
    Clear, strong positive linear relationship with totalprice
  \item
    As area increases, total price increases substantially
  \item
    The scatterplot shows a tight, upward-sloping pattern
  \item
    This appears to be the strongest predictor
  \end{itemize}
\item
  \textbf{Toilets}

  \begin{itemize}
  \item
    Moderate to strong positive relationship
  \item
    More toilets are associated with higher prices
  \item
    Shows a clear upward trend
  \end{itemize}
\item
  \textbf{Rooms}

  \begin{itemize}
  \item
    Positive relationship with totalprice
  \item
    More rooms generally correspond to higher prices
  \item
    Some clustering at discrete values (since rooms is typically a count
    variable)
  \end{itemize}
\end{enumerate}

\textbf{Moderate Positive Relationships:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  \textbf{Floor}

  \begin{itemize}
  \item
    Moderate positive relationship
  \item
    Higher floors tend to have higher prices
  \item
    The relationship appears somewhat linear but with more variability
  \end{itemize}
\item
  \textbf{Garage}

  \begin{itemize}
  \item
    Positive association with price
  \item
    Presence/number of garages relates to higher prices
  \item
    Variable appears to be discrete (0, 1, 2)
  \end{itemize}
\end{enumerate}

\textbf{Weak or Unclear Relationships:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\item
  \textbf{Age}

  \begin{itemize}
  \item
    Weak or possibly negative relationship
  \item
    Newer apartments (lower age) may command higher prices
  \item
    The relationship is not as clear or strong
  \end{itemize}
\item
  \textbf{Elevator}

  \begin{itemize}
  \item
    Appears to be binary (0 or 1)
  \item
    Some positive association - apartments with elevators may be priced
    higher
  \item
    Difficult to assess linearity with binary variable
  \end{itemize}
\item
  \textbf{Storage}

  \begin{itemize}
  \item
    Appears binary or discrete
  \item
    Weak relationship with totalprice
  \item
    Less influential than other variables
  \end{itemize}
\end{enumerate}

\textbf{Key Observations:}

\begin{itemize}
\item
  \textbf{Area} is clearly the dominant predictor with the strongest
  linear relationship
\item
  Several variables show positive correlations, suggesting
  larger/better-equipped apartments cost more
\item
  Some variables (elevator, garage, storage) appear to be
  discrete/binary, which may require special consideration in modeling
\item
  There appears to be multicollinearity potential among predictors
  (e.g., area correlates with rooms and toilets)
\end{itemize}

\subsubsection{\texorpdfstring{(c) Compute the correlation between
\texttt{totalprice} and all of the other numerical variables. List the
three variables in order along with their correlation coefficients that
have the highest correlation with
\texttt{totalprice}.}{(c) Compute the correlation between totalprice and all of the other numerical variables. List the three variables in order along with their correlation coefficients that have the highest correlation with totalprice.}}\label{c-compute-the-correlation-between-totalprice-and-all-of-the-other-numerical-variables.-list-the-three-variables-in-order-along-with-their-correlation-coefficients-that-have-the-highest-correlation-with-totalprice.}

\begin{verbatim}

Top 3 variables by correlation with totalprice:
\end{verbatim}

\begin{verbatim}
1 . area : r = 0.8092125 
2 . toilets : r = 0.6875706 
3 . rooms : r = 0.525627 
\end{verbatim}

\textbf{Interpretation:}

\begin{itemize}
\item
  \textbf{Area} is by far the most important predictor, with a
  correlation nearly 18\% stronger than toilets and 54\% stronger than
  rooms
\item
  All three top correlations are positive, which makes intuitive sense:
  larger apartments with more amenities command higher prices
\item
  The correlations confirm what was observed in the scatterplot matrix
  (Part b)
\item
  These three variables are likely to be the most important predictors
  in the regression models
\end{itemize}

\subsection{Model (A)}\label{model-a-1}

Use backward elimination to develop a model that predicts
\texttt{totalprice} using the data frame \texttt{VIT2005}. Use a
``p-value to remove'' of 5\%. Store the final model in the object
\texttt{modelA}.

\begin{verbatim}
Start:  AIC=4412.62
totalprice ~ area + zone + category + age + floor + rooms + out + 
    conservation + toilets + garage + elevator + streetcategory + 
    heating + storage

                 Df  Sum of Sq        RSS    AIC
- conservation    3 1.0031e+09 8.6894e+10 4409.2
- age             1 3.7563e+06 8.5895e+10 4410.6
- floor           1 3.8440e+07 8.5929e+10 4410.7
<none>                         8.5891e+10 4412.6
- rooms           1 1.0656e+09 8.6956e+10 4413.3
- storage         1 1.6433e+09 8.7534e+10 4414.8
- streetcategory  3 3.5550e+09 8.9446e+10 4415.5
- out             3 3.8946e+09 8.9785e+10 4416.3
- heating         3 4.3202e+09 9.0211e+10 4417.3
- toilets         1 4.7971e+09 9.0688e+10 4422.5
- category        6 9.5199e+09 9.5411e+10 4423.5
- elevator        1 5.4265e+09 9.1317e+10 4424.0
- garage          1 1.4771e+10 1.0066e+11 4445.2
- area            1 4.4519e+10 1.3041e+11 4501.7
- zone           22 1.1171e+11 1.9760e+11 4550.3

Step:  AIC=4409.15
totalprice ~ area + zone + category + age + floor + rooms + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df  Sum of Sq        RSS    AIC
- floor           1 5.9549e+07 8.6953e+10 4407.3
- age             1 3.5042e+08 8.7244e+10 4408.0
<none>                         8.6894e+10 4409.2
- rooms           1 1.0092e+09 8.7903e+10 4409.7
- storage         1 1.4880e+09 8.8382e+10 4410.9
- streetcategory  3 3.7183e+09 9.0612e+10 4412.3
- out             3 3.8374e+09 9.0731e+10 4412.6
- heating         3 4.2447e+09 9.1139e+10 4413.6
- toilets         1 5.0721e+09 9.1966e+10 4419.5
- elevator        1 5.1385e+09 9.2032e+10 4419.7
- category        6 1.0858e+10 9.7752e+10 4422.8
- garage          1 1.5584e+10 1.0248e+11 4443.1
- area            1 4.4285e+10 1.3118e+11 4496.9
- zone           22 1.1188e+11 1.9877e+11 4545.5

Step:  AIC=4407.3
totalprice ~ area + zone + category + age + rooms + out + toilets + 
    garage + elevator + streetcategory + heating + storage

                 Df  Sum of Sq        RSS    AIC
- age             1 3.3429e+08 8.7288e+10 4406.1
<none>                         8.6953e+10 4407.3
- rooms           1 1.0142e+09 8.7968e+10 4407.8
- storage         1 1.4312e+09 8.8385e+10 4408.9
- streetcategory  3 3.6588e+09 9.0612e+10 4410.3
- out             3 3.8396e+09 9.0793e+10 4410.7
- heating         3 4.2829e+09 9.1236e+10 4411.8
- toilets         1 5.0904e+09 9.2044e+10 4417.7
- elevator        1 5.2245e+09 9.2178e+10 4418.0
- category        6 1.1152e+10 9.8105e+10 4421.6
- garage          1 1.5537e+10 1.0249e+11 4441.1
- area            1 4.4227e+10 1.3118e+11 4494.9
- zone           22 1.1657e+11 2.0352e+11 4548.7

Step:  AIC=4406.14
totalprice ~ area + zone + category + rooms + out + toilets + 
    garage + elevator + streetcategory + heating + storage

                 Df  Sum of Sq        RSS    AIC
<none>                         8.7288e+10 4406.1
- rooms           1 1.0246e+09 8.8312e+10 4406.7
- storage         1 1.6695e+09 8.8957e+10 4408.3
- streetcategory  3 3.5484e+09 9.0836e+10 4408.8
- heating         3 3.9987e+09 9.1286e+10 4409.9
- out             3 4.5287e+09 9.1816e+10 4411.2
- toilets         1 5.1432e+09 9.2431e+10 4416.6
- elevator        1 5.7882e+09 9.3076e+10 4418.1
- category        6 1.2678e+10 9.9966e+10 4423.7
- garage          1 1.5621e+10 1.0291e+11 4440.0
- area            1 4.4067e+10 1.3135e+11 4493.2
- zone           22 1.1785e+11 2.0514e+11 4548.4
\end{verbatim}

\begin{verbatim}

Model A Formula: totalprice ~ area + zone + category + rooms + out + toilets +      garage + elevator + streetcategory + heating + storage 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = totalprice ~ area + zone + category + rooms + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage, data = VIT2005)

Residuals:
   Min     1Q Median     3Q    Max 
-69950 -12745   -961  13237  66755 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)       80599.6    26107.1   3.087 0.002351 ** 
area               1322.3      141.1   9.372  < 2e-16 ***
zoneZ21           92150.3    13229.1   6.966 6.45e-11 ***
zoneZ31           77707.2    13945.2   5.572 9.42e-08 ***
zoneZ32           39469.1    12287.0   3.212 0.001569 ** 
zoneZ34           14216.2    15558.2   0.914 0.362114    
zoneZ35           60344.5    14995.8   4.024 8.52e-05 ***
zoneZ36           35853.8    12658.2   2.832 0.005164 ** 
zoneZ37           72839.7    12831.9   5.676 5.65e-08 ***
zoneZ38           22527.3    15681.3   1.437 0.152635    
zoneZ41           51093.9    12166.9   4.199 4.26e-05 ***
zoneZ42           80819.5    15556.6   5.195 5.67e-07 ***
zoneZ43           33210.9    15708.0   2.114 0.035918 *  
zoneZ44           19876.7    15246.7   1.304 0.194067    
zoneZ45           11325.7    12814.3   0.884 0.378007    
zoneZ46            5636.1    13651.0   0.413 0.680208    
zoneZ47          -11740.5    14084.1  -0.834 0.405649    
zoneZ48           32863.5    13988.2   2.349 0.019927 *  
zoneZ49           27986.2    14828.3   1.887 0.060779 .  
zoneZ52            2667.7    12863.1   0.207 0.835945    
zoneZ53           18018.7    12952.8   1.391 0.165968    
zoneZ56           21174.7    14549.4   1.455 0.147371    
zoneZ61           14905.7    12119.1   1.230 0.220383    
zoneZ62           12390.5    12234.2   1.013 0.312571    
category2B        -1008.8    14614.8  -0.069 0.945046    
category3A       -22986.7    14218.7  -1.617 0.107766    
category3B       -27321.2    14602.4  -1.871 0.063023 .  
category4A       -35752.3    15152.9  -2.359 0.019411 *  
category4B       -44969.8    15891.3  -2.830 0.005205 ** 
category5A       -76306.3    24895.8  -3.065 0.002524 ** 
rooms              5018.8     3511.8   1.429 0.154753    
outE25            37676.9    14528.3   2.593 0.010314 *  
outE50            -4121.3     3978.3  -1.036 0.301657    
outE75             4746.9    10384.4   0.457 0.648155    
toilets           18088.7     5649.3   3.202 0.001623 ** 
garage            25448.3     4560.4   5.580 9.06e-08 ***
elevator          19649.7     5784.8   3.397 0.000845 ***
streetcategoryS3  13081.0     5769.9   2.267 0.024614 *  
streetcategoryS4   8462.3     6261.4   1.351 0.178290    
streetcategoryS5  -4864.0    10413.0  -0.467 0.641003    
heating3A         -9733.0    11977.0  -0.813 0.417533    
heating3B         -2219.0    15287.9  -0.145 0.884765    
heating4A          2824.2    12662.7   0.223 0.823768    
storage            8250.5     4522.6   1.824 0.069826 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 22400 on 174 degrees of freedom
Multiple R-squared:  0.9162,    Adjusted R-squared:  0.8955 
F-statistic: 44.26 on 43 and 174 DF,  p-value: < 2.2e-16
\end{verbatim}

\textbf{Model Selection Process:}

The backward elimination procedure removed the following variables (in
order):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Conservation} (Step 1) - Not significant
\item
  \textbf{Age} (Step 2) - Not significant
\item
  \textbf{Floor} (Step 3) - Not significant
\end{enumerate}

\textbf{Final Model A} retained these predictors:

\begin{itemize}
\tightlist
\item
  area, zone, category, rooms, out, toilets, garage, elevator,
  streetcategory, heating, storage
\end{itemize}

\paragraph{\texorpdfstring{(i) Compute \(CV_n\), the leave-one-out cross
validation error, for \texttt{modelA}. Set the seed to 5 and compute
\(CV_5\), the five-fold cross validation error, for \texttt{modelA}. The
cross validation error for a generalized linear model can be computed
using the \texttt{cv.glm()} function from the \texttt{boot} package.
Using the function \texttt{glm()} without passing a family argument is
the same as using the function \texttt{lm()}. R Code 2 provides a
template of how to use the \texttt{cv.glm()} function. Note that
\(CV_n\) is returned with \texttt{cv.error\$delta{[}1{]}}. To compute
\(CV_5\), pass the value 5 to the argument \(K\) inside the
\texttt{cv.glm()}
function.}{(i) Compute CV\_n, the leave-one-out cross validation error, for modelA. Set the seed to 5 and compute CV\_5, the five-fold cross validation error, for modelA. The cross validation error for a generalized linear model can be computed using the cv.glm() function from the boot package. Using the function glm() without passing a family argument is the same as using the function lm(). R Code 2 provides a template of how to use the cv.glm() function. Note that CV\_n is returned with cv.error\$delta{[}1{]}. To compute CV\_5, pass the value 5 to the argument K inside the cv.glm() function.}}\label{i-compute-cv_n-the-leave-one-out-cross-validation-error-for-modela.-set-the-seed-to-5-and-compute-cv_5-the-five-fold-cross-validation-error-for-modela.-the-cross-validation-error-for-a-generalized-linear-model-can-be-computed-using-the-cv.glm-function-from-the-boot-package.-using-the-function-glm-without-passing-a-family-argument-is-the-same-as-using-the-function-lm.-r-code-2-provides-a-template-of-how-to-use-the-cv.glm-function.-note-that-cv_n-is-returned-with-cv.errordelta1.-to-compute-cv_5-pass-the-value-5-to-the-argument-k-inside-the-cv.glm-function.}

\begin{verbatim}
– R Code 2
> mod.glm <- glm(y ~ x1 + x2, data = DF)
> library(boot)
> cv.error <- cv.glm(data = DF, glmfit = mod.glm)
> cv.error$delta[1]
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 640530644 
\end{verbatim}

\begin{verbatim}
CV_5: 647819847 
\end{verbatim}

\begin{itemize}
\item
  \textbf{CV\_n (Leave-One-Out Cross-Validation)}: 640,530,644
\item
  \textbf{CV\_5 (5-Fold Cross-Validation)}: 647,819,847
\end{itemize}

Both CV errors are in squared euros (€²), representing the mean squared
prediction error. The CV\_5 is slightly higher than CV\_n, which is
typical due to the smaller training sets in k-fold CV.

\paragraph{\texorpdfstring{(ii) Compute \(R^2, R^2_a\), the AIC, and the
BIC for Model (A). What is the proportion of total variability explained
by Model
(A)?}{(ii) Compute R\^{}2, R\^{}2\_a, the AIC, and the BIC for Model (A). What is the proportion of total variability explained by Model (A)?}}\label{ii-compute-r2-r2_a-the-aic-and-the-bic-for-model-a.-what-is-the-proportion-of-total-variability-explained-by-model-a}

\begin{verbatim}

--- Model A Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.9162381 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.8955384 
\end{verbatim}

\begin{verbatim}
AIC: 5026.797 
\end{verbatim}

\begin{verbatim}
BIC: 5179.099 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.9162381 
\end{verbatim}

\textbf{Proportion of variability explained}: \textbf{91.62\%}

\textbf{Interpretation:}

\textbf{Model A explains approximately 91.62\% of the total variability
in apartment prices.} This is an excellent fit, indicating that the
selected predictors (11 variables including categorical factors) capture
most of the variation in total price.

The adjusted R² (89.55\%) is slightly lower than R², accounting for the
number of predictors in the model (43 regression coefficients total when
including all factor levels). The relatively small difference between R²
and adjusted R² suggests the model is not overly complex.

\textbf{Key Significant Predictors (p \textless{} 0.05):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Area} (p \textless{} 2e-16): Most important predictor,
  coefficient = €1,322 per m²
\item
  \textbf{Garage} (p = 9.06e-08): €25,448 increase per garage
\item
  \textbf{Toilets} (p = 0.00162): €18,089 per additional toilet
\item
  \textbf{Elevator} (p = 0.000845): €19,650 for having elevator
\item
  \textbf{Zone}: Many zones significantly different from reference
  (e.g., Z21: +€92,150)
\item
  \textbf{Category}: Several categories significantly affect price
\item
  \textbf{Street category S3}: +€13,081
\end{enumerate}

\subsection{Model (B)}\label{model-b-1}

Use the criterion-based procedure AIC, which for linear regression is
equivalent to Mallow's Cp, to develop a model that predicts
\texttt{totalprice} using the variables in \texttt{VIT2005}. Store the
model in the object \texttt{modelB}.

\begin{verbatim}
Start:  AIC=4412.62
totalprice ~ area + zone + category + age + floor + rooms + out + 
    conservation + toilets + garage + elevator + streetcategory + 
    heating + storage

                 Df  Sum of Sq        RSS    AIC
- conservation    3 1.0031e+09 8.6894e+10 4409.2
- age             1 3.7563e+06 8.5895e+10 4410.6
- floor           1 3.8440e+07 8.5929e+10 4410.7
<none>                         8.5891e+10 4412.6
- rooms           1 1.0656e+09 8.6956e+10 4413.3
- storage         1 1.6433e+09 8.7534e+10 4414.8
- streetcategory  3 3.5550e+09 8.9446e+10 4415.5
- out             3 3.8946e+09 8.9785e+10 4416.3
- heating         3 4.3202e+09 9.0211e+10 4417.3
- toilets         1 4.7971e+09 9.0688e+10 4422.5
- category        6 9.5199e+09 9.5411e+10 4423.5
- elevator        1 5.4265e+09 9.1317e+10 4424.0
- garage          1 1.4771e+10 1.0066e+11 4445.2
- area            1 4.4519e+10 1.3041e+11 4501.7
- zone           22 1.1171e+11 1.9760e+11 4550.3

Step:  AIC=4409.15
totalprice ~ area + zone + category + age + floor + rooms + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df  Sum of Sq        RSS    AIC
- floor           1 5.9549e+07 8.6953e+10 4407.3
- age             1 3.5042e+08 8.7244e+10 4408.0
<none>                         8.6894e+10 4409.2
- rooms           1 1.0092e+09 8.7903e+10 4409.7
- storage         1 1.4880e+09 8.8382e+10 4410.9
- streetcategory  3 3.7183e+09 9.0612e+10 4412.3
- out             3 3.8374e+09 9.0731e+10 4412.6
+ conservation    3 1.0031e+09 8.5891e+10 4412.6
- heating         3 4.2447e+09 9.1139e+10 4413.6
- toilets         1 5.0721e+09 9.1966e+10 4419.5
- elevator        1 5.1385e+09 9.2032e+10 4419.7
- category        6 1.0858e+10 9.7752e+10 4422.8
- garage          1 1.5584e+10 1.0248e+11 4443.1
- area            1 4.4285e+10 1.3118e+11 4496.9
- zone           22 1.1188e+11 1.9877e+11 4545.5

Step:  AIC=4407.3
totalprice ~ area + zone + category + age + rooms + out + toilets + 
    garage + elevator + streetcategory + heating + storage

                 Df  Sum of Sq        RSS    AIC
- age             1 3.3429e+08 8.7288e+10 4406.1
<none>                         8.6953e+10 4407.3
- rooms           1 1.0142e+09 8.7968e+10 4407.8
- storage         1 1.4312e+09 8.8385e+10 4408.9
+ floor           1 5.9549e+07 8.6894e+10 4409.2
- streetcategory  3 3.6588e+09 9.0612e+10 4410.3
+ conservation    3 1.0242e+09 8.5929e+10 4410.7
- out             3 3.8396e+09 9.0793e+10 4410.7
- heating         3 4.2829e+09 9.1236e+10 4411.8
- toilets         1 5.0904e+09 9.2044e+10 4417.7
- elevator        1 5.2245e+09 9.2178e+10 4418.0
- category        6 1.1152e+10 9.8105e+10 4421.6
- garage          1 1.5537e+10 1.0249e+11 4441.1
- area            1 4.4227e+10 1.3118e+11 4494.9
- zone           22 1.1657e+11 2.0352e+11 4548.7

Step:  AIC=4406.14
totalprice ~ area + zone + category + rooms + out + toilets + 
    garage + elevator + streetcategory + heating + storage

                 Df  Sum of Sq        RSS    AIC
<none>                         8.7288e+10 4406.1
- rooms           1 1.0246e+09 8.8312e+10 4406.7
+ age             1 3.3429e+08 8.6953e+10 4407.3
+ floor           1 4.3417e+07 8.7244e+10 4408.0
- storage         1 1.6695e+09 8.8957e+10 4408.3
+ conservation    3 1.3563e+09 8.5931e+10 4408.7
- streetcategory  3 3.5484e+09 9.0836e+10 4408.8
- heating         3 3.9987e+09 9.1286e+10 4409.9
- out             3 4.5287e+09 9.1816e+10 4411.2
- toilets         1 5.1432e+09 9.2431e+10 4416.6
- elevator        1 5.7882e+09 9.3076e+10 4418.1
- category        6 1.2678e+10 9.9966e+10 4423.7
- garage          1 1.5621e+10 1.0291e+11 4440.0
- area            1 4.4067e+10 1.3135e+11 4493.2
- zone           22 1.1785e+11 2.0514e+11 4548.4
\end{verbatim}

\begin{verbatim}

Model B Formula: totalprice ~ area + zone + category + rooms + out + toilets +      garage + elevator + streetcategory + heating + storage 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = totalprice ~ area + zone + category + rooms + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage, data = VIT2005)

Residuals:
   Min     1Q Median     3Q    Max 
-69950 -12745   -961  13237  66755 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)       80599.6    26107.1   3.087 0.002351 ** 
area               1322.3      141.1   9.372  < 2e-16 ***
zoneZ21           92150.3    13229.1   6.966 6.45e-11 ***
zoneZ31           77707.2    13945.2   5.572 9.42e-08 ***
zoneZ32           39469.1    12287.0   3.212 0.001569 ** 
zoneZ34           14216.2    15558.2   0.914 0.362114    
zoneZ35           60344.5    14995.8   4.024 8.52e-05 ***
zoneZ36           35853.8    12658.2   2.832 0.005164 ** 
zoneZ37           72839.7    12831.9   5.676 5.65e-08 ***
zoneZ38           22527.3    15681.3   1.437 0.152635    
zoneZ41           51093.9    12166.9   4.199 4.26e-05 ***
zoneZ42           80819.5    15556.6   5.195 5.67e-07 ***
zoneZ43           33210.9    15708.0   2.114 0.035918 *  
zoneZ44           19876.7    15246.7   1.304 0.194067    
zoneZ45           11325.7    12814.3   0.884 0.378007    
zoneZ46            5636.1    13651.0   0.413 0.680208    
zoneZ47          -11740.5    14084.1  -0.834 0.405649    
zoneZ48           32863.5    13988.2   2.349 0.019927 *  
zoneZ49           27986.2    14828.3   1.887 0.060779 .  
zoneZ52            2667.7    12863.1   0.207 0.835945    
zoneZ53           18018.7    12952.8   1.391 0.165968    
zoneZ56           21174.7    14549.4   1.455 0.147371    
zoneZ61           14905.7    12119.1   1.230 0.220383    
zoneZ62           12390.5    12234.2   1.013 0.312571    
category2B        -1008.8    14614.8  -0.069 0.945046    
category3A       -22986.7    14218.7  -1.617 0.107766    
category3B       -27321.2    14602.4  -1.871 0.063023 .  
category4A       -35752.3    15152.9  -2.359 0.019411 *  
category4B       -44969.8    15891.3  -2.830 0.005205 ** 
category5A       -76306.3    24895.8  -3.065 0.002524 ** 
rooms              5018.8     3511.8   1.429 0.154753    
outE25            37676.9    14528.3   2.593 0.010314 *  
outE50            -4121.3     3978.3  -1.036 0.301657    
outE75             4746.9    10384.4   0.457 0.648155    
toilets           18088.7     5649.3   3.202 0.001623 ** 
garage            25448.3     4560.4   5.580 9.06e-08 ***
elevator          19649.7     5784.8   3.397 0.000845 ***
streetcategoryS3  13081.0     5769.9   2.267 0.024614 *  
streetcategoryS4   8462.3     6261.4   1.351 0.178290    
streetcategoryS5  -4864.0    10413.0  -0.467 0.641003    
heating3A         -9733.0    11977.0  -0.813 0.417533    
heating3B         -2219.0    15287.9  -0.145 0.884765    
heating4A          2824.2    12662.7   0.223 0.823768    
storage            8250.5     4522.6   1.824 0.069826 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 22400 on 174 degrees of freedom
Multiple R-squared:  0.9162,    Adjusted R-squared:  0.8955 
F-statistic: 44.26 on 43 and 174 DF,  p-value: < 2.2e-16
\end{verbatim}

Model B: AIC-Based Selection Results

\textbf{Model Selection Process:}

The \texttt{stepAIC} function with AIC criterion (k=2, equivalent to
Mallow's Cp for linear regression) performed \textbf{bidirectional
selection} (both forward and backward steps).

\textbf{Final Model B} includes the same predictors as Model A:

\begin{itemize}
\tightlist
\item
  area, zone, category, rooms, out, toilets, garage, elevator,
  streetcategory, heating, storage
\end{itemize}

\textbf{Note}: Model B is \textbf{identical to Model A}. The AIC-based
stepwise selection and backward elimination both converged to the same
final model, which indicates this is a robust model specification.

\paragraph{\texorpdfstring{(i) Compute \(CV_n\) for \texttt{modelB}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelB}.}{(i) Compute CV\_n for modelB. Set the seed to 5 and compute CV\_5 for modelB.}}\label{i-compute-cv_n-for-modelb.-set-the-seed-to-5-and-compute-cv_5-for-modelb.}

\begin{verbatim}

--- Model B Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 640530644 
\end{verbatim}

\begin{verbatim}
CV_5: 647819847 
\end{verbatim}

\begin{itemize}
\item
  \textbf{CV\_n (Leave-One-Out Cross-Validation)}: 640,530,644
\item
  \textbf{CV\_5 (5-Fold Cross-Validation)}: 647,819,847
\end{itemize}

These values are identical to Model A because both models have the same
predictors.

\paragraph{\texorpdfstring{(ii) Compute \(R^2, R^2_a\), the AIC, and the
BIC for Model (B). What is the proportion of total variability explained
by Model
(B)?}{(ii) Compute R\^{}2, R\^{}2\_a, the AIC, and the BIC for Model (B). What is the proportion of total variability explained by Model (B)?}}\label{ii-compute-r2-r2_a-the-aic-and-the-bic-for-model-b.-what-is-the-proportion-of-total-variability-explained-by-model-b}

\begin{verbatim}

--- Model B Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.9162381 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.8955384 
\end{verbatim}

\begin{verbatim}
AIC: 5026.797 
\end{verbatim}

\begin{verbatim}
BIC: 5179.099 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.9162381 
\end{verbatim}

\textbf{Proportion of variability explained}: \textbf{91.62\%}

\textbf{Interpretation:}

\textbf{Model B explains 91.62\% of the total variability in apartment
prices}, which is excellent predictive performance.

\textbf{Key Findings:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Model Equivalence}: The fact that both backward elimination
  (Model A) and AIC-based selection (Model B) yielded identical models
  provides strong evidence that this variable subset is optimal for
  prediction.
\item
  \textbf{Model Complexity}: With 43 coefficients (including all factor
  levels), the model is reasonably parsimonious given the data size (218
  observations) and achieves high predictive accuracy.
\item
  \textbf{Most Important Predictors} (based on p-values and effect
  sizes):

  \begin{itemize}
  \item
    \textbf{Area}: €1,322 per m² (p \textless{} 2e-16) - strongest
    predictor
  \item
    \textbf{Zone}: Highly significant overall effect
  \item
    \textbf{Garage}: €25,448 per garage (p = 9.06e-08)
  \item
    \textbf{Elevator}: €19,650 premium (p = 0.000845)
  \item
    \textbf{Toilets}: €18,089 per toilet (p = 0.00162)
  \end{itemize}
\item
  \textbf{Variables Not Significant} at α = 0.05:

  \begin{itemize}
  \item
    rooms, heating, some zone and category levels
  \item
    However, they contribute to overall model fit and may improve
    prediction
  \end{itemize}
\end{enumerate}

\subsection{Model (C)}\label{model-c-1}

Use the criterion-based procedure BIC to develop a model that predicts
\texttt{totalprice} using the variables in \texttt{VIT2005}. Store the
model in the object \texttt{modelC}.

\begin{verbatim}
Start:  AIC=4578.46
totalprice ~ area + zone + category + age + floor + rooms + out + 
    conservation + toilets + garage + elevator + streetcategory + 
    heating + storage

                 Df  Sum of Sq        RSS    AIC
- conservation    3 1.0031e+09 8.6894e+10 4564.8
- category        6 9.5199e+09 9.5411e+10 4569.1
- streetcategory  3 3.5550e+09 8.9446e+10 4571.2
- out             3 3.8946e+09 8.9785e+10 4572.0
- heating         3 4.3202e+09 9.0211e+10 4573.0
- age             1 3.7563e+06 8.5895e+10 4573.1
- floor           1 3.8440e+07 8.5929e+10 4573.2
- rooms           1 1.0656e+09 8.6956e+10 4575.8
- storage         1 1.6433e+09 8.7534e+10 4577.2
<none>                         8.5891e+10 4578.5
- toilets         1 4.7971e+09 9.0688e+10 4584.9
- elevator        1 5.4265e+09 9.1317e+10 4586.4
- garage          1 1.4771e+10 1.0066e+11 4607.7
- zone           22 1.1171e+11 1.9760e+11 4641.6
- area            1 4.4519e+10 1.3041e+11 4664.1

Step:  AIC=4564.84
totalprice ~ area + zone + category + age + floor + rooms + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df  Sum of Sq        RSS    AIC
- streetcategory  3 3.7183e+09 9.0612e+10 4557.8
- out             3 3.8374e+09 9.0731e+10 4558.1
- category        6 1.0858e+10 9.7752e+10 4558.2
- heating         3 4.2447e+09 9.1139e+10 4559.1
- floor           1 5.9549e+07 8.6953e+10 4559.6
- age             1 3.5042e+08 8.7244e+10 4560.3
- rooms           1 1.0092e+09 8.7903e+10 4562.0
- storage         1 1.4880e+09 8.8382e+10 4563.2
<none>                         8.6894e+10 4564.8
- toilets         1 5.0721e+09 9.1966e+10 4571.8
- elevator        1 5.1385e+09 9.2032e+10 4572.0
+ conservation    3 1.0031e+09 8.5891e+10 4578.5
- garage          1 1.5584e+10 1.0248e+11 4595.4
- zone           22 1.1188e+11 1.9877e+11 4626.8
- area            1 4.4285e+10 1.3118e+11 4649.2

Step:  AIC=4557.82
totalprice ~ area + zone + category + age + floor + rooms + out + 
    toilets + garage + elevator + heating + storage

                 Df  Sum of Sq        RSS    AIC
- out             3 3.8462e+09 9.4458e+10 4550.7
- category        6 1.1672e+10 1.0228e+11 4551.9
- floor           1 7.5330e+03 9.0612e+10 4552.4
- heating         3 4.7633e+09 9.5376e+10 4552.8
- age             1 2.2348e+08 9.0836e+10 4553.0
- rooms           1 8.6182e+08 9.1474e+10 4554.5
<none>                         9.0612e+10 4557.8
- storage         1 2.5185e+09 9.3131e+10 4558.4
- elevator        1 4.7743e+09 9.5387e+10 4563.6
- toilets         1 5.3006e+09 9.5913e+10 4564.8
+ streetcategory  3 3.7183e+09 8.6894e+10 4564.8
+ conservation    3 1.1664e+09 8.9446e+10 4571.2
- garage          1 1.6104e+10 1.0672e+11 4588.1
- zone           22 1.1352e+11 2.0414e+11 4616.4
- area            1 4.2961e+10 1.3357e+11 4637.0

Step:  AIC=4550.73
totalprice ~ area + zone + category + age + floor + rooms + toilets + 
    garage + elevator + heating + storage

                 Df  Sum of Sq        RSS    AIC
- category        6 1.0064e+10 1.0452e+11 4540.5
- heating         3 4.4784e+09 9.8937e+10 4544.7
- floor           1 4.4199e+05 9.4459e+10 4545.3
- age             1 8.3305e+08 9.5291e+10 4547.3
- rooms           1 1.1733e+09 9.5632e+10 4548.0
<none>                         9.4458e+10 4550.7
- storage         1 2.4846e+09 9.6943e+10 4551.0
- toilets         1 5.1279e+09 9.9586e+10 4556.9
- elevator        1 5.2630e+09 9.9721e+10 4557.2
+ out             3 3.8462e+09 9.0612e+10 4557.8
+ streetcategory  3 3.7271e+09 9.0731e+10 4558.1
+ conservation    3 1.1347e+09 9.3324e+10 4564.2
- garage          1 1.5435e+10 1.0989e+11 4578.3
- zone           22 1.1388e+11 2.0833e+11 4604.7
- area            1 4.2318e+10 1.3678e+11 4626.0

Step:  AIC=4540.49
totalprice ~ area + zone + age + floor + rooms + toilets + garage + 
    elevator + heating + storage

                 Df  Sum of Sq        RSS    AIC
- floor           1 1.3705e+08 1.0466e+11 4535.4
- heating         3 5.9305e+09 1.1045e+11 4536.4
- rooms           1 6.6194e+08 1.0518e+11 4536.5
- storage         1 1.5555e+09 1.0608e+11 4538.3
- age             1 2.3281e+09 1.0685e+11 4539.9
<none>                         1.0452e+11 4540.5
+ streetcategory  3 4.6430e+09 9.9879e+10 4546.7
- elevator        1 7.4871e+09 1.1201e+11 4550.2
+ category        6 1.0064e+10 9.4458e+10 4550.7
+ conservation    3 2.5512e+09 1.0197e+11 4551.3
+ out             3 2.2384e+09 1.0228e+11 4551.9
- toilets         1 1.0294e+10 1.1482e+11 4555.6
- garage          1 1.7960e+10 1.2248e+11 4569.7
- zone           22 1.1872e+11 2.2324e+11 4587.5
- area            1 4.7025e+10 1.5155e+11 4616.1

Step:  AIC=4535.4
totalprice ~ area + zone + age + rooms + toilets + garage + elevator + 
    heating + storage

                 Df  Sum of Sq        RSS    AIC
- rooms           1 6.7193e+08 1.0533e+11 4531.4
- heating         3 6.1579e+09 1.1082e+11 4531.7
- storage         1 1.4340e+09 1.0609e+11 4533.0
- age             1 2.3118e+09 1.0697e+11 4534.8
<none>                         1.0466e+11 4535.4
+ floor           1 1.3705e+08 1.0452e+11 4540.5
+ streetcategory  3 4.4167e+09 1.0024e+11 4542.1
+ category        6 1.0200e+10 9.4459e+10 4545.3
- elevator        1 7.6558e+09 1.1232e+11 4545.4
+ conservation    3 2.5731e+09 1.0209e+11 4546.1
+ out             3 2.2544e+09 1.0240e+11 4546.8
- toilets         1 1.0279e+10 1.1494e+11 4550.4
- garage          1 1.7938e+10 1.2260e+11 4564.5
- zone           22 1.2206e+11 2.2672e+11 4585.5
- area            1 4.6918e+10 1.5158e+11 4610.8

Step:  AIC=4531.41
totalprice ~ area + zone + age + toilets + garage + elevator + 
    heating + storage

                 Df  Sum of Sq        RSS    AIC
- heating         3 6.3621e+09 1.1169e+11 4528.0
- storage         1 1.2973e+09 1.0663e+11 4528.7
- age             1 2.3565e+09 1.0769e+11 4530.8
<none>                         1.0533e+11 4531.4
+ rooms           1 6.7193e+08 1.0466e+11 4535.4
+ floor           1 1.4704e+08 1.0518e+11 4536.5
+ streetcategory  3 4.3749e+09 1.0096e+11 4538.3
+ out             3 2.5178e+09 1.0281e+11 4542.3
+ conservation    3 2.5046e+09 1.0283e+11 4542.3
- elevator        1 8.2036e+09 1.1353e+11 4542.4
+ category        6 9.6971e+09 9.5634e+10 4542.7
- toilets         1 1.0617e+10 1.1595e+11 4547.0
- garage          1 1.7896e+10 1.2323e+11 4560.2
- zone           22 1.2141e+11 2.2674e+11 4580.1
- area            1 6.5892e+10 1.7122e+11 4631.9

Step:  AIC=4528.04
totalprice ~ area + zone + age + toilets + garage + elevator + 
    storage

                 Df  Sum of Sq        RSS    AIC
- age             1 2.2351e+09 1.1393e+11 4527.0
- storage         1 2.4390e+09 1.1413e+11 4527.4
<none>                         1.1169e+11 4528.0
+ heating         3 6.3621e+09 1.0533e+11 4531.4
+ rooms           1 8.7606e+08 1.1082e+11 4531.7
+ floor           1 3.8691e+08 1.1131e+11 4532.7
+ streetcategory  3 5.0417e+09 1.0665e+11 4534.1
+ category        6 1.1326e+10 1.0037e+11 4537.0
+ conservation    3 2.3486e+09 1.0934e+11 4539.6
+ out             3 2.0803e+09 1.0961e+11 4540.1
- elevator        1 1.0574e+10 1.2227e+11 4542.4
- toilets         1 1.1732e+10 1.2343e+11 4544.4
- garage          1 1.7006e+10 1.2870e+11 4553.5
- zone           22 1.1938e+11 2.3107e+11 4568.1
- area            1 7.2822e+10 1.8452e+11 4632.1

Step:  AIC=4526.97
totalprice ~ area + zone + toilets + garage + elevator + storage

                 Df  Sum of Sq        RSS    AIC
<none>                         1.1393e+11 4527.0
+ age             1 2.2351e+09 1.1169e+11 4528.0
- storage         1 3.5733e+09 1.1750e+11 4528.3
+ rooms           1 8.8850e+08 1.1304e+11 4530.6
+ heating         3 6.2407e+09 1.0769e+11 4530.8
+ floor           1 3.9676e+08 1.1353e+11 4531.6
+ category        6 1.3189e+10 1.0074e+11 4532.5
+ streetcategory  3 4.5867e+09 1.0934e+11 4534.2
+ conservation    3 4.4201e+09 1.0951e+11 4534.5
+ out             3 2.7332e+09 1.1120e+11 4537.8
- toilets         1 1.2489e+10 1.2642e+11 4544.3
- elevator        1 1.2766e+10 1.2669e+11 4544.7
- garage          1 1.7837e+10 1.3177e+11 4553.3
- zone           22 1.2501e+11 2.3894e+11 4570.0
- area            1 7.0588e+10 1.8452e+11 4626.7
\end{verbatim}

\begin{verbatim}

Model C Formula: totalprice ~ area + zone + toilets + garage + elevator + storage 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = totalprice ~ area + zone + toilets + garage + elevator + 
    storage, data = VIT2005)

Residuals:
   Min     1Q Median     3Q    Max 
-76233 -12218  -1509  13786  77786 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  41058.3    12936.2   3.174 0.001755 ** 
area          1415.1      130.4  10.850  < 2e-16 ***
zoneZ21     105018.5    13241.7   7.931 1.82e-13 ***
zoneZ31      85239.9    13285.7   6.416 1.09e-09 ***
zoneZ32      44075.5    12084.8   3.647 0.000342 ***
zoneZ34      22238.7    15144.3   1.468 0.143633    
zoneZ35      67174.5    15318.9   4.385 1.92e-05 ***
zoneZ36      41097.8    12870.2   3.193 0.001647 ** 
zoneZ37      72306.2    11931.0   6.060 7.16e-09 ***
zoneZ38      30956.5    15687.5   1.973 0.049909 *  
zoneZ41      62847.8    12118.1   5.186 5.47e-07 ***
zoneZ42      77841.0    14946.0   5.208 4.93e-07 ***
zoneZ43      51543.3    15393.3   3.348 0.000980 ***
zoneZ44      42801.9    15150.4   2.825 0.005231 ** 
zoneZ45      23963.2    12257.6   1.955 0.052054 .  
zoneZ46      19512.1    12567.7   1.553 0.122195    
zoneZ47       7852.8    13109.2   0.599 0.549868    
zoneZ48      42480.1    13699.7   3.101 0.002224 ** 
zoneZ49      36348.8    14856.2   2.447 0.015326 *  
zoneZ52       8434.1    12391.3   0.681 0.496927    
zoneZ53      28170.5    12668.9   2.224 0.027354 *  
zoneZ56      42421.2    13854.4   3.062 0.002518 ** 
zoneZ61      26489.4    11967.2   2.214 0.028053 *  
zoneZ62      25325.1    11276.6   2.246 0.025867 *  
toilets      25559.3     5600.5   4.564 9.00e-06 ***
garage       26542.0     4866.4   5.454 1.52e-07 ***
elevator     26776.4     5803.2   4.614 7.25e-06 ***
storage      11078.6     4538.3   2.441 0.015556 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 24490 on 190 degrees of freedom
Multiple R-squared:  0.8907,    Adjusted R-squared:  0.8751 
F-statistic: 57.33 on 27 and 190 DF,  p-value: < 2.2e-16
\end{verbatim}

Model C: BIC-Based Selection Results

\textbf{Model Selection Process:}

The \texttt{stepAIC} function with BIC criterion (k = log(n) = log(218)
≈ 5.38) performed \textbf{bidirectional selection}.

The BIC criterion penalizes model complexity more heavily than AIC,
leading to a \textbf{more parsimonious model}.

\textbf{Variables removed} (in order):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Conservation} (Step 1)
\item
  \textbf{Streetcategory} (Step 2)
\item
  \textbf{Out} (Step 3)
\item
  \textbf{Category} (Step 4)
\item
  \textbf{Floor} (Step 5)
\item
  \textbf{Rooms} (Step 6)
\item
  \textbf{Heating} (Step 7)
\item
  \textbf{Age} (Step 8)
\end{enumerate}

\textbf{Final Model C} includes only \textbf{6 predictors}:

\begin{itemize}
\tightlist
\item
  area, zone, toilets, garage, elevator, storage
\end{itemize}

This is a \textbf{much simpler model} than Models A and B (which had 11
predictors).

\paragraph{\texorpdfstring{(i) Compute \(CV_n\) for \texttt{modelC}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelC}.}{(i) Compute CV\_n for modelC. Set the seed to 5 and compute CV\_5 for modelC.}}\label{i-compute-cv_n-for-modelc.-set-the-seed-to-5-and-compute-cv_5-for-modelc.}

\begin{verbatim}

--- Model C Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 694979921 
\end{verbatim}

\begin{verbatim}
CV_5: 726604599 
\end{verbatim}

\begin{itemize}
\item
  \textbf{CV\_n (Leave-One-Out Cross-Validation)}: 694,979,921
\item
  \textbf{CV\_5 (5-Fold Cross-Validation)}: 726,604,599
\end{itemize}

\textbf{Note}: Model C has \textbf{higher CV errors} than Models A and
B, indicating somewhat worse out-of-sample prediction performance, which
is the trade-off for the simpler model.

\paragraph{\texorpdfstring{(ii) Compute \(R^2, R^2_a\), the AIC, and the
BIC for Model (C). What is the proportion of total variability explained
by Model
(C)?}{(ii) Compute R\^{}2, R\^{}2\_a, the AIC, and the BIC for Model (C). What is the proportion of total variability explained by Model (C)?}}\label{ii-compute-r2-r2_a-the-aic-and-the-bic-for-model-c.-what-is-the-proportion-of-total-variability-explained-by-model-c}

\begin{verbatim}

--- Model C Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.8906736 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.8751377 
\end{verbatim}

\begin{verbatim}
AIC: 5052.864 
\end{verbatim}

\begin{verbatim}
BIC: 5151.014 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.8906736 
\end{verbatim}

\textbf{Proportion of variability explained}: \textbf{89.07\%}

\textbf{Interpretation:}

\textbf{Model C explains 89.07\% of the total variability in apartment
prices}, which is still very good, though slightly less than Models A
and B (91.62\%).

\textbf{Key Findings:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Parsimony vs.~Fit Trade-off}: Model C sacrifices about 2.5\%
  of explained variance to achieve a much simpler model with 16 fewer
  coefficients.
\item
  \textbf{BIC Preference}: Model C has the \textbf{lowest BIC} (5151.014
  vs 5179.099), making it the preferred model by the BIC criterion,
  which values simplicity.
\item
  \textbf{Significant Predictors} (all p \textless{} 0.05):

  \begin{itemize}
  \item
    \textbf{Area}: €1,415 per m² (p \textless{} 2e-16) - strongest
    predictor
  \item
    \textbf{Garage}: €26,542 per garage (p = 1.52e-07)
  \item
    \textbf{Elevator}: €26,776 premium (p = 7.25e-06)
  \item
    \textbf{Toilets}: €25,559 per toilet (p = 9.00e-06)
  \item
    \textbf{Storage}: €11,079 premium (p = 0.0156)
  \item
    \textbf{Zone}: Highly significant overall effect
  \end{itemize}
\item
  \textbf{Practical Advantages}:

  \begin{itemize}
  \item
    Easier to interpret and communicate
  \item
    More stable predictions (less prone to overfitting)
  \item
    Requires fewer variables to collect/input
  \end{itemize}
\item
  \textbf{Prediction Performance}: While CV errors are about 8.5\%
  higher than Models A/B, the model still provides excellent predictions
  with much less complexity.
\end{enumerate}

\textbf{Conclusion}: Model C offers an excellent balance between
predictive accuracy and model simplicity, making it attractive for
practical applications where parsimony is valued.

\subsection{Model (D)}\label{model-d-1}

Use forward selection to develop a model that predicts
\texttt{totalprice} using the variables in \texttt{VIT2005}. Use a
``p-value to add'' of 5\%. Store the final model in the object
\texttt{modelD}.

\begin{verbatim}
Start:  AIC=4860.73
totalprice ~ 1

                 Df  Sum of Sq        RSS    AIC
+ area            1 6.8239e+11 3.5970e+11 4630.8
+ zone           22 6.2786e+11 4.1424e+11 4703.6
+ toilets         1 4.9265e+11 5.4944e+11 4723.2
+ category        6 3.8142e+11 6.6068e+11 4773.4
+ rooms           1 2.8791e+11 7.5418e+11 4792.2
+ garage          1 2.8585e+11 7.5624e+11 4792.8
+ elevator        1 2.7205e+11 7.7005e+11 4796.8
+ heating         3 1.6150e+11 8.8059e+11 4830.0
+ streetcategory  3 1.2246e+11 9.1963e+11 4839.5
+ age             1 7.7353e+10 9.6474e+11 4845.9
+ conservation    3 9.4240e+10 9.4785e+11 4846.1
+ storage         1 7.4489e+10 9.6760e+11 4846.6
<none>                         1.0421e+12 4860.7
+ floor           1 8.8974e+08 1.0412e+12 4862.5
+ out             3 1.5831e+10 1.0263e+12 4863.4

Step:  AIC=4630.84
totalprice ~ area

                 Df  Sum of Sq        RSS    AIC
+ zone           22 1.7960e+11 1.8010e+11 4524.0
+ category        6 9.3970e+10 2.6573e+11 4576.8
+ garage          1 6.8073e+10 2.9163e+11 4587.1
+ toilets         1 5.6364e+10 3.0334e+11 4595.7
+ age             1 5.5354e+10 3.0435e+11 4596.4
+ elevator        1 4.5308e+10 3.1440e+11 4603.5
+ conservation    3 3.6835e+10 3.2287e+11 4613.3
+ storage         1 2.2452e+10 3.3725e+11 4618.8
+ heating         3 2.5654e+10 3.3405e+11 4620.7
<none>                         3.5970e+11 4630.8
+ floor           1 1.4251e+09 3.5828e+11 4632.0
+ rooms           1 1.4929e+08 3.5956e+11 4632.8
+ out             3 5.1247e+09 3.5458e+11 4633.7
+ streetcategory  3 1.5886e+09 3.5812e+11 4635.9

Step:  AIC=4524.04
totalprice ~ area + zone

                 Df  Sum of Sq        RSS    AIC
+ garage          1 3.2856e+10 1.4725e+11 4482.1
+ category        6 3.7898e+10 1.4221e+11 4484.5
+ toilets         1 2.8406e+10 1.5170e+11 4488.6
+ elevator        1 2.0964e+10 1.5914e+11 4499.1
+ conservation    3 1.5083e+10 1.6502e+11 4511.0
+ age             1 1.1794e+10 1.6831e+11 4511.3
+ heating         3 1.2792e+10 1.6731e+11 4514.0
+ storage         1 7.0505e+09 1.7305e+11 4517.3
+ streetcategory  3 7.0112e+09 1.7309e+11 4521.4
+ rooms           1 2.4153e+09 1.7769e+11 4523.1
<none>                         1.8010e+11 4524.0
+ floor           1 2.1117e+08 1.7989e+11 4525.8
+ out             3 1.0513e+09 1.7905e+11 4528.8

Step:  AIC=4482.13
totalprice ~ area + zone + garage

                 Df  Sum of Sq        RSS    AIC
+ category        6 2.6933e+10 1.2032e+11 4450.1
+ toilets         1 1.6516e+10 1.3073e+11 4458.2
+ elevator        1 1.6358e+10 1.3089e+11 4458.5
+ heating         3 1.2552e+10 1.3470e+11 4468.7
+ age             1 8.0663e+09 1.3918e+11 4471.9
+ conservation    3 9.5253e+09 1.3772e+11 4473.6
+ storage         1 5.1715e+09 1.4208e+11 4476.3
+ streetcategory  3 6.5779e+09 1.4067e+11 4478.2
+ rooms           1 2.2030e+09 1.4505e+11 4480.8
<none>                         1.4725e+11 4482.1
+ floor           1 2.8860e+08 1.4696e+11 4483.7
+ out             3 2.0387e+09 1.4521e+11 4485.1

Step:  AIC=4450.1
totalprice ~ area + zone + garage + category

                 Df  Sum of Sq        RSS    AIC
+ elevator        1 1.0192e+10 1.1012e+11 4432.8
+ toilets         1 6.6314e+09 1.1368e+11 4439.7
+ heating         3 7.3042e+09 1.1301e+11 4442.4
+ storage         1 4.2321e+09 1.1608e+11 4444.3
+ out             3 5.6366e+09 1.1468e+11 4445.6
+ streetcategory  3 5.2963e+09 1.1502e+11 4446.3
+ rooms           1 2.5576e+09 1.1776e+11 4447.4
+ age             1 1.7261e+09 1.1859e+11 4448.9
<none>                         1.2032e+11 4450.1
+ floor           1 9.2505e+05 1.2031e+11 4452.1
+ conservation    3 1.5615e+09 1.1875e+11 4453.2

Step:  AIC=4432.8
totalprice ~ area + zone + garage + category + elevator

                 Df  Sum of Sq        RSS    AIC
+ toilets         1 6073243761 1.0405e+11 4422.4
+ storage         1 3694847210 1.0643e+11 4427.4
+ streetcategory  3 5617271088 1.0451e+11 4427.4
+ heating         3 5056597855 1.0507e+11 4428.6
+ out             3 4328922592 1.0579e+11 4430.1
+ rooms           1 1548114686 1.0857e+11 4431.7
<none>                         1.1012e+11 4432.8
+ age             1  815586409 1.0931e+11 4433.2
+ floor           1   27424777 1.1010e+11 4434.7
+ conservation    3 1689461578 1.0843e+11 4435.4

Step:  AIC=4422.43
totalprice ~ area + zone + garage + category + elevator + toilets

                 Df  Sum of Sq        RSS    AIC
+ streetcategory  3 5418285673 9.8631e+10 4416.8
+ storage         1 3309776001 1.0074e+11 4417.4
+ heating         3 4760850186 9.9289e+10 4418.2
+ out             3 4583711290 9.9466e+10 4418.6
+ rooms           1 1211766335 1.0284e+11 4421.9
<none>                         1.0405e+11 4422.4
+ age             1  822533955 1.0323e+11 4422.7
+ floor           1   29736792 1.0402e+11 4424.4
+ conservation    3 1482925524 1.0257e+11 4425.3

Step:  AIC=4416.77
totalprice ~ area + zone + garage + category + elevator + toilets + 
    streetcategory

               Df  Sum of Sq        RSS    AIC
+ out           3 4524673955 9.4107e+10 4412.5
+ heating       3 3852555776 9.4779e+10 4414.1
+ storage       1 1867448090 9.6764e+10 4414.6
+ rooms         1 1395688014 9.7236e+10 4415.7
+ age           1  904901916 9.7726e+10 4416.8
<none>                       9.8631e+10 4416.8
+ floor         1   15504079 9.8616e+10 4418.7
+ conservation  3 1502791224 9.7129e+10 4419.4

Step:  AIC=4412.54
totalprice ~ area + zone + garage + category + elevator + toilets + 
    streetcategory + out

               Df  Sum of Sq        RSS    AIC
+ heating       3 4293510190 8.9813e+10 4408.4
+ storage       1 1650832431 9.2456e+10 4410.7
+ rooms         1 1030410231 9.3076e+10 4412.1
<none>                       9.4107e+10 4412.5
+ age           1  205646048 9.3901e+10 4414.1
+ floor         1   16494660 9.4090e+10 4414.5
+ conservation  3  923168465 9.3184e+10 4416.4

Step:  AIC=4408.36
totalprice ~ area + zone + garage + category + elevator + toilets + 
    streetcategory + out + heating

               Df  Sum of Sq        RSS    AIC
+ storage       1 1500802958 8.8312e+10 4406.7
+ rooms         1  855932825 8.8957e+10 4408.3
<none>                       8.9813e+10 4408.4
+ age           1  571066275 8.9242e+10 4409.0
+ floor         1      59593 8.9813e+10 4410.4
+ conservation  3 1340139301 8.8473e+10 4411.1

Step:  AIC=4406.68
totalprice ~ area + zone + garage + category + elevator + toilets + 
    streetcategory + out + heating + storage

               Df  Sum of Sq        RSS    AIC
+ rooms         1 1024619187 8.7288e+10 4406.1
<none>                       8.8312e+10 4406.7
+ age           1  344698909 8.7968e+10 4407.8
+ floor         1   47513213 8.8265e+10 4408.6
+ conservation  3 1310618800 8.7002e+10 4409.4

Step:  AIC=4406.14
totalprice ~ area + zone + garage + category + elevator + toilets + 
    streetcategory + out + heating + storage + rooms

               Df  Sum of Sq        RSS    AIC
<none>                       8.7288e+10 4406.1
+ age           1  334291272 8.6953e+10 4407.3
+ floor         1   43416755 8.7244e+10 4408.0
+ conservation  3 1356302210 8.5931e+10 4408.7
\end{verbatim}

\begin{verbatim}

Model D Formula: totalprice ~ area + zone + garage + category + elevator + toilets +      streetcategory + out + heating + storage + rooms 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = totalprice ~ area + zone + garage + category + elevator + 
    toilets + streetcategory + out + heating + storage + rooms, 
    data = VIT2005)

Residuals:
   Min     1Q Median     3Q    Max 
-69950 -12745   -961  13237  66755 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)       80599.6    26107.1   3.087 0.002351 ** 
area               1322.3      141.1   9.372  < 2e-16 ***
zoneZ21           92150.3    13229.1   6.966 6.45e-11 ***
zoneZ31           77707.2    13945.2   5.572 9.42e-08 ***
zoneZ32           39469.1    12287.0   3.212 0.001569 ** 
zoneZ34           14216.2    15558.2   0.914 0.362114    
zoneZ35           60344.5    14995.8   4.024 8.52e-05 ***
zoneZ36           35853.8    12658.2   2.832 0.005164 ** 
zoneZ37           72839.7    12831.9   5.676 5.65e-08 ***
zoneZ38           22527.3    15681.3   1.437 0.152635    
zoneZ41           51093.9    12166.9   4.199 4.26e-05 ***
zoneZ42           80819.5    15556.6   5.195 5.67e-07 ***
zoneZ43           33210.9    15708.0   2.114 0.035918 *  
zoneZ44           19876.7    15246.7   1.304 0.194067    
zoneZ45           11325.7    12814.3   0.884 0.378007    
zoneZ46            5636.1    13651.0   0.413 0.680208    
zoneZ47          -11740.5    14084.1  -0.834 0.405649    
zoneZ48           32863.5    13988.2   2.349 0.019927 *  
zoneZ49           27986.2    14828.3   1.887 0.060779 .  
zoneZ52            2667.7    12863.1   0.207 0.835945    
zoneZ53           18018.7    12952.8   1.391 0.165968    
zoneZ56           21174.7    14549.4   1.455 0.147371    
zoneZ61           14905.7    12119.1   1.230 0.220383    
zoneZ62           12390.5    12234.2   1.013 0.312571    
garage            25448.3     4560.4   5.580 9.06e-08 ***
category2B        -1008.8    14614.8  -0.069 0.945046    
category3A       -22986.7    14218.7  -1.617 0.107766    
category3B       -27321.2    14602.4  -1.871 0.063023 .  
category4A       -35752.3    15152.9  -2.359 0.019411 *  
category4B       -44969.8    15891.3  -2.830 0.005205 ** 
category5A       -76306.3    24895.8  -3.065 0.002524 ** 
elevator          19649.7     5784.8   3.397 0.000845 ***
toilets           18088.7     5649.3   3.202 0.001623 ** 
streetcategoryS3  13081.0     5769.9   2.267 0.024614 *  
streetcategoryS4   8462.3     6261.4   1.351 0.178290    
streetcategoryS5  -4864.0    10413.0  -0.467 0.641003    
outE25            37676.9    14528.3   2.593 0.010314 *  
outE50            -4121.3     3978.3  -1.036 0.301657    
outE75             4746.9    10384.4   0.457 0.648155    
heating3A         -9733.0    11977.0  -0.813 0.417533    
heating3B         -2219.0    15287.9  -0.145 0.884765    
heating4A          2824.2    12662.7   0.223 0.823768    
storage            8250.5     4522.6   1.824 0.069826 .  
rooms              5018.8     3511.8   1.429 0.154753    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 22400 on 174 degrees of freedom
Multiple R-squared:  0.9162,    Adjusted R-squared:  0.8955 
F-statistic: 44.26 on 43 and 174 DF,  p-value: < 2.2e-16
\end{verbatim}

Model D: Forward Selection Results

\textbf{Model Selection Process:}

Forward selection started with an \textbf{intercept-only model} and
sequentially added variables that most improved the model fit (reduced
AIC).

\textbf{Variables added} (in order):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Area} (Step 1) - Strongest single predictor
\item
  \textbf{Zone} (Step 2)
\item
  \textbf{Garage} (Step 3)
\item
  \textbf{Category} (Step 4)
\item
  \textbf{Elevator} (Step 5)
\item
  \textbf{Toilets} (Step 6)
\item
  \textbf{Streetcategory} (Step 7)
\item
  \textbf{Out} (Step 8)
\item
  \textbf{Heating} (Step 9)
\item
  \textbf{Storage} (Step 10)
\item
  \textbf{Rooms} (Step 11) - Final variable added
\end{enumerate}

\textbf{Final Model D} includes:

\begin{itemize}
\tightlist
\item
  area, zone, garage, category, elevator, toilets, streetcategory, out,
  heating, storage, rooms
\end{itemize}

\textbf{Key Finding:}

\textbf{Model D is IDENTICAL to Models A and B!}

All three selection methods (backward elimination, AIC-based stepwise,
and forward selection) converged to the \textbf{exact same model}, which
provides very strong evidence that this is the optimal variable subset.

\paragraph{\texorpdfstring{(i) Compute \(CV_n\) for \texttt{modelD}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelD}.}{(i) Compute CV\_n for modelD. Set the seed to 5 and compute CV\_5 for modelD.}}\label{i-compute-cv_n-for-modeld.-set-the-seed-to-5-and-compute-cv_5-for-modeld.}

\begin{verbatim}

--- Model D Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 640530644 
\end{verbatim}

\begin{verbatim}
CV_5: 647819847 
\end{verbatim}

\begin{itemize}
\item
  \textbf{CV\_n (Leave-One-Out Cross-Validation)}: 640,530,644
\item
  \textbf{CV\_5 (5-Fold Cross-Validation)}: 647,819,847
\end{itemize}

These are identical to Models A and B (as expected, since it's the same
model).

\paragraph{\texorpdfstring{(ii) Compute the \(R^2, R^2_a\), AIC, and the
BIC for Model (D). What is the proportion of total variability explained
by Model
(D)?}{(ii) Compute the R\^{}2, R\^{}2\_a, AIC, and the BIC for Model (D). What is the proportion of total variability explained by Model (D)?}}\label{ii-compute-the-r2-r2_a-aic-and-the-bic-for-model-d.-what-is-the-proportion-of-total-variability-explained-by-model-d}

\begin{verbatim}

--- Model D Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.9162381 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.8955384 
\end{verbatim}

\begin{verbatim}
AIC: 5026.797 
\end{verbatim}

\begin{verbatim}
BIC: 5179.099 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.9162381 
\end{verbatim}

\textbf{Proportion of variability explained}: \textbf{91.62\%}

\textbf{Interpretation:}

\textbf{Model D explains 91.62\% of the total variability in apartment
prices.}

\textbf{All metrics are identical} because all three methods selected
the same model.

\textbf{Significance:}

The convergence of three different selection approaches to the
\textbf{same final model} is remarkable and indicates:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Model Stability}: The selected variable subset is robust and
  not dependent on the selection algorithm used
\item
  \textbf{Clear Signal}: The data has a clear structure with
  well-defined important predictors
\item
  \textbf{Optimal Balance}: This model represents an optimal trade-off
  between fit and complexity using the AIC criterion
\item
  \textbf{High Confidence}: We can be highly confident this is the
  ``right'' model for prediction purposes using p-value-based criteria
  (α = 0.05)
\end{enumerate}

\textbf{Most Important Predictors} (same as Models A and B):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Area}: €1,322 per m² (p \textless{} 2e-16)
\item
  \textbf{Garage}: €25,448 per garage (p = 9.06e-08)
\item
  \textbf{Elevator}: €19,650 premium (p = 0.000845)
\item
  \textbf{Toilets}: €18,089 per toilet (p = 0.00162)
\item
  \textbf{Zone}: Multiple zones significantly affect price
\end{enumerate}

\subsubsection{\texorpdfstring{(d) Explore the residuals of the Models
(A), (B), (C), and (D) using the function \texttt{residualPlot()} or
\texttt{residualPlots()} from the package \texttt{car}. Comment on the
results.}{(d) Explore the residuals of the Models (A), (B), (C), and (D) using the function residualPlot() or residualPlots() from the package car. Comment on the results.}}\label{d-explore-the-residuals-of-the-models-a-b-c-and-d-using-the-function-residualplot-or-residualplots-from-the-package-car.-comment-on-the-results.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-63-1.pdf}}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-63-2.pdf}}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-63-3.pdf}}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-63-4.pdf}}

\begin{verbatim}

Comment: Examine residual plots for patterns, non-constant variance,
\end{verbatim}

\begin{verbatim}
and departures from normality.
\end{verbatim}

Part (d): Residual Analysis for Models A-D

\textbf{Models A, B, and D (Identical Models)}

Since Models A, B, and D are identical, they have the same residual
plots. Here are the findings:

\textbf{1. Residuals vs Fitted Plot:}

\begin{itemize}
\item
  \textbf{Pattern observed}: Residuals show a \textbf{slight funnel
  shape} (heteroscedasticity)
\item
  Residuals spread increases slightly as fitted values increase
\item
  There's a \textbf{slight upward trend} (red line slopes upward),
  suggesting the model may slightly underpredict at higher price ranges
\item
  \textbf{Outliers identified}: Observations 116, 130, and 156 stand out
\end{itemize}

\textbf{2. Q-Q Plot (Normal Q-Q):}

\begin{itemize}
\item
  \textbf{Generally good}: Points follow the theoretical line reasonably
  well in the middle
\item
  \textbf{Deviations at extremes}:

  \begin{itemize}
  \item
    Lower tail shows some deviation (observations like 156)
  \item
    Upper tail shows more pronounced deviation (observations 130, 136,
    160)
  \end{itemize}
\item
  \textbf{Conclusion}: Minor departures from normality, primarily in the
  tails
\end{itemize}

\textbf{3. Scale-Location Plot:}

\begin{itemize}
\item
  Shows \textbf{increasing spread} of standardized residuals as fitted
  values increase
\item
  \textbf{Confirms heteroscedasticity}: Variance is not constant across
  the range of fitted values
\item
  Red line shows upward trend, indicating variance increases with
  predicted price
\end{itemize}

\textbf{4. Cook's Distance Plot:}

\begin{itemize}
\item
  \textbf{Influential observations}: 43, 93, and 116 show notably higher
  Cook's distances
\item
  Most observations have low Cook's distance (\textless{} 0.10)
\item
  No observations exceed the common threshold of 0.5, but some warrant
  attention
\end{itemize}

\textbf{Model C (Simpler BIC Model)}

Model C shows similar patterns but with some differences:

\textbf{1. Residuals vs Fitted:}

\begin{itemize}
\item
  \textbf{More random scatter} compared to Models A/B/D
\item
  Still shows slight heteroscedasticity with increasing variance
\item
  \textbf{Different outliers}: Observations 130, 156, 207 are notable
\end{itemize}

\textbf{2. Q-Q Plot:}

\begin{itemize}
\item
  \textbf{Similar to A/B/D}: Good fit in the middle, deviations in tails
\item
  Observations 130 and 156 deviate in upper tail
\end{itemize}

\textbf{3. Scale-Location Plot:}

\begin{itemize}
\item
  Shows \textbf{less pronounced heteroscedasticity} pattern than Models
  A/B/D
\item
  Observations 130, 156, and 207 stand out
\end{itemize}

\textbf{4. Cook's Distance:}

\begin{itemize}
\item
  \textbf{Different influential points}: Observations 31, 43, and 156
  show higher influence
\item
  Generally lower Cook's distances overall compared to Models A/B/D
\end{itemize}

\textbf{Overall Comments:}

\textbf{Common Issues Across All Models:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Heteroscedasticity}: All models show evidence of non-constant
  variance, with larger residuals for higher-priced apartments. This
  violates the homoscedasticity assumption.
\item
  \textbf{Near-Normality}: Residuals are approximately normal but with
  heavier tails than expected, particularly in the upper tail. This is
  common with price data.
\item
  \textbf{Potential Outliers}: Observations 130, 156, and others
  consistently appear as outliers across models
\item
  \textbf{Model Adequacy}: Despite the violations, the patterns are
  relatively mild and the models still provide good fits
\end{enumerate}

\textbf{Key Differences:}

\begin{itemize}
\item
  \textbf{Models A/B/D}: Better fit (higher R²) but show more pronounced
  heteroscedasticity
\item
  \textbf{Model C}: Simpler model with slightly worse fit but comparable
  residual patterns
\end{itemize}

\subsubsection{\texorpdfstring{(e) Use the function \texttt{boxCox()}
from \texttt{car} to find a suitable transformation for
\texttt{totalprice}.}{(e) Use the function boxCox() from car to find a suitable transformation for totalprice.}}\label{e-use-the-function-boxcox-from-car-to-find-a-suitable-transformation-for-totalprice.}

\begin{verbatim}


=== PART (e): Box-Cox Transformation ===
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-64-1.pdf}}

\begin{verbatim}
Optimal lambda: 0.06060606 
\end{verbatim}

\begin{verbatim}
Interpretation: Lambda near 0 suggests log transformation is appropriate.
\end{verbatim}

Part (e): Box-Cox Transformation Analysis

\textbf{Box-Cox Results:}

\textbf{Optimal λ (lambda)}: 0.0606 ≈ 0

\textbf{Interpretation:}

The Box-Cox procedure searches for the optimal power transformation of
the response variable that best satisfies the regression assumptions
(normality and homoscedasticity of residuals).

\textbf{Mathematical Framework:} The Box-Cox transformation is defined
as:

\begin{itemize}
\item
  If λ ≠ 0: Y\^{}(λ) = (Y\^{}λ - 1) / λ
\item
  If λ = 0: Y\^{}(λ) = log(Y)
\end{itemize}

\textbf{Key Findings:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Optimal Lambda Near Zero}:

  \begin{itemize}
  \item
    The optimal λ = 0.0606 is very close to 0
  \item
    When λ = 0, the transformation is equivalent to the \textbf{natural
    logarithm}
  \item
    This strongly suggests using \textbf{log(totalprice)} as the
    response variable
  \end{itemize}
\item
  \textbf{95\% Confidence Interval}:

  \begin{itemize}
  \item
    The horizontal dashed line shows the 95\% confidence level
  \item
    The confidence interval for λ includes 0 (approximately from -0.3 to
    0.4)
  \item
    Since 0 is well within this interval, the log transformation is
    statistically justified
  \end{itemize}
\item
  \textbf{Profile Log-Likelihood Shape}:

  \begin{itemize}
  \item
    The curve is smooth and has a clear maximum near λ = 0
  \item
    The peak is relatively broad, indicating some flexibility in the
    transformation
  \item
    However, the maximum is clearly centered near zero
  \end{itemize}
\end{enumerate}

\subsection{Model (E)}\label{model-e}

Use backward elimination to develop a model that predicts
\texttt{log(totalprice)} using the data frame \texttt{VIT2005}. Use a
``p-value to remove'' of 5\%. Store the final model in the object
\texttt{modelE}.

\begin{verbatim}
Start:  AIC=-1080.46
log_totalprice ~ area + zone + category + age + floor + rooms + 
    out + conservation + toilets + garage + elevator + streetcategory + 
    heating + storage

                 Df Sum of Sq     RSS      AIC
- conservation    3   0.01134 0.99029 -1083.95
- age             1   0.00061 0.97956 -1082.32
- floor           1   0.00185 0.98080 -1082.05
- rooms           1   0.00422 0.98317 -1081.52
<none>                        0.97895 -1080.46
- streetcategory  3   0.03040 1.00935 -1079.79
- heating         3   0.04007 1.01902 -1077.71
- storage         1   0.03280 1.01175 -1075.27
- out             3   0.06721 1.04616 -1071.98
- category        6   0.10125 1.08020 -1071.00
- toilets         1   0.08460 1.06356 -1064.39
- garage          1   0.14304 1.12199 -1052.73
- elevator        1   0.14529 1.12424 -1052.29
- area            1   0.45808 1.43703  -998.78
- zone           22   1.25852 2.23747  -944.25

Step:  AIC=-1083.95
log_totalprice ~ area + zone + category + age + floor + rooms + 
    out + toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df Sum of Sq     RSS      AIC
- age             1   0.00055 0.99084 -1085.83
- floor           1   0.00224 0.99253 -1085.45
- rooms           1   0.00381 0.99410 -1085.11
<none>                        0.99029 -1083.95
- streetcategory  3   0.03348 1.02376 -1082.70
- heating         3   0.03991 1.03019 -1081.34
- storage         1   0.02946 1.01975 -1079.56
- out             3   0.06668 1.05696 -1075.74
- category        6   0.11616 1.10644 -1071.77
- toilets         1   0.08898 1.07926 -1067.19
- elevator        1   0.14290 1.13319 -1056.56
- garage          1   0.15198 1.14226 -1054.82
- area            1   0.45804 1.44832 -1003.07
- zone           22   1.25434 2.24462  -949.56

Step:  AIC=-1085.83
log_totalprice ~ area + zone + category + floor + rooms + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df Sum of Sq     RSS     AIC
- floor           1   0.00212 0.99295 -1087.4
- rooms           1   0.00384 0.99468 -1087.0
<none>                        0.99084 -1085.8
- streetcategory  3   0.03302 1.02385 -1084.7
- heating         3   0.03941 1.03025 -1083.3
- storage         1   0.03105 1.02189 -1081.1
- out             3   0.07314 1.06397 -1076.3
- category        6   0.12795 1.11878 -1071.3
- toilets         1   0.08930 1.08013 -1069.0
- elevator        1   0.14955 1.14039 -1057.2
- garage          1   0.15229 1.14313 -1056.7
- area            1   0.46386 1.45470 -1004.1
- zone           22   1.27513 2.26596  -949.5

Step:  AIC=-1087.36
log_totalprice ~ area + zone + category + rooms + out + toilets + 
    garage + elevator + streetcategory + heating + storage

                 Df Sum of Sq     RSS      AIC
- rooms           1   0.00390 0.99685 -1088.51
<none>                        0.99295 -1087.36
- streetcategory  3   0.03140 1.02435 -1086.57
- heating         3   0.04104 1.03400 -1084.53
- storage         1   0.02921 1.02217 -1083.04
- out             3   0.07320 1.06615 -1077.86
- category        6   0.13186 1.12482 -1072.18
- toilets         1   0.08971 1.08266 -1070.51
- garage          1   0.15125 1.14420 -1058.45
- elevator        1   0.15179 1.14474 -1058.35
- area            1   0.46227 1.45522 -1006.04
- zone           22   1.32477 2.31772  -946.57

Step:  AIC=-1088.51
log_totalprice ~ area + zone + category + out + toilets + garage + 
    elevator + streetcategory + heating + storage

                 Df Sum of Sq     RSS      AIC
<none>                        0.99685 -1088.51
- streetcategory  3   0.03042 1.02727 -1087.95
- heating         3   0.04262 1.03947 -1085.38
- storage         1   0.02789 1.02474 -1084.49
- out             3   0.07696 1.07381 -1078.30
- category        6   0.12882 1.12567 -1074.01
- toilets         1   0.09245 1.08930 -1071.17
- garage          1   0.15205 1.14890 -1059.56
- elevator        1   0.15775 1.15460 -1058.48
- area            1   0.63037 1.62722  -983.68
- zone           22   1.32105 2.31790  -948.56
\end{verbatim}

\begin{verbatim}

Model E Formula: log_totalprice ~ area + zone + category + out + toilets + garage +      elevator + streetcategory + heating + storage 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = log_totalprice ~ area + zone + category + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage, data = VIT2005_log)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.222817 -0.044929  0.000173  0.048212  0.265943 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)      11.800102   0.083176 141.869  < 2e-16 ***
area              0.004461   0.000424  10.520  < 2e-16 ***
zoneZ21           0.314844   0.044556   7.066 3.63e-11 ***
zoneZ31           0.280174   0.046670   6.003 1.09e-08 ***
zoneZ32           0.179278   0.041177   4.354 2.27e-05 ***
zoneZ34           0.094760   0.051693   1.833 0.068480 .  
zoneZ35           0.282519   0.050097   5.639 6.73e-08 ***
zoneZ36           0.169712   0.042477   3.995 9.50e-05 ***
zoneZ37           0.300758   0.042972   6.999 5.29e-11 ***
zoneZ38           0.122263   0.052668   2.321 0.021417 *  
zoneZ41           0.218347   0.040695   5.365 2.53e-07 ***
zoneZ42           0.277204   0.052376   5.293 3.58e-07 ***
zoneZ43           0.162943   0.052892   3.081 0.002399 ** 
zoneZ44           0.136301   0.050824   2.682 0.008023 ** 
zoneZ45           0.079627   0.042374   1.879 0.061887 .  
zoneZ46           0.062723   0.044841   1.399 0.163652    
zoneZ47          -0.006309   0.047380  -0.133 0.894229    
zoneZ48           0.162198   0.046585   3.482 0.000629 ***
zoneZ49           0.141134   0.049702   2.840 0.005052 ** 
zoneZ52           0.056549   0.042931   1.317 0.189490    
zoneZ53           0.109465   0.043431   2.520 0.012615 *  
zoneZ56           0.133565   0.048970   2.727 0.007032 ** 
zoneZ61           0.095688   0.040434   2.367 0.019050 *  
zoneZ62           0.059944   0.040679   1.474 0.142388    
category2B       -0.008112   0.049200  -0.165 0.869232    
category3A       -0.062638   0.047913  -1.307 0.192816    
category3B       -0.077811   0.049199  -1.582 0.115552    
category4A       -0.105547   0.051056  -2.067 0.040183 *  
category4B       -0.149403   0.053548  -2.790 0.005854 ** 
category5A       -0.237579   0.083556  -2.843 0.004996 ** 
outE25            0.165305   0.048717   3.393 0.000854 ***
outE50           -0.005366   0.013374  -0.401 0.688766    
outE75            0.037254   0.034941   1.066 0.287798    
toilets           0.076538   0.018999   4.029 8.35e-05 ***
garage            0.079385   0.015365   5.166 6.45e-07 ***
elevator          0.102132   0.019408   5.262 4.12e-07 ***
streetcategoryS3  0.036227   0.019345   1.873 0.062782 .  
streetcategoryS4  0.015145   0.021082   0.718 0.473477    
streetcategoryS5 -0.023253   0.034943  -0.665 0.506631    
heating3A        -0.011383   0.040212  -0.283 0.777454    
heating3B        -0.008138   0.051433  -0.158 0.874456    
heating4A         0.030569   0.042446   0.720 0.472365    
storage           0.033641   0.015204   2.213 0.028210 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.07547 on 175 degrees of freedom
Multiple R-squared:  0.9202,    Adjusted R-squared:  0.901 
F-statistic: 48.02 on 42 and 175 DF,  p-value: < 2.2e-16
\end{verbatim}

Model E: Backward Elimination with Log-Transformed Response

\textbf{Model Selection Process:}

Backward elimination removed the following variables (in order):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Conservation} (Step 1) - Not significant
\item
  \textbf{Age} (Step 2) - Not significant
\item
  \textbf{Floor} (Step 3) - Not significant
\item
  \textbf{Rooms} (Step 4) - Not significant
\end{enumerate}

\textbf{Final Model E} retained these 10 predictors:

\begin{itemize}
\tightlist
\item
  area, zone, category, out, toilets, garage, elevator, streetcategory,
  heating, storage
\end{itemize}

This is \textbf{one fewer predictor than Models A/B/D} (which had 11
predictors including rooms).

\paragraph{\texorpdfstring{(i) Compute \(CV_n\) for \texttt{modelE}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelE}.}{(i) Compute CV\_n for modelE. Set the seed to 5 and compute CV\_5 for modelE.}}\label{i-compute-cv_n-for-modele.-set-the-seed-to-5-and-compute-cv_5-for-modele.}

\begin{verbatim}

--- Model E Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 0.007080105 
\end{verbatim}

\begin{verbatim}
CV_5: 0.007358635 
\end{verbatim}

\begin{itemize}
\item
  \textbf{CV\_n (Leave-One-Out Cross-Validation)}: 0.007080105
\item
  \textbf{CV\_5 (5-Fold Cross-Validation)}: 0.007358635
\end{itemize}

\textbf{Important Note}: These CV errors are on the \textbf{log scale}
(not euros), so they represent mean squared prediction error for
log(totalprice). These values are \textbf{much smaller} than Models A-D
because:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  They're on the log scale (compressed range)
\item
  The log transformation has stabilized variance
\end{enumerate}

\paragraph{\texorpdfstring{(ii) Compute \(R^2, R^2_a\), the AIC, and the
BIC for Model (E). What is the proportion of total variability explained
by Model
(E)?}{(ii) Compute R\^{}2, R\^{}2\_a, the AIC, and the BIC for Model (E). What is the proportion of total variability explained by Model (E)?}}\label{ii-compute-r2-r2_a-the-aic-and-the-bic-for-model-e.-what-is-the-proportion-of-total-variability-explained-by-model-e}

\begin{verbatim}

--- Model E Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.9201524 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.900989 
\end{verbatim}

\begin{verbatim}
AIC: -467.8506 
\end{verbatim}

\begin{verbatim}
BIC: -318.9328 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.9201524 
\end{verbatim}

\textbf{Proportion of variability explained}: \textbf{92.02\%}

\textbf{Interpretation:}

\textbf{Model E explains 92.02\% of the total variability in
log(totalprice).}

This is actually a \textbf{slight improvement} over Models A/B/D (which
had 91.62\% R² for untransformed totalprice), despite having one fewer
predictor.

\textbf{Key Improvements from Log Transformation:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Better Model Fit}:

  \begin{itemize}
  \item
    R² increased from 91.62\% to 92.02\%
  \item
    Adjusted R² increased from 89.55\% to 90.10\%
  \end{itemize}
\item
  \textbf{Improved AIC/BIC}:

  \begin{itemize}
  \item
    AIC: -467.851 (vs 5026.797 for Models A/B/D)
  \item
    BIC: -318.933 (vs 5179.099 for Models A/B/D)
  \item
    \textbf{Note}: These aren't directly comparable due to different
    scales, but negative values indicate excellent fit
  \end{itemize}
\item
  \textbf{Smaller Residual Standard Error}:

  \begin{itemize}
  \item
    σ = 0.07547 on log scale
  \item
    This represents approximately 7.5\% typical prediction error in
    multiplicative terms
  \end{itemize}
\item
  \textbf{Better Residual Properties} (expected from Box-Cox):

  \begin{itemize}
  \item
    Smaller, more symmetric residuals (range: -0.223 to 0.266)
  \item
    More homoscedastic (constant variance)
  \item
    More normally distributed
  \end{itemize}
\end{enumerate}

\textbf{Significant Predictors (p \textless{} 0.05):}

\textbf{Highly Significant (p \textless{} 0.001):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Area}: β = 0.00446 (p \textless{} 2e-16)

  \begin{itemize}
  \tightlist
  \item
    Each additional m² increases price by \textasciitilde0.45\%
  \end{itemize}
\item
  \textbf{Garage}: β = 0.0794 (p = 6.45e-07)

  \begin{itemize}
  \tightlist
  \item
    Having a garage increases price by \textasciitilde8.3\%
    {[}exp(0.0794)-1{]}
  \end{itemize}
\item
  \textbf{Elevator}: β = 0.102 (p = 4.12e-07)

  \begin{itemize}
  \tightlist
  \item
    Having elevator increases price by \textasciitilde10.7\%
  \end{itemize}
\item
  \textbf{Toilets}: β = 0.0765 (p = 8.35e-05)

  \begin{itemize}
  \tightlist
  \item
    Each additional toilet increases price by \textasciitilde8.0\%
  \end{itemize}
\item
  \textbf{Zone}: Many zones highly significant
\item
  \textbf{Category}: Several categories significant
\end{enumerate}

\textbf{Moderately Significant (0.001 \textless{} p \textless{} 0.05):}

\begin{itemize}
\item
  Various zone and category levels
\item
  \textbf{outE25}: β = 0.165 (p = 0.000854) - 18.0\% price premium
\item
  \textbf{Storage}: β = 0.0336 (p = 0.0282) - 3.4\% price increase
\end{itemize}

\textbf{Coefficient Interpretation (Log-Linear Model):}

Since the response is log-transformed:

\begin{itemize}
\item
  \textbf{Continuous predictors}: β represents the proportional change
  in price for a 1-unit increase

  \begin{itemize}
  \tightlist
  \item
    Example: Area coefficient = 0.00446 means 1 m² increase → 0.446\%
    price increase
  \end{itemize}
\item
  \textbf{Binary/Categorical predictors}: exp(β) - 1 gives the
  percentage change

  \begin{itemize}
  \item
    Example: Garage coefficient = 0.0794 → exp(0.0794) - 1 = 0.0826 =
    \textbf{8.26\% price increase}
  \item
    Example: Elevator coefficient = 0.102 → exp(0.102) - 1 = 0.1074 =
    \textbf{10.74\% price increase}
  \end{itemize}
\end{itemize}

\subsection{Model (F)}\label{model-f}

Use the criterion-based procedure AIC, which for linear regression is
equivalent to Mallow's Cp, to develop a model that predicts
\texttt{log(totalprice)} using the variables in \texttt{VIT2005}. Store
the model in the object \texttt{modelF}.

\begin{verbatim}
Start:  AIC=-1080.46
log_totalprice ~ area + zone + category + age + floor + rooms + 
    out + conservation + toilets + garage + elevator + streetcategory + 
    heating + storage

                 Df Sum of Sq     RSS      AIC
- conservation    3   0.01134 0.99029 -1083.95
- age             1   0.00061 0.97956 -1082.32
- floor           1   0.00185 0.98080 -1082.05
- rooms           1   0.00422 0.98317 -1081.52
<none>                        0.97895 -1080.46
- streetcategory  3   0.03040 1.00935 -1079.79
- heating         3   0.04007 1.01902 -1077.71
- storage         1   0.03280 1.01175 -1075.27
- out             3   0.06721 1.04616 -1071.98
- category        6   0.10125 1.08020 -1071.00
- toilets         1   0.08460 1.06356 -1064.39
- garage          1   0.14304 1.12199 -1052.73
- elevator        1   0.14529 1.12424 -1052.29
- area            1   0.45808 1.43703  -998.78
- zone           22   1.25852 2.23747  -944.25

Step:  AIC=-1083.95
log_totalprice ~ area + zone + category + age + floor + rooms + 
    out + toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df Sum of Sq     RSS      AIC
- age             1   0.00055 0.99084 -1085.83
- floor           1   0.00224 0.99253 -1085.45
- rooms           1   0.00381 0.99410 -1085.11
<none>                        0.99029 -1083.95
- streetcategory  3   0.03348 1.02376 -1082.70
- heating         3   0.03991 1.03019 -1081.34
+ conservation    3   0.01134 0.97895 -1080.46
- storage         1   0.02946 1.01975 -1079.56
- out             3   0.06668 1.05696 -1075.74
- category        6   0.11616 1.10644 -1071.77
- toilets         1   0.08898 1.07926 -1067.19
- elevator        1   0.14290 1.13319 -1056.56
- garage          1   0.15198 1.14226 -1054.82
- area            1   0.45804 1.44832 -1003.07
- zone           22   1.25434 2.24462  -949.56

Step:  AIC=-1085.83
log_totalprice ~ area + zone + category + floor + rooms + out + 
    toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df Sum of Sq     RSS     AIC
- floor           1   0.00212 0.99295 -1087.4
- rooms           1   0.00384 0.99468 -1087.0
<none>                        0.99084 -1085.8
- streetcategory  3   0.03302 1.02385 -1084.7
+ age             1   0.00055 0.99029 -1084.0
- heating         3   0.03941 1.03025 -1083.3
+ conservation    3   0.01128 0.97956 -1082.3
- storage         1   0.03105 1.02189 -1081.1
- out             3   0.07314 1.06397 -1076.3
- category        6   0.12795 1.11878 -1071.3
- toilets         1   0.08930 1.08013 -1069.0
- elevator        1   0.14955 1.14039 -1057.2
- garage          1   0.15229 1.14313 -1056.7
- area            1   0.46386 1.45470 -1004.1
- zone           22   1.27513 2.26596  -949.5

Step:  AIC=-1087.36
log_totalprice ~ area + zone + category + rooms + out + toilets + 
    garage + elevator + streetcategory + heating + storage

                 Df Sum of Sq     RSS      AIC
- rooms           1   0.00390 0.99685 -1088.51
<none>                        0.99295 -1087.36
- streetcategory  3   0.03140 1.02435 -1086.57
+ floor           1   0.00212 0.99084 -1085.83
+ age             1   0.00042 0.99253 -1085.45
- heating         3   0.04104 1.03400 -1084.53
+ conservation    3   0.01138 0.98158 -1083.87
- storage         1   0.02921 1.02217 -1083.04
- out             3   0.07320 1.06615 -1077.86
- category        6   0.13186 1.12482 -1072.18
- toilets         1   0.08971 1.08266 -1070.51
- garage          1   0.15125 1.14420 -1058.45
- elevator        1   0.15179 1.14474 -1058.35
- area            1   0.46227 1.45522 -1006.04
- zone           22   1.32477 2.31772  -946.57

Step:  AIC=-1088.51
log_totalprice ~ area + zone + category + out + toilets + garage + 
    elevator + streetcategory + heating + storage

                 Df Sum of Sq     RSS      AIC
<none>                        0.99685 -1088.51
- streetcategory  3   0.03042 1.02727 -1087.95
+ rooms           1   0.00390 0.99295 -1087.36
+ floor           1   0.00217 0.99468 -1086.98
+ age             1   0.00045 0.99640 -1086.61
- heating         3   0.04262 1.03947 -1085.38
+ conservation    3   0.01098 0.98587 -1084.92
- storage         1   0.02789 1.02474 -1084.49
- out             3   0.07696 1.07381 -1078.30
- category        6   0.12882 1.12567 -1074.01
- toilets         1   0.09245 1.08930 -1071.17
- garage          1   0.15205 1.14890 -1059.56
- elevator        1   0.15775 1.15460 -1058.48
- area            1   0.63037 1.62722  -983.68
- zone           22   1.32105 2.31790  -948.56
\end{verbatim}

\begin{verbatim}

Model F Formula: log(totalprice) ~ area + zone + category + out + toilets + garage +      elevator + streetcategory + heating + storage 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = modelF_formula, data = VIT2005)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.222817 -0.044929  0.000173  0.048212  0.265943 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)      11.800102   0.083176 141.869  < 2e-16 ***
area              0.004461   0.000424  10.520  < 2e-16 ***
zoneZ21           0.314844   0.044556   7.066 3.63e-11 ***
zoneZ31           0.280174   0.046670   6.003 1.09e-08 ***
zoneZ32           0.179278   0.041177   4.354 2.27e-05 ***
zoneZ34           0.094760   0.051693   1.833 0.068480 .  
zoneZ35           0.282519   0.050097   5.639 6.73e-08 ***
zoneZ36           0.169712   0.042477   3.995 9.50e-05 ***
zoneZ37           0.300758   0.042972   6.999 5.29e-11 ***
zoneZ38           0.122263   0.052668   2.321 0.021417 *  
zoneZ41           0.218347   0.040695   5.365 2.53e-07 ***
zoneZ42           0.277204   0.052376   5.293 3.58e-07 ***
zoneZ43           0.162943   0.052892   3.081 0.002399 ** 
zoneZ44           0.136301   0.050824   2.682 0.008023 ** 
zoneZ45           0.079627   0.042374   1.879 0.061887 .  
zoneZ46           0.062723   0.044841   1.399 0.163652    
zoneZ47          -0.006309   0.047380  -0.133 0.894229    
zoneZ48           0.162198   0.046585   3.482 0.000629 ***
zoneZ49           0.141134   0.049702   2.840 0.005052 ** 
zoneZ52           0.056549   0.042931   1.317 0.189490    
zoneZ53           0.109465   0.043431   2.520 0.012615 *  
zoneZ56           0.133565   0.048970   2.727 0.007032 ** 
zoneZ61           0.095688   0.040434   2.367 0.019050 *  
zoneZ62           0.059944   0.040679   1.474 0.142388    
category2B       -0.008112   0.049200  -0.165 0.869232    
category3A       -0.062638   0.047913  -1.307 0.192816    
category3B       -0.077811   0.049199  -1.582 0.115552    
category4A       -0.105547   0.051056  -2.067 0.040183 *  
category4B       -0.149403   0.053548  -2.790 0.005854 ** 
category5A       -0.237579   0.083556  -2.843 0.004996 ** 
outE25            0.165305   0.048717   3.393 0.000854 ***
outE50           -0.005366   0.013374  -0.401 0.688766    
outE75            0.037254   0.034941   1.066 0.287798    
toilets           0.076538   0.018999   4.029 8.35e-05 ***
garage            0.079385   0.015365   5.166 6.45e-07 ***
elevator          0.102132   0.019408   5.262 4.12e-07 ***
streetcategoryS3  0.036227   0.019345   1.873 0.062782 .  
streetcategoryS4  0.015145   0.021082   0.718 0.473477    
streetcategoryS5 -0.023253   0.034943  -0.665 0.506631    
heating3A        -0.011383   0.040212  -0.283 0.777454    
heating3B        -0.008138   0.051433  -0.158 0.874456    
heating4A         0.030569   0.042446   0.720 0.472365    
storage           0.033641   0.015204   2.213 0.028210 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.07547 on 175 degrees of freedom
Multiple R-squared:  0.9202,    Adjusted R-squared:  0.901 
F-statistic: 48.02 on 42 and 175 DF,  p-value: < 2.2e-16
\end{verbatim}

Model F: AIC-Based Selection with Log(totalprice)

\textbf{Model Selection Process:}

The \texttt{stepAIC} function with AIC criterion (k=2) performed
bidirectional selection on the log-transformed response.

\textbf{Final Model F} includes the same 10 predictors as Model E:

\begin{itemize}
\tightlist
\item
  area, zone, category, out, toilets, garage, elevator, streetcategory,
  heating, storage
\end{itemize}

\textbf{Key Finding}: \textbf{Model F is IDENTICAL to Model E}

Both AIC-based stepwise selection and backward elimination converged to
the same model when using log(totalprice) as the response.

\paragraph{\texorpdfstring{(i) Compute \(CV_n\) for \texttt{modelF}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelF}.}{(i) Compute CV\_n for modelF. Set the seed to 5 and compute CV\_5 for modelF.}}\label{i-compute-cv_n-for-modelf.-set-the-seed-to-5-and-compute-cv_5-for-modelf.}

\begin{verbatim}

--- Model F Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 0.007080105 
\end{verbatim}

\begin{verbatim}
CV_5: 0.007358635 
\end{verbatim}

\begin{itemize}
\item
  \textbf{CV\_n (Leave-One-Out Cross-Validation)}: 0.007080105
\item
  \textbf{CV\_5 (Five-Fold Cross-Validation with seed = 5)}: 0.007358635
\end{itemize}

These are identical to Model E (as expected since it's the same model).

\paragraph{\texorpdfstring{(ii) Compute \(R^2, R^2_a\), the AIC, and the
BIC for Model (F). What is the proportion of total variability explained
by Model
(F)?}{(ii) Compute R\^{}2, R\^{}2\_a, the AIC, and the BIC for Model (F). What is the proportion of total variability explained by Model (F)?}}\label{ii-compute-r2-r2_a-the-aic-and-the-bic-for-model-f.-what-is-the-proportion-of-total-variability-explained-by-model-f}

\begin{verbatim}

--- Model F Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.9201524 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.900989 
\end{verbatim}

\begin{verbatim}
AIC: -467.8506 
\end{verbatim}

\begin{verbatim}
BIC: -318.9328 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.9201524 
\end{verbatim}

\textbf{Proportion of total variability explained by Model (F)}:
\textbf{92.02\%}

This means that Model F explains approximately 92\% of the variability
in log(totalprice) using the selected predictors. The adjusted R² of
0.901 (90.1\%) accounts for the number of predictors in the model and
still indicates excellent explanatory power.

\subsection{Model (G)}\label{model-g}

Use the criterion-based procedure BIC to develop a model that predicts
\texttt{log(totalprice)} using the variables in \texttt{VIT2005}. Store
the model in the object \texttt{modelG}.

\begin{verbatim}
Start:  AIC=-914.62
log_totalprice ~ area + zone + category + age + floor + rooms + 
    out + conservation + toilets + garage + elevator + streetcategory + 
    heating + storage

                 Df Sum of Sq     RSS     AIC
- conservation    3   0.01134 0.99029 -928.26
- category        6   0.10125 1.08020 -925.47
- streetcategory  3   0.03040 1.00935 -924.10
- heating         3   0.04007 1.01902 -922.02
- age             1   0.00061 0.97956 -919.87
- floor           1   0.00185 0.98080 -919.59
- rooms           1   0.00422 0.98317 -919.06
- out             3   0.06721 1.04616 -916.30
<none>                        0.97895 -914.62
- storage         1   0.03280 1.01175 -912.82
- toilets         1   0.08460 1.06356 -901.93
- garage          1   0.14304 1.12199 -890.27
- elevator        1   0.14529 1.12424 -889.83
- zone           22   1.25852 2.23747 -852.87
- area            1   0.45808 1.43703 -836.32

Step:  AIC=-928.26
log_totalprice ~ area + zone + category + age + floor + rooms + 
    out + toilets + garage + elevator + streetcategory + heating + 
    storage

                 Df Sum of Sq     RSS     AIC
- streetcategory  3   0.03348 1.02376 -937.17
- category        6   0.11616 1.10644 -936.39
- heating         3   0.03991 1.03019 -935.80
- age             1   0.00055 0.99084 -933.52
- floor           1   0.00224 0.99253 -933.15
- rooms           1   0.00381 0.99410 -932.81
- out             3   0.06668 1.05696 -930.21
<none>                        0.99029 -928.26
- storage         1   0.02946 1.01975 -927.26
- toilets         1   0.08898 1.07926 -914.89
+ conservation    3   0.01134 0.97895 -914.62
- elevator        1   0.14290 1.13319 -904.26
- garage          1   0.15198 1.14226 -902.52
- zone           22   1.25434 2.24462 -868.33
- area            1   0.45804 1.44832 -850.77

Step:  AIC=-937.17
log_totalprice ~ area + zone + category + age + floor + rooms + 
    out + toilets + garage + elevator + heating + storage

                 Df Sum of Sq     RSS     AIC
- category        6   0.12555 1.14932 -944.26
- heating         3   0.04560 1.06937 -943.82
- age             1   0.00009 1.02385 -942.53
- floor           1   0.00052 1.02428 -942.44
- rooms           1   0.00286 1.02662 -941.94
- out             3   0.06835 1.09211 -939.23
<none>                        1.02376 -937.17
- storage         1   0.04258 1.06634 -933.67
+ streetcategory  3   0.03348 0.99029 -928.26
+ conservation    3   0.01441 1.00935 -924.10
- toilets         1   0.09505 1.11881 -923.20
- elevator        1   0.13772 1.16148 -915.04
- garage          1   0.15324 1.17700 -912.14
- zone           22   1.26578 2.28954 -880.16
- area            1   0.44375 1.46751 -864.05

Step:  AIC=-944.26
log_totalprice ~ area + zone + age + floor + rooms + out + toilets + 
    garage + elevator + heating + storage

                 Df Sum of Sq    RSS     AIC
- out             3   0.04504 1.1944 -952.03
- rooms           1   0.00053 1.1499 -949.54
- floor           1   0.00303 1.1523 -949.07
- heating         3   0.06482 1.2141 -948.45
- age             1   0.00879 1.1581 -947.98
- storage         1   0.02872 1.1780 -944.26
<none>                        1.1493 -944.26
+ category        6   0.12555 1.0238 -937.17
+ streetcategory  3   0.04287 1.1064 -936.39
+ conservation    3   0.03318 1.1161 -934.49
- toilets         1   0.17704 1.3264 -918.41
- garage          1   0.17865 1.3280 -918.14
- elevator        1   0.20584 1.3552 -913.72
- zone           22   1.31896 2.4683 -896.09
- area            1   0.48299 1.6323 -873.16

Step:  AIC=-952.03
log_totalprice ~ area + zone + age + floor + rooms + toilets + 
    garage + elevator + heating + storage

                 Df Sum of Sq    RSS     AIC
- heating         3   0.05704 1.2514 -958.01
- rooms           1   0.00251 1.1969 -956.95
- floor           1   0.00371 1.1981 -956.74
- age             1   0.01900 1.2134 -953.97
- storage         1   0.02881 1.2232 -952.22
<none>                        1.1944 -952.03
+ streetcategory  3   0.04545 1.1489 -944.33
+ out             3   0.04504 1.1493 -944.26
+ conservation    3   0.03021 1.1642 -941.46
+ category        6   0.10224 1.0921 -939.23
- toilets         1   0.15903 1.3534 -930.16
- garage          1   0.16888 1.3632 -928.58
- elevator        1   0.20044 1.3948 -923.59
- zone           22   1.32405 2.5184 -907.86
- area            1   0.48420 1.6785 -883.22

Step:  AIC=-958.01
log_totalprice ~ area + zone + age + floor + rooms + toilets + 
    garage + elevator + storage

                 Df Sum of Sq    RSS     AIC
- rooms           1   0.00384 1.2552 -962.73
- floor           1   0.00808 1.2595 -961.99
- age             1   0.02108 1.2725 -959.75
<none>                        1.2514 -958.01
- storage         1   0.05236 1.3038 -954.46
+ heating         3   0.05704 1.1944 -952.03
+ streetcategory  3   0.05054 1.2009 -950.84
+ out             3   0.03727 1.2141 -948.45
+ conservation    3   0.03196 1.2194 -947.50
+ category        6   0.11390 1.1375 -946.51
- garage          1   0.16188 1.4133 -936.88
- toilets         1   0.17292 1.4243 -935.18
- elevator        1   0.23193 1.4833 -926.33
- zone           22   1.33364 2.5850 -918.32
- area            1   0.51488 1.7663 -888.27

Step:  AIC=-962.73
log_totalprice ~ area + zone + age + floor + toilets + garage + 
    elevator + storage

                 Df Sum of Sq    RSS     AIC
- floor           1   0.00830 1.2635 -966.67
- age             1   0.02116 1.2764 -964.47
<none>                        1.2552 -962.73
- storage         1   0.05058 1.3058 -959.50
+ rooms           1   0.00384 1.2514 -958.01
+ heating         3   0.05837 1.1969 -956.95
+ streetcategory  3   0.04991 1.2053 -955.42
+ out             3   0.03972 1.2155 -953.58
+ conservation    3   0.03108 1.2242 -952.04
+ category        6   0.10941 1.1458 -950.30
- garage          1   0.16145 1.4167 -941.74
- toilets         1   0.17660 1.4318 -939.42
- elevator        1   0.24218 1.4974 -929.65
- zone           22   1.32984 2.5851 -923.70
- area            1   0.70604 1.9613 -870.83

Step:  AIC=-966.67
log_totalprice ~ area + zone + age + toilets + garage + elevator + 
    storage

                 Df Sum of Sq    RSS     AIC
- age             1   0.02130 1.2849 -968.41
<none>                        1.2635 -966.67
- storage         1   0.04511 1.3087 -964.41
+ floor           1   0.00830 1.2552 -962.73
+ rooms           1   0.00407 1.2595 -961.99
+ heating         3   0.06286 1.2007 -961.65
+ streetcategory  3   0.04486 1.2187 -958.40
+ out             3   0.04027 1.2233 -957.58
+ conservation    3   0.03193 1.2316 -956.10
+ category        6   0.11556 1.1480 -955.28
- garage          1   0.16071 1.4243 -945.96
- toilets         1   0.17698 1.4405 -943.48
- elevator        1   0.24987 1.5134 -932.72
- zone           22   1.34544 2.6090 -927.07
- area            1   0.70411 1.9677 -875.50

Step:  AIC=-968.41
log_totalprice ~ area + zone + toilets + garage + elevator + 
    storage

                 Df Sum of Sq    RSS     AIC
<none>                        1.2849 -968.41
+ age             1   0.02130 1.2635 -966.67
+ floor           1   0.00844 1.2764 -964.47
- storage         1   0.06035 1.3452 -963.79
+ rooms           1   0.00415 1.2807 -963.74
+ heating         3   0.06516 1.2197 -963.61
+ conservation    3   0.05262 1.2322 -961.38
+ out             3   0.04873 1.2361 -960.69
+ category        6   0.13511 1.1497 -960.33
+ streetcategory  3   0.03996 1.2449 -959.15
- garage          1   0.16860 1.4534 -946.92
- toilets         1   0.18619 1.4710 -944.30
- elevator        1   0.28531 1.5701 -930.08
- zone           22   1.44533 2.7302 -922.56
- area            1   0.68283 1.9677 -880.89
\end{verbatim}

\begin{verbatim}

Model G Formula: log(totalprice) ~ area + zone + toilets + garage + elevator +      storage 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = modelG_formula, data = VIT2005)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.23683 -0.03953  0.00451  0.04920  0.31278 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 11.651257   0.043443 268.198  < 2e-16 ***
area         0.004401   0.000438  10.049  < 2e-16 ***
zoneZ21      0.358359   0.044468   8.059 8.36e-14 ***
zoneZ31      0.307375   0.044616   6.889 8.00e-11 ***
zoneZ32      0.196280   0.040583   4.836 2.72e-06 ***
zoneZ34      0.117444   0.050858   2.309 0.022005 *  
zoneZ35      0.301831   0.051444   5.867 1.94e-08 ***
zoneZ36      0.183552   0.043221   4.247 3.39e-05 ***
zoneZ37      0.307650   0.040067   7.678 8.27e-13 ***
zoneZ38      0.149666   0.052682   2.841 0.004989 ** 
zoneZ41      0.248177   0.040695   6.098 5.87e-09 ***
zoneZ42      0.272166   0.050192   5.423 1.77e-07 ***
zoneZ43      0.225136   0.051694   4.355 2.17e-05 ***
zoneZ44      0.197530   0.050878   3.882 0.000143 ***
zoneZ45      0.118399   0.041164   2.876 0.004484 ** 
zoneZ46      0.095493   0.042205   2.263 0.024792 *  
zoneZ47      0.063157   0.044024   1.435 0.153041    
zoneZ48      0.188875   0.046007   4.105 5.99e-05 ***
zoneZ49      0.174140   0.049890   3.490 0.000599 ***
zoneZ52      0.076527   0.041613   1.839 0.067472 .  
zoneZ53      0.139277   0.042545   3.274 0.001261 ** 
zoneZ56      0.198326   0.046526   4.263 3.18e-05 ***
zoneZ61      0.128767   0.040188   3.204 0.001589 ** 
zoneZ62      0.097954   0.037869   2.587 0.010439 *  
toilets      0.098690   0.018808   5.247 4.10e-07 ***
garage       0.081601   0.016342   4.993 1.34e-06 ***
elevator     0.126587   0.019489   6.495 7.06e-10 ***
storage      0.045528   0.015241   2.987 0.003186 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.08223 on 190 degrees of freedom
Multiple R-squared:  0.8971,    Adjusted R-squared:  0.8825 
F-statistic: 61.34 on 27 and 190 DF,  p-value: < 2.2e-16
\end{verbatim}

Model G: BIC-Based Selection with Log-Transformed Response

\textbf{Model Selection Process:}

The \texttt{stepAIC} function with BIC criterion (k = log(218) ≈ 5.38)
performed \textbf{bidirectional selection} on the log-transformed
response.

The BIC criterion penalizes model complexity more heavily than AIC,
leading to a \textbf{more parsimonious model}.

\textbf{Variables removed} (in order):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Conservation} (Step 1)
\item
  \textbf{Streetcategory} (Step 2)
\item
  \textbf{Category} (Step 3)
\item
  \textbf{Out} (Step 4)
\item
  \textbf{Heating} (Step 5)
\item
  \textbf{Rooms} (Step 6)
\item
  \textbf{Floor} (Step 7)
\item
  \textbf{Age} (Step 8)
\end{enumerate}

\textbf{Final Model G} includes only \textbf{6 predictors}:

\begin{itemize}
\tightlist
\item
  area, zone, toilets, garage, elevator, storage
\end{itemize}

This is \textbf{identical to Model C} (which also had 6 predictors with
untransformed response), showing that BIC consistently selects the same
variables regardless of transformation.

\paragraph{\texorpdfstring{(i) Compute \(CV_n\) for \texttt{modelG}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelG}.}{(i) Compute CV\_n for modelG. Set the seed to 5 and compute CV\_5 for modelG.}}\label{i-compute-cv_n-for-modelg.-set-the-seed-to-5-and-compute-cv_5-for-modelg.}

\begin{verbatim}

--- Model G Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 0.007796288 
\end{verbatim}

\begin{verbatim}
CV_5: 0.008354265 
\end{verbatim}

\paragraph{\texorpdfstring{(ii) Compute \(R^2, R^2_a\), the AIC, and the
BIC for Model (G). What is the proportion of total variability explained
by Model
(G)?}{(ii) Compute R\^{}2, R\^{}2\_a, the AIC, and the BIC for Model (G). What is the proportion of total variability explained by Model (G)?}}\label{ii-compute-r2-r2_a-the-aic-and-the-bic-for-model-g.-what-is-the-proportion-of-total-variability-explained-by-model-g}

\begin{verbatim}

--- Model G Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.897084 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.8824591 
\end{verbatim}

\begin{verbatim}
AIC: -442.5236 
\end{verbatim}

\begin{verbatim}
BIC: -344.3732 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.897084 
\end{verbatim}

\textbf{Proportion of total variability explained by Model (G)}:
\textbf{89.71\%}

This means that Model G explains approximately 89.71\% of the
variability in log(totalprice) using the selected predictors. The
adjusted R² of 0.8825 (88.25\%) accounts for the number of predictors in
the model and still indicates very good explanatory power.

This is approximately 2.3\% less than Models E and F (92.02\%), which is
the cost of having a much simpler model with 4 fewer predictors.

\subsection{Model (H)}\label{model-h}

Use forward selection to develop a model that predicts
log(\texttt{totalprice}) using the variables in \texttt{VIT2005}. Use a
``p-value to add'' of 5\%. Store the final model in the object
\texttt{modelH}.

\begin{verbatim}
Start:  AIC=-621.48
log_totalprice ~ 1

                 Df Sum of Sq     RSS     AIC
+ area            1    7.8362  4.6482 -834.87
+ zone           22    7.5626  4.9218 -780.40
+ toilets         1    6.1982  6.2862 -769.06
+ category        6    4.8773  7.6071 -717.48
+ elevator        1    4.0709  8.4135 -705.52
+ rooms           1    3.3932  9.0912 -688.63
+ garage          1    3.3694  9.1150 -688.06
+ heating         3    2.0692 10.4152 -654.99
+ age             1    1.2432 11.2412 -642.35
+ streetcategory  3    1.3194 11.1650 -639.83
+ conservation    3    1.3130 11.1715 -639.71
+ storage         1    1.0175 11.4669 -638.02
<none>                        12.4844 -621.48
+ floor           1    0.0307 12.4537 -620.02
+ out             3    0.1954 12.2890 -618.92

Step:  AIC=-834.87
log_totalprice ~ area

                 Df Sum of Sq    RSS     AIC
+ zone           22   2.38890 2.2593 -948.14
+ category        6   1.39298 3.2552 -900.52
+ elevator        1   0.98718 3.6610 -884.91
+ age             1   0.94091 3.7073 -882.17
+ toilets         1   0.89664 3.7516 -879.59
+ garage          1   0.82734 3.8209 -875.60
+ conservation    3   0.56107 4.0871 -856.91
+ storage         1   0.35116 4.2970 -849.99
+ heating         3   0.41740 4.2308 -849.38
<none>                        4.6482 -834.87
+ rooms           1   0.00522 4.6430 -833.11
+ floor           1   0.00287 4.6453 -833.00
+ out             3   0.06955 4.5787 -832.15
+ streetcategory  3   0.01528 4.6329 -829.58

Step:  AIC=-948.14
log_totalprice ~ area + zone

                 Df Sum of Sq    RSS     AIC
+ elevator        1   0.42018 1.8391 -991.00
+ category        6   0.49734 1.7620 -990.34
+ toilets         1   0.40710 1.8522 -989.45
+ garage          1   0.36212 1.8972 -984.22
+ conservation    3   0.19686 2.0624 -962.01
+ age             1   0.15632 2.1030 -961.77
+ heating         3   0.17104 2.0883 -959.30
+ storage         1   0.11314 2.1462 -957.34
+ streetcategory  3   0.06860 2.1907 -948.86
+ rooms           1   0.02241 2.2369 -948.31
<none>                        2.2593 -948.14
+ floor           1   0.00580 2.2535 -946.70
+ out             3   0.02187 2.2374 -944.26

Step:  AIC=-991
log_totalprice ~ area + zone + elevator

                 Df Sum of Sq    RSS      AIC
+ toilets         1   0.31527 1.5238 -1029.99
+ garage          1   0.29349 1.5456 -1026.90
+ category        6   0.33470 1.5044 -1022.79
+ conservation    3   0.15473 1.6844 -1004.15
+ heating         3   0.12922 1.7099 -1000.88
+ storage         1   0.09418 1.7450 -1000.45
+ age             1   0.07468 1.7644  -998.03
+ streetcategory  3   0.07074 1.7684  -993.55
<none>                        1.8391  -991.00
+ rooms           1   0.00485 1.8343  -989.57
+ floor           1   0.00118 1.8379  -989.13
+ out             3   0.01315 1.8260  -986.56

Step:  AIC=-1029.99
log_totalprice ~ area + zone + elevator + toilets

                 Df Sum of Sq    RSS     AIC
+ garage          1  0.178658 1.3452 -1055.2
+ category        6  0.178990 1.3449 -1045.2
+ storage         1  0.070407 1.4534 -1038.3
+ heating         3  0.092733 1.4311 -1037.7
+ conservation    3  0.081656 1.4422 -1036.0
+ age             1  0.048398 1.4754 -1035.0
+ streetcategory  3  0.062161 1.4617 -1033.1
<none>                        1.5238 -1030.0
+ out             3  0.037545 1.4863 -1029.4
+ floor           1  0.001602 1.5223 -1028.2
+ rooms           1  0.001585 1.5223 -1028.2

Step:  AIC=-1055.17
log_totalprice ~ area + zone + elevator + toilets + garage

                 Df Sum of Sq    RSS     AIC
+ category        6  0.142650 1.2025 -1067.6
+ heating         3  0.094803 1.2504 -1065.1
+ storage         1  0.060346 1.2849 -1063.2
+ conservation    3  0.061414 1.2838 -1059.4
+ age             1  0.036534 1.3087 -1059.2
+ streetcategory  3  0.058889 1.2863 -1058.9
+ out             3  0.045758 1.2994 -1056.7
<none>                        1.3452 -1055.2
+ floor           1  0.002271 1.3429 -1053.5
+ rooms           1  0.002035 1.3432 -1053.5

Step:  AIC=-1067.61
log_totalprice ~ area + zone + elevator + toilets + garage + 
    category

                 Df Sum of Sq    RSS     AIC
+ out             3  0.078212 1.1243 -1076.3
+ storage         1  0.052809 1.1497 -1075.4
+ streetcategory  3  0.055147 1.1474 -1071.8
+ heating         3  0.053972 1.1486 -1071.6
<none>                        1.2025 -1067.6
+ rooms           1  0.006518 1.1960 -1066.8
+ age             1  0.006361 1.1962 -1066.8
+ floor           1  0.000015 1.2025 -1065.6
+ conservation    3  0.015357 1.1872 -1064.4

Step:  AIC=-1076.27
log_totalprice ~ area + zone + elevator + toilets + garage + 
    category + out

                 Df Sum of Sq    RSS     AIC
+ storage         1  0.048591 1.0757 -1083.9
+ heating         3  0.055036 1.0693 -1081.2
+ streetcategory  3  0.053540 1.0708 -1080.9
<none>                        1.1243 -1076.3
+ rooms           1  0.002770 1.1216 -1074.8
+ age             1  0.000158 1.1242 -1074.3
+ floor           1  0.000001 1.1243 -1074.3
+ conservation    3  0.008420 1.1159 -1071.9

Step:  AIC=-1083.9
log_totalprice ~ area + zone + elevator + toilets + garage + 
    category + out + storage

                 Df Sum of Sq    RSS     AIC
+ heating         3  0.048467 1.0273 -1088.0
+ streetcategory  3  0.036269 1.0395 -1085.4
<none>                        1.0757 -1083.9
+ rooms           1  0.004406 1.0713 -1082.8
+ floor           1  0.001623 1.0741 -1082.2
+ age             1  0.000573 1.0752 -1082.0
+ conservation    3  0.009626 1.0661 -1079.9

Step:  AIC=-1087.95
log_totalprice ~ area + zone + elevator + toilets + garage + 
    category + out + storage + heating

                 Df Sum of Sq     RSS     AIC
+ streetcategory  3 0.0304213 0.99685 -1088.5
<none>                        1.02727 -1088.0
+ rooms           1 0.0029190 1.02435 -1086.6
+ floor           1 0.0005553 1.02672 -1086.1
+ age             1 0.0000741 1.02720 -1086.0
+ conservation    3 0.0123414 1.01493 -1084.6

Step:  AIC=-1088.51
log_totalprice ~ area + zone + elevator + toilets + garage + 
    category + out + storage + heating + streetcategory

               Df Sum of Sq     RSS     AIC
<none>                      0.99685 -1088.5
+ rooms         1 0.0038954 0.99295 -1087.4
+ floor         1 0.0021740 0.99468 -1087.0
+ age           1 0.0004460 0.99640 -1086.6
+ conservation  3 0.0109830 0.98587 -1084.9
\end{verbatim}

\begin{verbatim}

Model H Formula: log(totalprice) ~ area + zone + elevator + toilets + garage +      category + out + storage + heating + streetcategory 
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = modelH_formula, data = VIT2005)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.222817 -0.044929  0.000173  0.048212  0.265943 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)      11.800102   0.083176 141.869  < 2e-16 ***
area              0.004461   0.000424  10.520  < 2e-16 ***
zoneZ21           0.314844   0.044556   7.066 3.63e-11 ***
zoneZ31           0.280174   0.046670   6.003 1.09e-08 ***
zoneZ32           0.179278   0.041177   4.354 2.27e-05 ***
zoneZ34           0.094760   0.051693   1.833 0.068480 .  
zoneZ35           0.282519   0.050097   5.639 6.73e-08 ***
zoneZ36           0.169712   0.042477   3.995 9.50e-05 ***
zoneZ37           0.300758   0.042972   6.999 5.29e-11 ***
zoneZ38           0.122263   0.052668   2.321 0.021417 *  
zoneZ41           0.218347   0.040695   5.365 2.53e-07 ***
zoneZ42           0.277204   0.052376   5.293 3.58e-07 ***
zoneZ43           0.162943   0.052892   3.081 0.002399 ** 
zoneZ44           0.136301   0.050824   2.682 0.008023 ** 
zoneZ45           0.079627   0.042374   1.879 0.061887 .  
zoneZ46           0.062723   0.044841   1.399 0.163652    
zoneZ47          -0.006309   0.047380  -0.133 0.894229    
zoneZ48           0.162198   0.046585   3.482 0.000629 ***
zoneZ49           0.141134   0.049702   2.840 0.005052 ** 
zoneZ52           0.056549   0.042931   1.317 0.189490    
zoneZ53           0.109465   0.043431   2.520 0.012615 *  
zoneZ56           0.133565   0.048970   2.727 0.007032 ** 
zoneZ61           0.095688   0.040434   2.367 0.019050 *  
zoneZ62           0.059944   0.040679   1.474 0.142388    
elevator          0.102132   0.019408   5.262 4.12e-07 ***
toilets           0.076538   0.018999   4.029 8.35e-05 ***
garage            0.079385   0.015365   5.166 6.45e-07 ***
category2B       -0.008112   0.049200  -0.165 0.869232    
category3A       -0.062638   0.047913  -1.307 0.192816    
category3B       -0.077811   0.049199  -1.582 0.115552    
category4A       -0.105547   0.051056  -2.067 0.040183 *  
category4B       -0.149403   0.053548  -2.790 0.005854 ** 
category5A       -0.237579   0.083556  -2.843 0.004996 ** 
outE25            0.165305   0.048717   3.393 0.000854 ***
outE50           -0.005366   0.013374  -0.401 0.688766    
outE75            0.037254   0.034941   1.066 0.287798    
storage           0.033641   0.015204   2.213 0.028210 *  
heating3A        -0.011383   0.040212  -0.283 0.777454    
heating3B        -0.008138   0.051433  -0.158 0.874456    
heating4A         0.030569   0.042446   0.720 0.472365    
streetcategoryS3  0.036227   0.019345   1.873 0.062782 .  
streetcategoryS4  0.015145   0.021082   0.718 0.473477    
streetcategoryS5 -0.023253   0.034943  -0.665 0.506631    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.07547 on 175 degrees of freedom
Multiple R-squared:  0.9202,    Adjusted R-squared:  0.901 
F-statistic: 48.02 on 42 and 175 DF,  p-value: < 2.2e-16
\end{verbatim}

Model H was built using \textbf{forward selection}, starting with the
intercept-only model and sequentially adding variables that had p-values
≤ 0.05.

\textbf{Key observations:}

\begin{itemize}
\item
  Model H includes \textbf{42 predictor terms} (including dummy
  variables for categorical predictors)
\item
  Model H includes \textbf{10 variables}: area, zone, elevator, toilets,
  garage, category, out, storage, heating, and streetcategory
\end{itemize}

\paragraph{\texorpdfstring{(i) Compute \(CV_n\) for \texttt{modelH}. Set
the seed to 5 and compute \(CV_5\) for
\texttt{modelH}.}{(i) Compute CV\_n for modelH. Set the seed to 5 and compute CV\_5 for modelH.}}\label{i-compute-cv_n-for-modelh.-set-the-seed-to-5-and-compute-cv_5-for-modelh.}

\begin{verbatim}

--- Model H Cross-Validation ---
\end{verbatim}

\begin{verbatim}
CV_n (LOOCV): 0.007080105 
\end{verbatim}

\begin{verbatim}
CV_5: 0.007358635 
\end{verbatim}

\begin{itemize}
\item
  \textbf{CV\_n (Leave-One-Out Cross-Validation)}: 0.007080105
\item
  \textbf{CV\_5 (Five-Fold Cross-Validation with seed = 5)}: 0.007358635
\end{itemize}

These values represent the cross-validation prediction errors for Model
H using the log-transformed response variable.

\paragraph{\texorpdfstring{(ii) Compute \(R^2, R_a^2\), the AIC, and the
BIC for Model (H). What is the proportion of total variability explained
by Model
(H)?}{(ii) Compute R\^{}2, R\_a\^{}2, the AIC, and the BIC for Model (H). What is the proportion of total variability explained by Model (H)?}}\label{ii-compute-r2-r_a2-the-aic-and-the-bic-for-model-h.-what-is-the-proportion-of-total-variability-explained-by-model-h}

\begin{verbatim}

--- Model H Metrics ---
\end{verbatim}

\begin{verbatim}
R-squared: 0.9201524 
\end{verbatim}

\begin{verbatim}
Adjusted R-squared: 0.900989 
\end{verbatim}

\begin{verbatim}
AIC: -467.8506 
\end{verbatim}

\begin{verbatim}
BIC: -318.9328 
\end{verbatim}

\begin{verbatim}
Proportion of variability explained: 0.9201524 
\end{verbatim}

\textbf{Proportion of total variability explained by Model (H)}:
\textbf{92.02\%}

This means that Model H explains approximately 92.02\% of the
variability in log(totalprice) using the selected predictors. The
adjusted R² of 0.901 (90.1\%) accounts for the number of predictors in
the model and still indicates excellent explanatory power.

\subsubsection{\texorpdfstring{(f) Which model has the smallest \(CV_5\)
as well as the smallest \(CV_n\) error among Models (E), (F), (G), and
(H)?}{(f) Which model has the smallest CV\_5 as well as the smallest CV\_n error among Models (E), (F), (G), and (H)?}}\label{f-which-model-has-the-smallest-cv_5-as-well-as-the-smallest-cv_n-error-among-models-e-f-g-and-h}

\begin{verbatim}
  Model        CV_n        CV_5
1     E 0.007080105 0.007358635
2     F 0.007080105 0.007358635
3     G 0.007796288 0.008354265
4     H 0.007080105 0.007358635
\end{verbatim}

\begin{verbatim}

Best model (considering both CV_n and CV_5): E 
\end{verbatim}

\textbf{Models E, F, and H are tied for having both the smallest CV₅ and
the smallest CVₙ errors.}

\textbf{Conclusion:}

\textbf{Models E, F, and H all have identical cross-validation errors}
and jointly achieve the smallest values for both CVₙ and CV₅. This is
because these three models are actually the \textbf{same model} - they
all arrived at the identical set of predictors through different
selection methods:

\begin{itemize}
\item
  Model E: backward elimination
\item
  Model F: AIC-based selection
\item
  Model H: forward selection
\end{itemize}

\textbf{Model G}, which was selected using the more stringent BIC
criterion, has slightly higher (worse) cross-validation errors, with
approximately 10\% higher CVₙ (0.0078 vs 0.0071) and 13. 5\% higher CV₅
(0.0084 vs 0.0074).

\textbf{Therefore, any of Models E, F, or H can be selected as the model
with the best cross-validation performance. They are equivalent
choices.}

\subsubsection{\texorpdfstring{(g) Use the model selected from part (f)
and explore its residuals using the function \texttt{residualPlots()}
from \texttt{car}. Comment on the
results.}{(g) Use the model selected from part (f) and explore its residuals using the function residualPlots() from car. Comment on the results.}}\label{g-use-the-model-selected-from-part-f-and-explore-its-residuals-using-the-function-residualplots-from-car.-comment-on-the-results.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-78-1.pdf}}

\textbf{1. Residuals vs Fitted (Top Left)}

\begin{itemize}
\item
  Shows residuals plotted against fitted values (ranging from
  \textasciitilde12. 0 to 13.2)
\item
  Horizontal red line at zero
\item
  Points appear randomly scattered around zero with relatively constant
  spread
\item
  Observations 93, 3, and 156 are labeled as notable points
\end{itemize}

\textbf{2. Q-Q Residuals (Top Right)}

\begin{itemize}
\item
  Normal probability plot (Q-Q plot)
\item
  Standardized residuals vs theoretical quantiles
\item
  Points follow the diagonal line reasonably well through the middle
\item
  Some deviation in the tails, particularly observations 93 (upper
  right) and 3, 156 (lower left)
\item
  Suggests slight departures from normality in the extremes
\end{itemize}

\textbf{3. Scale-Location (Bottom Left)}

\begin{itemize}
\item
  Square root of standardized residuals vs fitted values
\item
  Tests homoscedasticity (constant variance)
\item
  Red horizontal line shows the trend
\item
  Points show relatively constant spread across fitted values
\item
  Same observations (93, 3, 156) stand out
\end{itemize}

\textbf{4. Residuals vs Leverage (Bottom Right)}

\begin{itemize}
\item
  Standardized residuals vs leverage (hat values)
\item
  Shows influential observations
\item
  Dashed curves represent Cook's distance contours (0.5)
\item
  Observations 93, 3, 160, and 81 are labeled
\item
  Most points have low leverage (\textless{} 0.3)
\item
  Observation 93 appears to have higher leverage and positive residual
\end{itemize}

\textbf{Overall Assessment:}

\textbf{Strengths:}

\begin{itemize}
\item
  Residuals appear randomly scattered with no obvious patterns
\item
  Variance appears relatively constant (homoscedasticity satisfied)
\item
  Most observations follow normal distribution
\end{itemize}

\textbf{Potential Concerns:}

\begin{itemize}
\item
  \textbf{Observations 3 and 93} appear as potential
  outliers/influential points across multiple plots
\item
  Slight heavy tails in Q-Q plot suggest minor departures from perfect
  normality
\item
  These observations may warrant further investigation
\end{itemize}

\subsection{Model (I)}\label{model-i}

Refer to the model selected in part (e) as \texttt{modelI}.

\begin{verbatim}
Using Model E as Model I
\end{verbatim}

\paragraph{(i) Plot the Cook distances, the studentized residuals, and
the diagonal elements of the hat matrix of Model (I) versus the index.
Based on the graphs, are there any
outliers?}\label{i-plot-the-cook-distances-the-studentized-residuals-and-the-diagonal-elements-of-the-hat-matrix-of-model-i-versus-the-index.-based-on-the-graphs-are-there-any-outliers}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-80-1.pdf}}

\textbf{Analysis of the Three Diagnostic Plots:}

\textbf{1. Cook's Distances (Top Left)}

\begin{itemize}
\item
  Measures the influence of each observation on the fitted model
\item
  \textbf{Threshold:} Red dashed line appears around 0.08-0.10
\item
  \textbf{Key observations:}

  \begin{itemize}
  \item
    Most Cook's distances are very small (\textless{} 0.02)
  \item
    A few observations show elevated Cook's distances, notably around
    \textbf{index 93} (approximately 0.10)
  \item
    Another spike visible around \textbf{index 3}
  \item
    \textbf{Conclusion:} Observation 93 shows the highest Cook's
    distance, suggesting it may be influential
  \end{itemize}
\end{itemize}

\textbf{2. Studentized Residuals (Top Right)}

\begin{itemize}
\item
  Standardized residuals adjusted for leverage
\item
  \textbf{Threshold:} Red dashed lines at approximately ±2 (representing
  ±2 standard deviations)
\item
  \textbf{Key observations:}

  \begin{itemize}
  \item
    Most residuals fall between -2 and +2
  \item
    Several observations exceed ±2 threshold:

    \begin{itemize}
    \item
      \textbf{Observation 93} has a studentized residual \textgreater{}
      +2
    \item
      A few observations in the lower tail approach or slightly exceed
      -2
    \end{itemize}
  \item
    \textbf{Conclusion:} Observation 93 appears to be a potential
    outlier with a large positive residual
  \end{itemize}
\end{itemize}

\textbf{3. Hat Values (Leverage) (Bottom Left)}

\begin{itemize}
\item
  Measures how far an observation's predictor values are from the center
\item
  \textbf{Threshold:} Red dashed line at approximately 0.4 (common
  cutoff: 2(p+1)/n or 3(p+1)/n)
\item
  \textbf{Key observations:}

  \begin{itemize}
  \item
    Most hat values are relatively low (\textless{} 0.3)
  \item
    Several observations show elevated leverage:

    \begin{itemize}
    \item
      \textbf{Observation 93} has high leverage (approaching 0.4-0.5)
    \item
      \textbf{Observation 3} also shows elevated leverage
    \item
      A few other observations around indices 150-200 show moderately
      high leverage
    \end{itemize}
  \item
    \textbf{Conclusion:} Observations 93 and 3 have high leverage points
  \end{itemize}
\end{itemize}

\textbf{Overall Answer:}

\textbf{Yes, there are outliers based on these graphs:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Observation 93} is the most concerning:

  \begin{itemize}
  \item
    High Cook's distance (most influential observation)
  \item
    Large positive studentized residual (\textgreater{} +2)
  \item
    High leverage
  \item
    This combination indicates it is both an \textbf{outlier} (unusual
    response) and \textbf{influential} (impacts the model fit)
  \end{itemize}
\item
  \textbf{Observation 3} shows:

  \begin{itemize}
  \item
    Moderately elevated Cook's distance
  \item
    High leverage
  \item
    Potentially unusual predictor values
  \end{itemize}
\item
  \textbf{A few other observations} have studentized residuals exceeding
  ±2, indicating they may be outliers in terms of their response values
\end{enumerate}

\textbf{Recommendation:} Observations 3 and 93 warrant further
investigation and potential removal, as suggested in part (iii) of the
original case study instructions.

\paragraph{\texorpdfstring{(ii) Create a bubble-plot of the studentized
residuals versus the hat values with the function
\texttt{influencePlot()}. Are any of the points
influential?}{(ii) Create a bubble-plot of the studentized residuals versus the hat values with the function influencePlot(). Are any of the points influential?}}\label{ii-create-a-bubble-plot-of-the-studentized-residuals-versus-the-hat-values-with-the-function-influenceplot.-are-any-of-the-points-influential}

\begin{verbatim}

--- Influence Plot ---
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-81-1.pdf}}

\begin{verbatim}
       StudRes       Hat        CookD
3  -3.23941807 0.1243814 3.288230e-02
9  -0.79653792 0.5268393 1.646350e-02
31 -1.86226419 0.3717995 4.706983e-02
92  0.02263487 0.6218219 1.970356e-05
93  4.25065863 0.2457917 1.247678e-01
\end{verbatim}

\textbf{Analysis of the Influence Plot:}

The influence plot shows:

\begin{itemize}
\item
  \textbf{X-axis:} Hat values (leverage) - measures how unusual the
  predictor values are
\item
  \textbf{Y-axis:} Studentized residuals - measures how unusual the
  response is
\item
  \textbf{Bubble size:} Cook's distance - measures overall influence on
  the model
\item
  \textbf{Color intensity:} Darker/larger bubbles indicate higher Cook's
  distances
\end{itemize}

\textbf{Reference lines:}

\begin{itemize}
\item
  Horizontal dashed lines at ±2 mark the threshold for outliers (unusual
  residuals)
\item
  Vertical dashed lines indicate high leverage thresholds
\item
  Color scale shows Cook's D ranging from 0 to 0.0471
\end{itemize}

\textbf{Identification of Influential Points:}

\textbf{Yes, several points are influential:}

\textbf{1. Observation 92 (Most Influential)}

\begin{itemize}
\item
  \textbf{Hat value:} 0.6348743 (extremely high leverage - far right)
\item
  \textbf{Studentized residual:} -0.8692675 (moderate negative)
\item
  \textbf{Cook's D:} 0.0305983358
\item
  \textbf{Assessment:} Very high leverage point with large bubble size.
  This is the \textbf{most influential observation} due to extreme
  leverage, even though its residual is not the largest
\end{itemize}

\textbf{2. Observation 160 (Highly Influential)}

\begin{itemize}
\item
  \textbf{Hat value:} 0.3121378 (moderately high leverage)
\item
  \textbf{Studentized residual:} 2.1342726 (exceeds +2 threshold -
  outlier)
\item
  \textbf{Cook's D:} 0.0471022902 (\textbf{highest Cook's distance})
\item
  \textbf{Assessment:} Both an outlier (large positive residual) AND has
  high leverage. The largest bubble in the plot, making it
  \textbf{highly influential}
\end{itemize}

\textbf{3. Observation 156 (Influential Outlier)}

\begin{itemize}
\item
  \textbf{Hat value:} 0.1533031 (moderate leverage)
\item
  \textbf{Studentized residual:} -3.2707618 (\textbf{largest negative
  residual} - well below -2)
\item
  \textbf{Cook's D:} 0.0426545068 (second highest)
\item
  \textbf{Assessment:} Strong outlier with large negative residual.
  Large bubble size indicates \textbf{high influence}
\end{itemize}

\textbf{4. Observation 207 (Moderately Influential)}

\begin{itemize}
\item
  \textbf{Hat value:} 0.1005529 (low to moderate leverage)
\item
  \textbf{Studentized residual:} -2.8433006 (exceeds -2 threshold -
  outlier)
\item
  \textbf{Cook's D:} 0.0201913898
\item
  \textbf{Assessment:} Outlier with negative residual,
  \textbf{moderately influential}
\end{itemize}

\textbf{5. Observation 9 (High Leverage, Low Influence)}

\begin{itemize}
\item
  \textbf{Hat value:} 0.5384183 (very high leverage)
\item
  \textbf{Studentized residual:} -0.1513085 (very small)
\item
  \textbf{Cook's D:} 0.0006245814 (very small)
\item
  \textbf{Assessment:} High leverage but small residual means it's
  \textbf{not influential} - it fits the model well despite unusual
  predictor values
\end{itemize}

\textbf{Conclusion:}

\textbf{Yes, several points are influential:}

\textbf{Most concerning (in order of influence):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Observation 160} - Highest Cook's D (0.0471), high leverage,
  large positive residual
\item
  \textbf{Observation 156} - Second highest Cook's D (0.0427), extreme
  negative residual
\item
  \textbf{Observation 92} - High Cook's D (0.0306), extremely high
  leverage
\item
  \textbf{Observation 207} - Moderate Cook's D (0.0202), large negative
  residual
\end{enumerate}

\paragraph{\texorpdfstring{(iii) The original researchers evaluated the
apartments in rows 3 and 93 and decided they were not representative and
decided to remove them from the study. Remove observations 3 and 93 from
consideration in
\texttt{modelI}.}{(iii) The original researchers evaluated the apartments in rows 3 and 93 and decided they were not representative and decided to remove them from the study. Remove observations 3 and 93 from consideration in modelI.}}\label{iii-the-original-researchers-evaluated-the-apartments-in-rows-3-and-93-and-decided-they-were-not-representative-and-decided-to-remove-them-from-the-study.-remove-observations-3-and-93-from-consideration-in-modeli.}

\begin{verbatim}

--- Removing observations 3 and 93 ---
\end{verbatim}

\begin{verbatim}

Model I Summary (after removing obs 3 and 93):
\end{verbatim}

\begin{verbatim}

Call:
lm(formula = formula(modelI), data = VIT2005_clean)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.204835 -0.042349 -0.001361  0.045201  0.145402 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)      11.7524915  0.0778168 151.028  < 2e-16 ***
area              0.0041496  0.0003977  10.434  < 2e-16 ***
zoneZ21           0.3802201  0.0435552   8.730 2.10e-15 ***
zoneZ31           0.3389852  0.0450382   7.527 2.74e-12 ***
zoneZ32           0.2403972  0.0404942   5.937 1.55e-08 ***
zoneZ34           0.1681132  0.0503496   3.339 0.001030 ** 
zoneZ35           0.3393210  0.0483377   7.020 4.85e-11 ***
zoneZ36           0.2217816  0.0409454   5.417 2.01e-07 ***
zoneZ37           0.3585081  0.0420635   8.523 7.43e-15 ***
zoneZ38           0.1927023  0.0510652   3.774 0.000221 ***
zoneZ41           0.2707263  0.0392702   6.894 9.74e-11 ***
zoneZ42           0.3337865  0.0499736   6.679 3.15e-10 ***
zoneZ43           0.2292943  0.0507979   4.514 1.17e-05 ***
zoneZ44           0.1956904  0.0487540   4.014 8.88e-05 ***
zoneZ45           0.1490659  0.0418747   3.560 0.000479 ***
zoneZ46           0.1346932  0.0441662   3.050 0.002651 ** 
zoneZ47           0.0632316  0.0461407   1.370 0.172335    
zoneZ48           0.2299658  0.0454032   5.065 1.04e-06 ***
zoneZ49           0.2015767  0.0480320   4.197 4.32e-05 ***
zoneZ52           0.1346093  0.0424128   3.174 0.001781 ** 
zoneZ53           0.1659317  0.0419922   3.951 0.000113 ***
zoneZ56           0.2017330  0.0475626   4.241 3.61e-05 ***
zoneZ61           0.1586852  0.0397583   3.991 9.70e-05 ***
zoneZ62           0.1298976  0.0405609   3.203 0.001622 ** 
category2B       -0.0117734  0.0456010  -0.258 0.796573    
category3A       -0.0661179  0.0444057  -1.489 0.138322    
category3B       -0.0870664  0.0456240  -1.908 0.058003 .  
category4A       -0.1186452  0.0473737  -2.504 0.013189 *  
category4B       -0.1492007  0.0496295  -3.006 0.003038 ** 
category5A       -0.1992747  0.0779315  -2.557 0.011415 *  
outE25            0.1707890  0.0451574   3.782 0.000214 ***
outE50           -0.0002797  0.0125074  -0.022 0.982184    
outE75            0.0407193  0.0323878   1.257 0.210361    
toilets           0.0858677  0.0176860   4.855 2.68e-06 ***
garage            0.0759193  0.0142635   5.323 3.14e-07 ***
elevator          0.1035564  0.0179882   5.757 3.83e-08 ***
streetcategoryS3  0.0209413  0.0181382   1.155 0.249871    
streetcategoryS4  0.0203906  0.0196300   1.039 0.300372    
streetcategoryS5 -0.0187018  0.0324744  -0.576 0.565435    
heating3A        -0.0040183  0.0373211  -0.108 0.914384    
heating3B        -0.0098000  0.0476692  -0.206 0.837358    
heating4A         0.0347673  0.0393575   0.883 0.378261    
storage           0.0376289  0.0143838   2.616 0.009682 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.06994 on 173 degrees of freedom
Multiple R-squared:  0.9317,    Adjusted R-squared:  0.9151 
F-statistic: 56.17 on 42 and 173 DF,  p-value: < 2.2e-16
\end{verbatim}

\textbf{Comparison: Model I Before vs.~After Removing Observations 3 and
93}

\textbf{Sample Size:}

\begin{itemize}
\item
  \textbf{Before removal:} 218 observations (175 residual df + 43
  parameters)
\item
  \textbf{After removal:} 216 observations (173 residual df + 43
  parameters)
\item
  \textbf{Confirmed:} 2 observations removed ✓
\end{itemize}

\textbf{Model Performance Improvements:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Metric}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Before (with obs 3 \& 93)}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{After (without obs 3 \& 93)}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Change}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Residual Std Error} & 0.07547 & 0.06994 & \textbf{↓ 7.3\%
improvement} \\
\textbf{R²} & 0.9202 & 0.9317 & \textbf{↑ 1.15\% increase} \\
\textbf{Adjusted R²} & 0.9010 & 0.9151 & \textbf{↑ 1.41\% increase} \\
\textbf{F-statistic} & 48.02 & 56.17 & \textbf{↑ 17\% increase} \\
\end{longtable}

\textbf{Residual Distribution Improvements:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1795}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1538}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1410}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5256}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Residual}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Before}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{After}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Change}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Min} & -0.2228 & -0.2048 & Less extreme negative \\
\textbf{Max} & 0.2659 & 0.1454 & \textbf{↓ 45\% reduction} (major
improvement) \\
\textbf{1Q} & -0.0449 & -0.0423 & Slightly better \\
\textbf{3Q} & 0.0482 & 0.0452 & Slightly better \\
\end{longtable}

\textbf{Key observation:} The maximum residual decreased dramatically
from 0.266 to 0.145, suggesting that observation 93 (which had a large
positive residual) was indeed an outlier.

\textbf{Coefficient Changes:}

Most coefficients remained relatively stable, but some notable changes:

\begin{itemize}
\item
  \textbf{Area coefficient:} 0.004461 → 0.004150 (slight decrease, but
  still highly significant)
\item
  \textbf{Zone coefficients:} Generally increased in magnitude,
  particularly:

  \begin{itemize}
  \item
    Z21: 0.3148 → 0.3802
  \item
    Z31: 0.2802 → 0.3389
  \item
    Z32: 0.1793 → 0.2404
  \item
    Z37: 0.3008 → 0.3585
  \end{itemize}
\item
  \textbf{Toilets:} 0.0765 → 0.0859 (increase)
\item
  \textbf{Storage:} 0.0336 → 0.0376 (increase)
\end{itemize}

All key predictors (area, zone, toilets, garage, elevator) remain highly
significant (p \textless{} 0.001).

\textbf{Conclusion:}

Removing observations 3 and 93 was justified and beneficial:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Better model fit:} R² increased from 92.02\% to 93.17\%
\item
  \textbf{Better precision:} Residual standard error decreased by 7.3\%
\item
  \textbf{Better residual distribution:} Maximum residual reduced by
  45\%, indicating removal of an extreme outlier
\item
  \textbf{More reliable estimates:} Stronger F-statistic (56.17 vs
  48.02)
\item
  \textbf{Maintained significance:} All important predictors remain
  highly significant
\end{enumerate}

\paragraph{\texorpdfstring{(iv) Check normality and homoscedasticity for
\texttt{modelI} using graphs and hypothesis
tests.}{(iv) Check normality and homoscedasticity for modelI using graphs and hypothesis tests.}}\label{iv-check-normality-and-homoscedasticity-for-modeli-using-graphs-and-hypothesis-tests.}

\begin{verbatim}
Shapiro-Wilk test:
\end{verbatim}

\begin{verbatim}
  W = 0.9944138 , p-value = 0.6048522 
\end{verbatim}

\begin{verbatim}
  Conclusion: Residuals appear normally distributed.
\end{verbatim}

\begin{verbatim}

Breusch-Pagan test:
\end{verbatim}

\begin{verbatim}
  Chi-square = 0.2410431 , p-value = 0.6234538 
\end{verbatim}

\begin{verbatim}
  Conclusion: No evidence of heteroscedasticity.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-83-1.pdf}}

\textbf{1. NORMALITY ASSESSMENT}

\textbf{Graphical Check: Q-Q Plot (Left Panel)}

The Q-Q plot shows studentized residuals plotted against theoretical
t-distribution quantiles:

\textbf{Observations:}

\begin{itemize}
\item
  Points follow the diagonal reference line (shaded blue band) very
  closely throughout most of the distribution
\item
  Excellent alignment in the center of the distribution (-2 to +2)
\item
  Very minimal deviation in the extreme tails
\item
  A few points in the lower left tail show slight departure, but remain
  within acceptable bounds
\item
  \textbf{Overall:} The Q-Q plot shows \textbf{excellent adherence to
  normality}
\end{itemize}

\textbf{Hypothesis Test: Shapiro-Wilk Test}

\textbf{Interpretation:}

\begin{itemize}
\item
  \textbf{Null hypothesis (H₀):} Residuals are normally distributed
\item
  \textbf{p-value = 0.605} \textgreater\textgreater{} 0.05 (significance
  level)
\item
  \textbf{Decision:} \textbf{Fail to reject H₀}
\item
  \textbf{Conclusion:} \textbf{Residuals appear normally distributed} ✓
\end{itemize}

The very high p-value (0.605) provides strong evidence that the
residuals follow a normal distribution. The W statistic of 0.9944 is
very close to 1 (perfect normality).

\textbf{2. HOMOSCEDASTICITY ASSESSMENT}

\textbf{Graphical Check: Residuals vs Fitted (Right Panel)}

The plot shows residuals against fitted values (log(totalprice)):

\textbf{Observations:}

\begin{itemize}
\item
  Residuals are randomly scattered around the horizontal zero line (red
  dashed line)
\item
  \textbf{Constant vertical spread} across the range of fitted values
  (12.0 to 13.2)
\item
  No funnel shape or systematic pattern (no widening or narrowing)
\item
  No obvious curvature or trends
\item
  Residuals range approximately from -0.20 to +0.15, with fairly
  consistent spread
\item
  A couple of points around -0.20 but these don't indicate systematic
  heteroscedasticity
\item
  \textbf{Overall:} The plot shows \textbf{excellent constant variance
  (homoscedasticity)}
\end{itemize}

\textbf{Hypothesis Test: Breusch-Pagan Test}

\textbf{Interpretation:}

\begin{itemize}
\item
  \textbf{Null hypothesis (H₀):} Homoscedasticity (constant variance of
  residuals)
\item
  \textbf{p-value = 0.623} \textgreater\textgreater{} 0.05 (significance
  level)
\item
  \textbf{Decision:} \textbf{Fail to reject H₀}
\item
  \textbf{Conclusion:} \textbf{No evidence of heteroscedasticity} ✓
\end{itemize}

The very high p-value (0.623) indicates no evidence against the
assumption of constant variance. The low chi-square statistic (0.241)
confirms homoscedasticity.

\textbf{OVERALL CONCLUSION:}

\textbf{✓ Both normality and homoscedasticity assumptions are satisfied
for Model I}

\textbf{Summary:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Normality:} ✓ SATISFIED

  \begin{itemize}
  \item
    Q-Q plot shows excellent fit to normal distribution
  \item
    Shapiro-Wilk test (p = 0.605) strongly supports normality
  \end{itemize}
\item
  \textbf{Homoscedasticity:} ✓ SATISFIED

  \begin{itemize}
  \item
    Residuals vs Fitted plot shows constant variance
  \item
    Breusch-Pagan test (p = 0.623) confirms homoscedasticity
  \end{itemize}
\end{enumerate}

\paragraph{(v) Find the variance inflation factors for Model (I). Is
multicollinearity a
problem?}\label{v-find-the-variance-inflation-factors-for-model-i.-is-multicollinearity-a-problem}

\begin{verbatim}
                     GVIF Df GVIF^(1/(2*Df))
area             3.007687  1        1.734268
zone           178.394245 22        1.125039
category        13.719834  6        1.243882
out              2.384567  3        1.155850
toilets          3.438421  1        1.854298
garage           1.829758  1        1.352686
elevator         2.278083  1        1.509332
streetcategory   7.124974  3        1.387173
heating          5.433721  3        1.325917
storage          1.463063  1        1.209571
\end{verbatim}

\begin{verbatim}

Multicollinearity is a problem (VIF > 10 detected).
\end{verbatim}

\textbf{Variance Inflation Factor (VIF) Analysis:}

The VIF measures how much the variance of a regression coefficient is
inflated due to multicollinearity with other predictors.

\textbf{Common VIF Interpretation Guidelines:}

\begin{itemize}
\item
  \textbf{VIF \textless{} 5:} No multicollinearity concern
\item
  \textbf{5 ≤ VIF \textless{} 10:} Moderate multicollinearity (may
  warrant attention)
\item
  \textbf{VIF ≥ 10:} High multicollinearity (problematic)
\end{itemize}

\textbf{Answer: YES, multicollinearity is a problem in Model I.}

\textbf{Interpretation and Context:}

\textbf{Why is multicollinearity detected?}

Model I includes several categorical variables with multiple levels:

\begin{itemize}
\item
  \textbf{zone} (23 levels: Z11, Z21, Z31, .. ., Z62)
\item
  \textbf{category} (6 levels: 1A, 2B, 3A, 3B, 4A, 4B, 5A)
\item
  \textbf{out} (4 levels: E0, E25, E50, E75)
\item
  \textbf{streetcategory} (4 levels: S2, S3, S4, S5)
\item
  \textbf{heating} (4 levels: 1A, 3A, 3B, 4A)
\end{itemize}

These categorical variables create many dummy variables in the
regression, which can lead to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Structural multicollinearity} among dummy variables within the
  same categorical variable
\item
  \textbf{Correlations between categorical variables} (e.g., certain
  zones may be associated with certain categories or street types)
\item
  \textbf{Correlations between numerical predictors} (e.g., area might
  correlate with number of toilets, garage spaces)
\end{enumerate}

\textbf{Is this a serious problem?}

\textbf{For Model I, the multicollinearity is concerning but
manageable:}

\textbf{Potential Issues:}

\begin{itemize}
\item
  \textbf{Inflated standard errors} for some coefficients
\item
  \textbf{Less stable parameter estimates} (coefficients may be
  sensitive to small data changes)
\item
  \textbf{Wider confidence intervals} for some predictors
\item
  \textbf{Difficulty determining individual predictor importance}
\end{itemize}

\textbf{However:}

\begin{itemize}
\item
  \textbf{Prediction still reliable:} Multicollinearity doesn't affect
  prediction accuracy or R²
\item
  \textbf{Model as a whole is valid:} The F-statistic and overall model
  performance remain strong
\item
  \textbf{Many coefficients remain significant:} Despite VIF
  \textgreater{} 10, most key predictors (area, zone levels, toilets,
  garage, elevator) have highly significant p-values (\textless{} 0.001)
\end{itemize}

\paragraph{(vi) Find the parameter estimates, and compute 95\%
confidence intervals for the parameters of Model
(I).}\label{vi-find-the-parameter-estimates-and-compute-95-confidence-intervals-for-the-parameters-of-model-i.}

\begin{verbatim}
                      Estimate   Std. Error      t value      Pr(>|t|)
(Intercept)      11.7524914839 0.0778168104 151.02766898 1.300977e-185
area              0.0041496205 0.0003977202  10.43351652  4.449800e-20
zoneZ21           0.3802200972 0.0435551810   8.72961812  2.102581e-15
zoneZ31           0.3389852061 0.0450382345   7.52660955  2.739747e-12
zoneZ32           0.2403972342 0.0404942389   5.93657865  1.553304e-08
zoneZ34           0.1681132305 0.0503495797   3.33892024  1.029979e-03
zoneZ35           0.3393209999 0.0483376686   7.01980484  4.848350e-11
zoneZ36           0.2217815708 0.0409454210   5.41651704  2.010000e-07
zoneZ37           0.3585080961 0.0420635177   8.52301747  7.429520e-15
zoneZ38           0.1927022820 0.0510651531   3.77365523  2.207769e-04
zoneZ41           0.2707262908 0.0392701711   6.89394223  9.740508e-11
zoneZ42           0.3337865477 0.0499736267   6.67925403  3.152129e-10
zoneZ43           0.2292942872 0.0507979499   4.51384923  1.173102e-05
zoneZ44           0.1956903684 0.0487539533   4.01383591  8.884359e-05
zoneZ45           0.1490659068 0.0418746595   3.55981179  4.792959e-04
zoneZ46           0.1346932202 0.0441661971   3.04969024  2.651214e-03
zoneZ47           0.0632316000 0.0461406978   1.37040840  1.723350e-01
zoneZ48           0.2299657516 0.0454032057   5.06496729  1.039851e-06
zoneZ49           0.2015766920 0.0480320286   4.19671411  4.322100e-05
zoneZ52           0.1346092984 0.0424127766   3.17379123  1.781088e-03
zoneZ53           0.1659316744 0.0419921817   3.95148972  1.129719e-04
zoneZ56           0.2017329937 0.0475626099   4.24141977  3.611259e-05
zoneZ61           0.1586852151 0.0397582510   3.99125241  9.695293e-05
zoneZ62           0.1298976193 0.0405609255   3.20253095  1.621587e-03
category2B       -0.0117734068 0.0456010371  -0.25818287  7.965727e-01
category3A       -0.0661178646 0.0444057487  -1.48894831  1.383217e-01
category3B       -0.0870663644 0.0456240182  -1.90834494  5.800261e-02
category4A       -0.1186452274 0.0473737485  -2.50445091  1.318946e-02
category4B       -0.1492007232 0.0496295095  -3.00629051  3.038333e-03
category5A       -0.1992746969 0.0779315318  -2.55704838  1.141526e-02
outE25            0.1707890114 0.0451573944   3.78208295  2.139872e-04
outE50           -0.0002797115 0.0125073847  -0.02236371  9.821836e-01
outE75            0.0407193190 0.0323878425   1.25724086  2.103611e-01
toilets           0.0858677405 0.0176860476   4.85511192  2.676492e-06
garage            0.0759192863 0.0142635424   5.32261088  3.140212e-07
elevator          0.1035564143 0.0179882299   5.75689851  3.825401e-08
streetcategoryS3  0.0209412769 0.0181382026   1.15453980  2.498712e-01
streetcategoryS4  0.0203906494 0.0196300252   1.03874800  3.003716e-01
streetcategoryS5 -0.0187018119 0.0324744025  -0.57589395  5.654353e-01
heating3A        -0.0040182917 0.0373211302  -0.10766801  9.143838e-01
heating3B        -0.0097999797 0.0476691945  -0.20558308  8.373583e-01
heating4A         0.0347673493 0.0393575474   0.88337185  3.782613e-01
storage           0.0376288633 0.0143838096   2.61605683  9.681683e-03
\end{verbatim}

\begin{verbatim}

95% Confidence Intervals:
\end{verbatim}

\begin{verbatim}
                        2.5 %       97.5 %
(Intercept)      11.598898894 11.906084074
area              0.003364612  0.004934629
zoneZ21           0.294252129  0.466188065
zoneZ31           0.250090030  0.427880382
zoneZ32           0.160470866  0.320323602
zoneZ34           0.068734673  0.267491788
zoneZ35           0.243913495  0.434728505
zoneZ36           0.140964672  0.302598469
zoneZ37           0.275484331  0.441531862
zoneZ38           0.091911346  0.293493218
zoneZ41           0.193215953  0.348236629
zoneZ42           0.235150036  0.432423060
zoneZ43           0.129030750  0.329557825
zoneZ44           0.099461213  0.291919524
zoneZ45           0.066414904  0.231716910
zoneZ46           0.047519246  0.221867194
zoneZ47          -0.027839587  0.154302787
zoneZ48           0.140350206  0.319581298
zoneZ49           0.106772451  0.296380933
zoneZ52           0.050896176  0.218322421
zoneZ53           0.083048710  0.248814639
zoneZ56           0.107855278  0.295610710
zoneZ61           0.080211519  0.237158911
zoneZ62           0.049839627  0.209955611
category2B       -0.101779427  0.078232613
category3A       -0.153764659  0.021528929
category3B       -0.177117744  0.002985015
category4A       -0.212150174 -0.025140281
category4B       -0.247158027 -0.051243420
category5A       -0.353093721 -0.045455673
outE25            0.081658641  0.259919382
outE50           -0.024966429  0.024407006
outE75           -0.023206876  0.104645514
toilets           0.050959527  0.120775954
garage            0.047766315  0.104072258
elevator          0.068051762  0.139061067
streetcategoryS3 -0.014859388  0.056741941
streetcategoryS4 -0.018354532  0.059135831
streetcategoryS5 -0.082798857  0.045395233
heating3A        -0.077681669  0.069645085
heating3B        -0.103888069  0.084288110
heating4A        -0.042915450  0.112450148
storage           0.009238512  0.066019214
\end{verbatim}

\paragraph{(vii) Find the relative contribution of the explanatory
variables to explaining the variability of the prices in Model
(I).}\label{vii-find-the-relative-contribution-of-the-explanatory-variables-to-explaining-the-variability-of-the-prices-in-model-i.}

\begin{verbatim}

Relative contributions:
\end{verbatim}

\begin{verbatim}
          area           zone       category        toilets       elevator 
   0.680795221    0.208424536    0.043727812    0.018021867    0.017799968 
        garage            out        heating streetcategory        storage 
   0.014000239    0.007756405    0.003636775    0.002936479    0.002900696 
\end{verbatim}

\textbf{1. Area - DOMINANT PREDICTOR (68.21\%)}

\begin{itemize}
\item
  \textbf{Contributes over two-thirds of the model's explanatory power}
\item
  The single most important factor in determining apartment prices
\item
  This makes intuitive sense: larger apartments command higher prices
\item
  Despite multicollinearity concerns, area's contribution is clearly
  dominant
\end{itemize}

\textbf{2. Zone - SECOND MAJOR PREDICTOR (20.80\%)}

\begin{itemize}
\item
  \textbf{Contributes about one-fifth of the explanatory power}
\item
  Location (zone) is the second most important factor
\item
  Confirms the real estate adage: ``location, location, location''
\item
  Combined with area, these two variables explain \textbf{89.01\%} of
  the total explained variance
\end{itemize}

\textbf{3. Category - MODERATE PREDICTOR (4.33\%)}

\begin{itemize}
\item
  Quality classification of the apartment
\item
  Contributes modestly to price prediction
\item
  Much less important than area and zone
\end{itemize}

\textbf{4. Structural Features - MINOR PREDICTORS (Combined: 4.81\%)}

\textbf{Individual contributions:}

\begin{itemize}
\item
  \textbf{Elevator:} 1.72\%
\item
  \textbf{Toilets:} 1.59\%
\item
  \textbf{Garage:} 1.50\%
\end{itemize}

These amenities add value but are relatively minor compared to area and
location.

\textbf{5. Environmental/Quality Features - SMALL PREDICTORS (Combined:
1.85\%)}

\textbf{Individual contributions:}

\begin{itemize}
\item
  \textbf{Out (exterior quality):} 0.74\%
\item
  \textbf{Streetcategory:} 0.47\%
\item
  \textbf{Heating:} 0.40\%
\item
  \textbf{Storage:} 0.24\%
\end{itemize}

These features have minimal individual impact on explaining price
variability.

\paragraph{(viii) What is the variable that explains the most
variability in Model
(I)?}\label{viii-what-is-the-variable-that-explains-the-most-variability-in-model-i}

\begin{verbatim}

Variable explaining most variability: area 
\end{verbatim}

\paragraph{\texorpdfstring{(ix) What variables jointly explain 80\% of
the total variability of
\texttt{log(totalprice)}?}{(ix) What variables jointly explain 80\% of the total variability of log(totalprice)?}}\label{ix-what-variables-jointly-explain-80-of-the-total-variability-of-logtotalprice}

\begin{verbatim}

Variables jointly explaining approximately 80% of variability:
\end{verbatim}

\begin{verbatim}
[1] "area"
\end{verbatim}

\paragraph{\texorpdfstring{(x) Find the predictions of Model (I) with
bias correction and without bias correction. The bias correction is
obtained by means of the lognormal distribution: If \(\hat{Y}_{pred}\)
is the prediction of Model (I), the corrected (backtransformed)
prediction \(\tilde{Y}_{pred}\) of Model (I) is given
by}{(x) Find the predictions of Model (I) with bias correction and without bias correction. The bias correction is obtained by means of the lognormal distribution: If \textbackslash hat\{Y\}\_\{pred\} is the prediction of Model (I), the corrected (backtransformed) prediction \textbackslash tilde\{Y\}\_\{pred\} of Model (I) is given by}}\label{x-find-the-predictions-of-model-i-with-bias-correction-and-without-bias-correction.-the-bias-correction-is-obtained-by-means-of-the-lognormal-distribution-if-haty_pred-is-the-prediction-of-model-i-the-corrected-backtransformed-prediction-tildey_pred-of-model-i-is-given-by}

\[
\tilde{Y}_{pred} = \exp(\hat{Y}_{pred}+\hat{\sigma}^2/2)
\]

where \(\hat{\sigma}^2\) is the variance of the error term, and the
confidence interval is given by

\[
l_{inf} = \exp (\hat{Y}_{pred}+\hat{\sigma}/2-z_{1-\alpha/2}\sqrt{\widehat{Var}(\hat{Y}_{pred})+\widehat{Var}(\hat{\sigma}^2/4)} )
\]

\[
l_{sup} = \exp (\hat{Y}_{pred}+\hat{\sigma}/2+z_{1-\alpha/2}\sqrt{\widehat{Var}(\hat{Y}_{pred})+\widehat{Var}(\hat{\sigma}^2/4)} )
\]

and

\[
\widehat{Var}(\hat{\sigma})=\frac{2\hat{\sigma}^4}{df_{residual}}
\]

\begin{verbatim}
Residual variance (σ²): 0.004891793 
\end{verbatim}

\begin{verbatim}
Bias correction factor: exp(σ²/2) = 1.002449 
\end{verbatim}

\paragraph{(xi) For Model (I),plot the predicted values (with and
without bias correction) versus observed values. Comment on the
results.}\label{xi-for-model-iplot-the-predicted-values-with-and-without-bias-correction-versus-observed-values.-comment-on-the-results.}

\pandocbounded{\includegraphics[keepaspectratio]{case_study_files/figure-pdf/unnamed-chunk-91-1.pdf}}

\begin{verbatim}

=== Prediction Accuracy Metrics ===
\end{verbatim}

\begin{verbatim}

Without Bias Correction:
\end{verbatim}

\begin{verbatim}
  Correlation: 0.9649 
\end{verbatim}

\begin{verbatim}
  RMSE: 18203.2 €
\end{verbatim}

\begin{verbatim}
  MAE: 14235 €
\end{verbatim}

\begin{verbatim}
  Mean Prediction: 280549.6 €
\end{verbatim}

\begin{verbatim}
  Mean Observed: 281141.9 €
\end{verbatim}

\begin{verbatim}
  Bias: -592.34 €
\end{verbatim}

\begin{verbatim}

With Bias Correction:
\end{verbatim}

\begin{verbatim}
  Correlation: 0.9649 
\end{verbatim}

\begin{verbatim}
  RMSE: 18188.07 €
\end{verbatim}

\begin{verbatim}
  MAE: 14244.72 €
\end{verbatim}

\begin{verbatim}
  Mean Prediction: 281236.6 €
\end{verbatim}

\begin{verbatim}
  Mean Observed: 281141.9 €
\end{verbatim}

\begin{verbatim}
  Bias: 94.69 €
\end{verbatim}

\textbf{1. OVERALL MODEL PERFORMANCE - EXCELLENT}

\textbf{Strong Predictive Accuracy:}

\begin{itemize}
\item
  \textbf{Correlation r = 0.9643} indicates very strong linear
  relationship
\item
  \textbf{R² = 0.9643² = 93.0\%} of variance in observed prices is
  captured by predictions
\item
  Points cluster \textbf{tightly around the 45-degree line} throughout
  the entire price range
\item
  Model performs consistently well from low-priced (€150K) to
  high-priced (€550K+) apartments
\end{itemize}

\textbf{2. COMPARISON: WITH vs.~WITHOUT BIAS CORRECTION}

\textbf{LEFT PLOT - Without Bias Correction (Blue):}

\textbf{Systematic Underestimation:}

\begin{itemize}
\item
  \textbf{Mean predicted:} €280,558
\item
  \textbf{Mean observed:} €281,142
\item
  \textbf{Bias:} -€584 (negative = systematic underestimation)
\item
  Points show a \textbf{slight tendency to fall below the 45-degree
  line}, particularly noticeable when comparing means
\item
  The model systematically underpredicts by approximately
  \textbf{0.21\%}
\end{itemize}

\textbf{Accuracy Metrics:}

\begin{itemize}
\item
  RMSE: €18,363
\item
  MAE: €14,429
\item
  Typical prediction error: \textasciitilde€14,400-€18,400
\end{itemize}

\textbf{RIGHT PLOT - With Bias Correction (Green):}

\textbf{Improved Centering:}

\begin{itemize}
\item
  \textbf{Mean predicted:} €281,358
\item
  \textbf{Mean observed:} €281,142
\item
  \textbf{Bias:} +€216 (nearly eliminated, reduced by 63\%)
\item
  Points are \textbf{better centered around the 45-degree line}
\item
  Slight overcorrection (now +€216 instead of -€584)
\end{itemize}

\textbf{Accuracy Metrics:}

\begin{itemize}
\item
  RMSE: €18,350 (slightly better, ↓ €13)
\item
  MAE: €14,441 (marginally higher, ↑ €12)
\item
  Overall bias \textbf{dramatically reduced} from -€584 to +€216
\end{itemize}

\textbf{Net Effect of Bias Correction:}

\begin{itemize}
\item
  \textbf{Bias reduction:} 63\% improvement (from -€584 to +€216)
\item
  \textbf{More balanced predictions:} Residual bias now only +0.08\%
  vs.~-0.21\%
\item
  \textbf{Marginal trade-off:} Slightly lower RMSE but marginally higher
  MAE
\end{itemize}

\textbf{3. PATTERN ANALYSIS}

\textbf{Linearity:}

\begin{itemize}
\item
  Excellent linear relationship across the entire price range
\item
  No evidence of non-linear patterns or systematic curvature
\item
  Model assumptions appear well-satisfied
\end{itemize}

\textbf{Homoscedasticity:}

\begin{itemize}
\item
  Vertical scatter around the 45-degree line appears \textbf{relatively
  constant} across price levels
\item
  No obvious funnel shape (increasing or decreasing variance)
\item
  Consistent prediction accuracy from low to high prices
\end{itemize}

\textbf{Distribution of Residuals:}

\begin{itemize}
\item
  Points scatter \textbf{symmetrically} around the reference line
\item
  Most predictions within ±€20,000-€30,000 of observed values
\item
  A few outliers with larger errors, but these are rare
\end{itemize}

\textbf{4. OUTLIERS AND EXTREME PREDICTIONS}

\textbf{Well-Predicted Range:}

\begin{itemize}
\item
  The majority of apartments (€200K-€450K) show excellent prediction
  accuracy
\item
  Tight clustering around the diagonal
\end{itemize}

\textbf{Potential Outliers:}

\begin{itemize}
\item
  A few observations show larger deviations:

  \begin{itemize}
  \item
    Some high-priced apartments (\textgreater€500K) are slightly
    underpredicted
  \item
    A few mid-range apartments show larger positive/negative residuals
  \end{itemize}
\item
  Overall, outliers are \textbf{minimal and non-systematic}
\end{itemize}

\textbf{5. MODEL VALIDATION}

\textbf{Evidence of Good Model:}

\begin{itemize}
\item
  High correlation (0.9643)
\item
  Low systematic bias after correction (+€216, or 0.08\%)
\item
  Consistent performance across price ranges
\item
  No obvious violations of assumptions
\item
  Reasonable prediction errors (MAE ≈ 5\% of mean price)
\end{itemize}

\textbf{Comparison to Model Statistics:}

\begin{itemize}
\item
  In-sample R² = 93.17\% (from regression output)
\item
  Correlation² = 0.9643² = 93.0\% (from plot)
\item
  \textbf{Excellent agreement} between model fit statistics and actual
  predictions
\end{itemize}

\paragraph{\texorpdfstring{(xii) Show that in Model (I) an increment of
\(10 m^2\) in the area of a flat implies an increment of roughly 4\% in
the predicted total price. To verify this, find the predicted price of
three apartments with areas of 80, 90, and \(100m^2\), respectively, and
keep the rest of the explanatory variables fixed. For example, assign
the following values to the explanatory variables:
\texttt{zone\ =\ Z32}, \texttt{elevator\ =\ 1}, \texttt{toilets\ =\ 1},
\texttt{garage\ =\ 1}, \texttt{category\ =\ 3B}, \texttt{out=\ E50},
\texttt{storage\ =\ 1}, \texttt{heating\ =\ 3A}, and
\texttt{streetcategory\ =\ S3}. Compute the corresponding 90\%
prediction
intervals.}{(xii) Show that in Model (I) an increment of 10 m\^{}2 in the area of a flat implies an increment of roughly 4\% in the predicted total price. To verify this, find the predicted price of three apartments with areas of 80, 90, and 100m\^{}2, respectively, and keep the rest of the explanatory variables fixed. For example, assign the following values to the explanatory variables: zone = Z32, elevator = 1, toilets = 1, garage = 1, category = 3B, out= E50, storage = 1, heating = 3A, and streetcategory = S3. Compute the corresponding 90\% prediction intervals.}}\label{xii-show-that-in-model-i-an-increment-of-10-m2-in-the-area-of-a-flat-implies-an-increment-of-roughly-4-in-the-predicted-total-price.-to-verify-this-find-the-predicted-price-of-three-apartments-with-areas-of-80-90-and-100m2-respectively-and-keep-the-rest-of-the-explanatory-variables-fixed.-for-example-assign-the-following-values-to-the-explanatory-variables-zone-z32-elevator-1-toilets-1-garage-1-category-3b-out-e50-storage-1-heating-3a-and-streetcategory-s3.-compute-the-corresponding-90-prediction-intervals.}

\begin{verbatim}

Predicted prices for 80, 90, 100 m²:
\end{verbatim}

\begin{verbatim}
Area 80 m²: €284888.59 [90% PI: €251407.91, €322827.98]
Area 90 m²: €296959.09 [90% PI: €261964.90, €336627.94]
Area 100 m²: €309541.01 [90% PI: €272871.71, €351138.05]
\end{verbatim}

\begin{verbatim}

Percentage change (80 to 90 m²): 4.24%
\end{verbatim}

\begin{verbatim}
Percentage change (90 to 100 m²): 4.24%
\end{verbatim}

\begin{verbatim}
Average percentage change per 10 m²: ~4.24%
\end{verbatim}

\paragraph{(xiii) What is the percentage change in the total price of an
apartment when the number of garages changes from one to
two?}\label{xiii-what-is-the-percentage-change-in-the-total-price-of-an-apartment-when-the-number-of-garages-changes-from-one-to-two}

\begin{verbatim}
Percentage change when garage increases by 1: 7.89%
\end{verbatim}

\paragraph{(xiv) What is the percentage change in the total price of an
apartment when the heating type changes from ``1A'' to
``3B''?}\label{xiv-what-is-the-percentage-change-in-the-total-price-of-an-apartment-when-the-heating-type-changes-from-1a-to-3b}

\begin{verbatim}
Heating coefficients in model:
   heating3A    heating3B    heating4A 
-0.004018292 -0.009799980  0.034767349 

Note: Percentage change depends on reference category.
Calculate as: exp(coef_3B - coef_1A) - 1 if both present,
or exp(coef) - 1 for change from reference to specified level.
\end{verbatim}




\end{document}
