---
title: "Case_Study"
format: html
editor: visual
---

# Case Study 1: Biomass

*Data and ideas for this case study come from (Goicoa et al., 2011).*

To estimate the amount of carbon dioxide retained in a tree, its biomass needs to be known and multiplied by an expansion factor (there are several alternatives in the literature). To calculate the biomass, specific regression equations by species are frequently used. These regression equations, called allometric equations, estimate the biomass of the tree by means of some known characteristics, typically diameter and/or height of the stem and branches. The BIOMASS file contains data of 42 beeches (Fagus Sylvatica) from a forest of Navarra (Spain) in 2006, where

• `diameter`: diameter of the stem in centimeters

• `height`: height of the tree in meters

• `stemweight`: weight of the stem in kilograms

• `aboveweight`: aboveground weight in kilograms

```{r}
library(PASWR2)
data(BIOMASS)
head(BIOMASS)
```

#### (a) Create a scatterplot of aboveweight versus diameter. Is the relationship linear? Superimpose a regression line over the plot just created.

```{r}
library(ggplot2)
library(car)

# Create scatterplot with regression line
plot_a <- ggplot(BIOMASS, aes(x = diameter, y = aboveweight)) +
  geom_point(size = 3, color = "darkblue", alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1) +
  labs(title = "Aboveground Weight vs Diameter",
       x = "Diameter (cm)",
       y = "Aboveground Weight (kg)") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(plot_a)
```

**No, the relationship is NOT linear.**

**Observations:**

1.  **Curved Pattern**: The scatterplot shows a clear **curvilinear (non-linear) relationship** between diameter and aboveground weight. The data points follow a curved pattern rather than a straight line.

2.  **Accelerating Growth**: The relationship appears to be **exponential or power-law** in nature. As diameter increases, the aboveground weight increases at an accelerating rate (the curve becomes steeper).

3.  **Poor Linear Fit**: While the red regression line has been superimposed on the plot, you can see that:

    -   At small diameters (left side), the line overestimates the weight

    -   In the middle range, the fit is reasonable

    -   At large diameters (right side), the line underestimates the weight

    -   This systematic pattern of residuals (points above and below the line in a curved pattern) indicates that a linear model is **not appropriate** for this data.

4.  **Biological Interpretation**: This makes biological sense because tree biomass is related to volume, which grows as a function of diameter raised to a power (typically around 2-3), not linearly.

#### (b) Create a scatterplot of $\log(aboveweight)$ versus $\log(diameter)$. Is the relationship linear? Superimpose a regression line over the plot just created.

```{r}
# Create log-transformed scatterplot
plot_b <- ggplot(BIOMASS, aes(x = log(diameter), y = log(aboveweight))) +
  geom_point(size = 3, color = "darkgreen", alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1) +
  labs(title = "Log(Aboveground Weight) vs Log(Diameter)",
       x = "Log(Diameter)",
       y = "Log(Aboveground Weight)") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(plot_b)
```

**Yes, the relationship is linear.**

**Observations:**

1.  **Strong Linear Pattern**: After the log transformation, the data points now follow a clear **straight-line pattern**. The points are distributed closely around the red regression line with no systematic curvature.

2.  **Excellent Linear Fit**: The regression line fits the data much better than in part (a):

    -   Points are randomly scattered above and below the line

    -   No systematic pattern of over/under-estimation across the range

    -   The residuals appear to have constant variance (homoscedastic)

    -   Very tight clustering around the line suggests high R²

3.  **Success of Log Transformation**: The log-log transformation has successfully **linearized** the power-law relationship that was evident in part (a). This transformation is standard for allometric equations.

4.  **Mathematical Interpretation**: The linear relationship in log-log space indicates that the original relationship follows a power law: $\log(aboveweight) = β_0 + β_1 \log(diameter)$ Which corresponds to the power relationship: $aboveweight = \exp(β_0) × diameter^{β_1}$

5.  **Allometric Equation**: This is exactly the form expected for allometric equations in biology, where biomass scales as a power function of dimensional measurements like diameter.

#### (c) Fit the regression model $\log(aboveweight) = β_0 + β_1\log(diameter)$, and compute $R^2, R^2_a$ and the variance of the residuals.

```{r}
# Fit the model
model_c <- lm(log(aboveweight) ~ log(diameter), data = BIOMASS)

# Display results
cat("\nModel Summary:\n")
print(summary(model_c))

# Extract R-squared values
r_squared_c <- summary(model_c)$r.squared
r_squared_adj_c <- summary(model_c)$adj.r.squared
residual_var_c <- summary(model_c)$sigma^2

cat("\n--- Model Statistics ---\n")
cat(sprintf("R-squared: %.4f\n", r_squared_c))
cat(sprintf("Adjusted R-squared: %.4f\n", r_squared_adj_c))
cat(sprintf("Residual variance (σ²): %.4f\n", residual_var_c))
```

#### (d) Introduce $log(height)$ as an explanatory variable and fit the model$\log(aboveweight) =β_0 + β_1 \log(diameter) + β_2 \log(height)$. What is the effect of introducing log(height)in the model?

```{r}
# Fit the multiple regression model
model_d <- lm(log(aboveweight) ~ log(diameter) + log(height), data = BIOMASS)

# Display results
cat("\nModel Summary:\n")
print(summary(model_d))

# Extract R-squared values
r_squared_d <- summary(model_d)$r.squared
r_squared_adj_d <- summary(model_d)$adj.r.squared
residual_var_d <- summary(model_d)$sigma^2

cat("\n--- Effect of Adding log(height) ---\n")
cat(sprintf("Change in R²: %.4f → %.4f (Δ = %.4f)\n", 
            r_squared_c, r_squared_d, r_squared_d - r_squared_c))
cat(sprintf("Change in Adjusted R²: %.4f → %.4f (Δ = %.4f)\n", 
            r_squared_adj_c, r_squared_adj_d, r_squared_adj_d - r_squared_adj_c))
cat(sprintf("Change in Residual Variance: %.4f → %.4f (Δ = %.4f)\n", 
            residual_var_c, residual_var_d, residual_var_d - residual_var_c))
```

#### (e) Complete the Analysis questions for the model in (d).

#### Analysis questions:

##### (1) Estimate the model’s parameters and their standard errors. Provide an interpretation for the model’s parameters.

```{r}
coef_summary <- summary(model_d)$coefficients
print(coef_summary)

cat("\nInterpretation:\n")
cat(sprintf("β₀ (Intercept) = %.4f: Log of expected aboveground weight when\n", 
            coef(model_d)[1]))
cat("                        log(diameter) and log(height) are zero.\n")
cat(sprintf("β₁ (log diameter) = %.4f: A 1%% increase in diameter is associated with\n", 
            coef(model_d)[2]))
cat(sprintf("                          approximately a %.2f%% increase in aboveground weight,\n", 
            coef(model_d)[2]))
cat("                          holding height constant.\n")
cat(sprintf("β₂ (log height) = %.4f: A 1%% increase in height is associated with\n", 
            coef(model_d)[3]))
cat(sprintf("                        approximately a %.2f%% increase in aboveground weight,\n", 
            coef(model_d)[3]))
cat("                        holding diameter constant.\n")
```

##### (2) Compute the variance-covariance matrix of the $\hat{\beta}_s$.

```{r}
vcov_matrix <- vcov(model_d)
print(vcov_matrix)
```

##### (3) Provide 95% confidence intervals for $\beta_1$ and $\beta_2$.

```{r}
conf_int <- confint(model_d, level = 0.95)
print(conf_int)

cat("\nInterpretation:\n")
cat(sprintf("β₁: We are 95%% confident that the true elasticity of aboveground weight\n"))
cat(sprintf("    with respect to diameter is between %.4f and %.4f.\n", 
            conf_int[2,1], conf_int[2,2]))
cat(sprintf("β₂: We are 95%% confident that the true elasticity of aboveground weight\n"))
cat(sprintf("    with respect to height is between %.4f and %.4f.\n", 
            conf_int[3,1], conf_int[3,2]))
```

##### (4) Compute the $R^2, R^2_a$ and the residual variance.

```{r}
cat(sprintf("R-squared (R²): %.4f\n", r_squared_d))
cat(sprintf("  → The model explains %.2f%% of the variance in log(aboveground weight)\n", 
            r_squared_d * 100))
cat(sprintf("Adjusted R-squared (R²ₐ): %.4f\n", r_squared_adj_d))
cat(sprintf("  → Adjusts for number of predictors\n"))
cat(sprintf("Residual variance (σ²): %.4f\n", residual_var_d))
cat(sprintf("Residual standard error (σ): %.4f\n", sqrt(residual_var_d)))
```

##### (5) Construct a graph with the default diagnostics plots of R.

```{r}
par(mfrow = c(2, 2))
plot(model_d, which = 1:4)
par(mfrow = c(1, 1))
```

##### (6) Can homogeneity of variance be assumed?

```{r}
# Breusch-Pagan test
library(lmtest)
bp_test <- lmtest::bptest(model_d)
cat("\nBreusch-Pagan Test for Heteroscedasticity:\n")
print(bp_test)

if(bp_test$p.value > 0.05) {
  cat("\nConclusion: Fail to reject H₀ (p > 0.05).")
  cat("\nHomogeneity of variance can be assumed.\n")
} else {
  cat("\nConclusion: Reject H₀ (p < 0.05).")
  cat("\nEvidence of heteroscedasticity (non-constant variance).\n")
}

# Visual assessment
cat("\nVisual Assessment: Check the Residuals vs Fitted plot.")
cat("\nIf residuals are randomly scattered around zero with constant spread,")
cat("\nhomoscedasticity is reasonable.\n")
```

##### (7) Do the residuals appear to follow a normal distribution?

```{r}
# Shapiro-Wilk test
shapiro_test <- shapiro.test(residuals(model_d))
cat("\nShapiro-Wilk Normality Test:\n")
print(shapiro_test)

if(shapiro_test$p.value > 0.05) {
  cat("\nConclusion: Fail to reject H₀ (p > 0.05).")
  cat("\nResiduals appear to follow a normal distribution.\n")
} else {
  cat("\nConclusion: Reject H₀ (p < 0.05).")
  cat("\nResiduals may deviate from normality.\n")
}

# Q-Q plot
cat("\nVisual Assessment: Check the Normal Q-Q plot.")
cat("\nPoints should follow the diagonal line closely.\n")
```

##### (8) Are there any outliers in the data?

```{r}
# Standardized residuals
std_resid <- rstandard(model_d)
outliers <- which(abs(std_resid) > 3)

cat(sprintf("\nObservations with |standardized residuals| > 3:\n"))
if(length(outliers) > 0) {
  cat("Potential outliers at observations:", outliers, "\n")
  print(data.frame(
    Observation = outliers,
    Std_Residual = std_resid[outliers]
  ))
} else {
  cat("No extreme outliers detected (using |std. residual| > 3 criterion).\n")
}

# Check for moderate outliers (> 2.5)
moderate_outliers <- which(abs(std_resid) > 2.5)
cat(sprintf("\nObservations with |standardized residuals| > 2.5:\n"))
if(length(moderate_outliers) > 0) {
  cat("Moderate outliers at observations:", moderate_outliers, "\n")
} else {
  cat("None found.\n")
}
```

##### (9) Are there any influential observations in the data?

```{r}
# Cook's distance
cooks_d <- cooks.distance(model_d)
influential <- which(cooks_d > 4/length(cooks_d))

cat("\nCook's Distance Analysis:\n")
cat(sprintf("Threshold: 4/n = 4/%d = %.4f\n", length(cooks_d), 4/length(cooks_d)))

if(length(influential) > 0) {
  cat("\nInfluential observations (Cook's D > 4/n):\n")
  print(data.frame(
    Observation = influential,
    Cooks_Distance = cooks_d[influential]
  ))
} else {
  cat("No highly influential observations detected.\n")
}

# DFBETAS
dfb <- dfbetas(model_d)
influential_dfb <- which(apply(abs(dfb), 1, max) > 2/sqrt(length(cooks_d)))

cat("\nDFBETAS Analysis:\n")
cat(sprintf("Threshold: 2/√n = 2/√%d = %.4f\n", 
            length(cooks_d), 2/sqrt(length(cooks_d))))

if(length(influential_dfb) > 0) {
  cat("\nInfluential observations (max |DFBETAS| > 2/√n):\n")
  cat(influential_dfb, "\n")
} else {
  cat("No influential observations detected using DFBETAS criterion.\n")
}

# Leverage
hat_values <- hatvalues(model_d)
high_leverage <- which(hat_values > 2 * 3 / length(hat_values))

cat("\nLeverage Analysis:\n")
cat(sprintf("Threshold: 2p/n = 2*3/%d = %.4f\n", 
            length(hat_values), 2 * 3 / length(hat_values)))

if(length(high_leverage) > 0) {
  cat("\nHigh leverage observations:\n")
  cat(high_leverage, "\n")
} else {
  cat("No high leverage points detected.\n")
}
```

#### (f) Obtain predictions of the aboveground biomass of trees with diameters $diameter = seq(12.5, 42.5, 5)$ and heights $height = seq(10, 40, 5)$. Note that the weight predictions are obtained from back transforming the logarithm. The bias correction is obtained by means of the lognormal distribution: If $\hat{Y}_{pred}$ is the prediction, the corrected(back-transformed) prediction $\tilde{Y}_{pred}$ is given by

```{r}
# Create prediction data
pred_diameter <- seq(12.5, 42.5, 5)  
pred_height <- seq(10, 40, 5)        

# Create all combinations
pred_data <- expand.grid(
  diameter = pred_diameter,
  height = pred_height
)

cat(sprintf("\nCreating predictions for %d combinations of diameter and height\n", 
            nrow(pred_data)))

# Make predictions on log scale
pred_data$log_pred <- predict(model_d, 
                               newdata = data.frame(
                                 diameter = pred_data$diameter,
                                 height = pred_data$height
                               ))

# Extract residual variance (sigma squared)
sigma_sq <- summary(model_d)$sigma^2

# Back-transform with bias correction
pred_data$PSA_pred_naive <- exp(pred_data$log_pred)
pred_data$PSA_pred_corrected <- exp(pred_data$log_pred + sigma_sq/2)

cat("\nBias Correction Formula:\n")
cat(sprintf("ỹ_pred = exp(ŷ_pred + σ²/2)\n"))
cat(sprintf("where σ² = %.4f\n", sigma_sq))

cat("\n--- Sample Predictions ---\n")
print(head(pred_data[, c("diameter", "height", "PSA_pred_corrected")], 10))

cat("\n--- Full Prediction Table ---\n")
pred_table <- pred_data[, c("diameter", "height", 
                            "log_pred", "PSA_pred_corrected")]
colnames(pred_table) <- c("Diameter (cm)", "Height (m)", 
                          "Log(Weight)", "Predicted Weight (kg)")
print(pred_table)

# Create visualization of predictions
cat("\n\nGenerating prediction visualization...\n")

ggplot(pred_data, aes(x = diameter, y = PSA_pred_corrected, 
                      color = factor(height))) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  labs(title = "Predicted Aboveground Weight by Diameter and Height",
       x = "Diameter (cm)",
       y = "Predicted Aboveground Weight (kg)",
       color = "Height (m)") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position = "right")
```

# Case Study 2: Fruit Trees

*Data and ideas for this case study come from Militino et al. (2006).*

To estimate the total surface occupied by fruit trees in three small areas (R63, R67, and R68) of Navarra in 2001, a sample of 47 square segments has been taken. The experimental units are square segments or quadrats of 4 hectares, obtained by random sampling after overlaying a square grid on the study domain. The focus of this case study is illustrating two different techniques used to obtain estimates: direct estimation and small area estimation. The direct technique estimates the total surface area by multiplying the mean of the observed surface area in the sampled segments by the total number of segments in every small area. The small area technique consists of creating a regression model where the dependent variable is the observed surface area occupied by fruit trees in every segment and the explanatory variables are the classified cultivars by satellite in the same segment and the small areas to which they belong. The final surface area totals are obtained by multiplying the total classified surface area of every small area by the β’s parameter estimates obtained from the regression model (observed surface area∼ classified surface area + small areas). The surface variables in the data frame `SATFRUIT` are given in $m^2$:

• `quadrat` is the number of the sampled segment or quadraz

• `smallarea` are the small areas’ labels

• `wheat` is the classified surface of wheat in the sampled segment

• `barley` is the classified surface of barley in the sampled segment

• `nonarable` is the classified surface of fallow or non-arable land in the sampled segment

• `corn` is the classified surface of corn in the sampled segment

• `sunflower` is the classified surface of sunflowers in the sampled segment

• `vineyard` is the classified surface of vineyards in the sampled segment

• `grass` is the classified surface of grass in the sampled segment

• `asparagus` is the classified surface of asparagus in the sampled segment

• `alfalfa` is the classified surface of lucerne (type of alfalfa) in the sampled segment

• `rape` is the classified surface of rape Brassica napus in the sampled segment

• `rice` is the classified surface of rice in the sampled segment

• `almonds` is the classified surface of almonds in the sampled segment

• `olives` is the classified surface of olives in the sampled segment

• `fruit` is the classified surface of fruit trees in the sampled segment

• `observed` is the observed surface of fruit trees in the sampled segment

```{r}
# Load required libraries
suppressPackageStartupMessages({
  library(PASWR2)
  library(car)
  library(boot)
  library(ggplot2)
  library(MASS)
  library(dplyr)
})

# Load the data
data(SATFRUIT)
```

```{r}
head(SATFRUIT)
```

### (a) Characterize the shape, center, and spread for the variable `fruit`.

```{r}
summary(SATFRUIT$fruit)
cat("\nStandard Deviation:", sd(SATFRUIT$fruit), "\n")
cat("IQR:", IQR(SATFRUIT$fruit), "\n")

# Histogram
hist(SATFRUIT$fruit, main = "Distribution of Classified Fruit Surface Area",
     xlab = "Fruit (m²)", col = "lightblue", breaks = 15)
```

### (b) What is the maximum number of $m^2$ of classified fruits by segment?

```{r}
cat("Maximum m² of classified fruits:", max(SATFRUIT$fruit), "\n")
```

### (c) How many observations are there by small area?

```{r}
table(SATFRUIT$smallarea)
```

### (d) Use `scatterplotMatrix()` from `car` or `pairs()` to explore the linear relationships between observed and the remainder of the numerical variables. Comment on the results.

```{r}
# Select numerical variables
num_vars <- c("observed", "wheat", "barley", "nonarable", "corn", 
              "sunflower", "vineyard", "grass", "asparagus", 
              "alfalfa", "rape", "rice", "almonds", "olives", "fruit")

# Create simple pairs plot (avoids smoother warnings)
pairs(~ observed + fruit + almonds + olives + vineyard, data = SATFRUIT,
      main = "Pairs Plot - Key Variables",
      pch = 19, col = as.numeric(SATFRUIT$smallarea))
legend("topright", legend = levels(SATFRUIT$smallarea), 
       col = 1:3, pch = 19, cex = 0.8)
```

### (e) Create density plots of the observed fruits’ surface area (`observed`) by small areas (`smallarea`).

```{r}
print(ggplot(SATFRUIT, aes(x = observed, fill = smallarea)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density of Observed Fruit Surface by Small Area",
       x = "Observed Surface (m²)", y = "Density") +
  theme_minimal())
```

### (f) Use box plots and bar plots with standard errors to compare the observed surface area (`observed`) and the classified surface area (`fruit`) by small areas (`smallarea`).

```{r}
# Box plots
par(mfrow = c(1, 2))
boxplot(observed ~ smallarea, data = SATFRUIT, 
        main = "Observed Surface by Small Area",
        xlab = "Small Area", ylab = "Observed (m²)", col = "lightblue")

boxplot(fruit ~ smallarea, data = SATFRUIT,
        main = "Classified Surface by Small Area",
        xlab = "Small Area", ylab = "Fruit (m²)", col = "lightgreen")

# Bar plots with standard errors
summary_data <- SATFRUIT %>%
  group_by(smallarea) %>%
  summarise(
    mean_observed = mean(observed),
    se_observed = sd(observed) / sqrt(n()),
    mean_fruit = mean(fruit),
    se_fruit = sd(fruit) / sqrt(n())
  )

par(mfrow = c(1, 2))
bp1 <- barplot(summary_data$mean_observed, names.arg = summary_data$smallarea,
        main = "Mean Observed Surface by Area",
        ylab = "Mean Observed (m²)", col = "lightblue", ylim = c(0, max(summary_data$mean_observed) * 1.2))
arrows(x0 = bp1, 
       y0 = summary_data$mean_observed - summary_data$se_observed,
       y1 = summary_data$mean_observed + summary_data$se_observed,
       angle = 90, code = 3, length = 0.1)

bp2 <- barplot(summary_data$mean_fruit, names.arg = summary_data$smallarea,
        main = "Mean Classified Surface by Area",
        ylab = "Mean Fruit (m²)", col = "lightgreen", ylim = c(0, max(summary_data$mean_fruit) * 1.2))
arrows(x0 = bp2,
       y0 = summary_data$mean_fruit - summary_data$se_fruit,
       y1 = summary_data$mean_fruit + summary_data$se_fruit,
       angle = 90, code = 3, length = 0.1)

```

### (g) Compute the correlation between observed and all other numerical variables. List the three variables in order along with their correlation coe!cients that have the highestcorrelation with observed.

```{r}
correlations <- cor(SATFRUIT[, num_vars[-1]], SATFRUIT$observed)
correlations_sorted <- sort(abs(correlations), decreasing = TRUE)

cat("\nTop 3 variables with highest correlation with 'observed':\n")
print(head(correlations_sorted, 3))
cat("\nWith signs:\n")
print(correlations[names(head(correlations_sorted, 3))])
```

## Model (A)

Use backward elimination to develop a model that predicts `observed` using the data frame `SATFRUIT` without considering `smallarea`. Start the backward elimination process by considering all of the numerical variables in `SATFRUIT` as potential predictors. Use a p-value-to-remove of 10%. Store the final model in the object `modelA`.

```{r}
# Start with full model (excluding quadrat and smallarea)
predictors <- setdiff(num_vars, c("observed"))
formula_full <- as.formula(paste("observed ~", paste(predictors, collapse = " + ")))

model_full <- lm(formula_full, data = SATFRUIT)

# Backward elimination with p = 0.10
# k = qchisq(0.10, 1, lower.tail = FALSE) for p-value criterion
modelA <- step(model_full, direction = "backward", 
               k = qchisq(0.10, 1, lower.tail = FALSE),
               trace = 0)

cat("\nModel A Summary:\n")
summary(modelA)

# Cross-validation for Model A
modelA_glm <- glm(formula(modelA), data = SATFRUIT)
```

#### i. Compute $CV_n$, the leave-one-out cross-validation error, for `modelA`. Set the seed to 5 and compute $CV_5$, the five-fold cross-validation error, for `modelA`. The cross-validation error for a generalized linear model can be computed using the `cv.glm()` function from the boot package. Using the function `glm()` without passing a family argument is equivalent to using the function `lm()`. R Code 1 provides a template for how to use the `cv.glm()` function. Note that $CV_n$ is returned with `cv.error$delta[1]`. To compute $CV_5$, pass the value 5 to the argument $K$ inside the `cv.glm()` function.

```{=plain}
R Code 1:
> mod.glm <- glm(y ~ x1 + x2, data = DF)
> library(boot)
> cv.error <- cv.glm(data = DF, glmfit = mod.glm)
> cv.error$delta[1]
```
```{r}
# LOOCV (CV_n)
cv_n_A <- cv.glm(data = SATFRUIT, glmfit = modelA_glm)
CVn_A <- cv_n_A$delta[1]

# 5-fold CV
set.seed(5)
cv_5_A <- cv.glm(data = SATFRUIT, glmfit = modelA_glm, K = 5)
CV5_A <- cv_5_A$delta[1]

cat("\n--- Model A Cross-Validation ---\n")
cat("CV_n (LOOCV):", CVn_A, "\n")
cat("CV_5 (5-fold):", CV5_A, "\n")
```

#### ii. Compute $R^2, R^2_a$, the AIC, and the BIC for Model (A). What is the proportion of total variability explained by Model (A)?

```{r}
# Model A statistics
summary_A <- summary(modelA)
R2_A <- summary_A$r.squared
R2a_A <- summary_A$adj.r.squared
AIC_A <- AIC(modelA)
BIC_A <- BIC(modelA)

cat("\n--- Model A Statistics ---\n")
cat("R²:", R2_A, "\n")
cat("Adjusted R²:", R2a_A, "\n")
cat("AIC:", AIC_A, "\n")
cat("BIC:", BIC_A, "\n")
cat("Proportion of variability explained:", R2_A, "\n")
```

## Model (B)

Use the criterion-based procedure AIC, which for linear regression is equivalent to Mallow’s Cp, to develop a model that predicts `observed` using all of the numerical variables in `SATFRUIT`. Store the model in the object `modelB`. Verify that the model suggested using BIC is the same model as the one suggested by AIC or Mallow’s Cp, which are all the same as Model (A).

```{r}
modelB <- stepAIC(model_full, direction = "both", trace = 0)
cat("\nModel B Summary:\n")
summary(modelB)

# Verify BIC gives same model
modelB_BIC <- stepAIC(model_full, direction = "both", k = log(nrow(SATFRUIT)), trace = 0)

cat("\nModel B (AIC) formula:", deparse(formula(modelB)), "\n")
cat("Model with BIC formula:", deparse(formula(modelB_BIC)), "\n")
cat("Are Model B and Model A the same?", 
    identical(sort(names(coef(modelA))), sort(names(coef(modelB)))), "\n")
```

## Model (C)

Use mean squared prediction error (MSPE) to select a model using all of the numerical variables in SATFRUIT as potential predictors for predicting observed. Store the model in the object modelC. Specifically, select a model using both leave-one-out cross validation (LOOCV) and five-fold cross validation.

```{r}
# Test various model combinations based on correlations
# and select based on CV error

candidate_models <- list(
  m1 = observed ~ fruit,
  m2 = observed ~ fruit + almonds,
  m3 = observed ~ fruit + almonds + olives,
  m4 = observed ~ fruit + olives,
  m5 = observed ~ fruit + almonds + olives + vineyard,
  m6 = observed ~ fruit + vineyard
)
```

#### 1. Compute CVn for modelC. Set the seed to 5 and compute CV5 for modelC.

```{r}
# Function to compute CV errors
compute_cv <- function(formula, data, K = NULL) {
  mod_glm <- glm(formula, data = data)
  if(is.null(K)) {
    cv_result <- cv.glm(data = data, glmfit = mod_glm)
  } else {
    set.seed(5)
    cv_result <- cv.glm(data = data, glmfit = mod_glm, K = K)
  }
  return(cv_result$delta[1])
}

# Compare CV errors for candidate models
cv_results <- data.frame(
  Model = names(candidate_models),
  Formula = sapply(candidate_models, deparse),
  CV_n = sapply(candidate_models, compute_cv, data = SATFRUIT),
  CV_5 = sapply(candidate_models, function(f) compute_cv(f, SATFRUIT, K = 5))
)

print(cv_results[, c("Model", "CV_n", "CV_5")])
```

#### 2. Compute R2, R2a, the AIC, and the BIC for Model (C). What is the proportion of total variability explained by Model (C)?

```{r}
# Select model with minimum CV error (use CV_n for selection)
best_idx <- which.min(cv_results$CV_n)
cat("\nBest model based on LOOCV:", cv_results$Model[best_idx], "\n")
cat("Formula:", cv_results$Formula[best_idx], "\n")

modelC <- lm(candidate_models[[best_idx]], data = SATFRUIT)
cat("\nModel C Summary:\n")
summary(modelC)

# Store CV errors for Model C
cv_n_C <- cv_results$CV_n[best_idx]
CV5_C <- cv_results$CV_5[best_idx]

cat("\n--- Model C Cross-Validation ---\n")
cat("CV_n (LOOCV):", cv_n_C, "\n")
cat("CV_5 (5-fold):", CV5_C, "\n")

# Model C statistics
summary_C <- summary(modelC)
R2_C <- summary_C$r.squared
R2a_C <- summary_C$adj.r.squared
AIC_C <- AIC(modelC)
BIC_C <- BIC(modelC)

cat("\n--- Model C Statistics ---\n")
cat("R²:", R2_C, "\n")
cat("Adjusted R²:", R2a_C, "\n")
cat("AIC:", AIC_C, "\n")
cat("BIC:", BIC_C, "\n")
```

## Model (D)

Use whichever of Model (A) or (C) has the smaller cross-validation error, and introduce smallarea into the chosen model. Store the new model that includes smallarea in modelD.

#### (i.) Eliminate any variables from modelD that are not statistically significant (α= 0.10). Store the resulting model in modelD.

```{r}
# Choose model with smaller CV error
if(CVn_A < cv_n_C) {
  base_model <- modelA
  cat("Using Model A as base (smaller CV error)\n")
} else {
  base_model <- modelC
  cat("Using Model C as base (smaller CV error)\n")
}

# Add smallarea
formula_D <- update(formula(base_model), ~ . + smallarea)
modelD_initial <- lm(formula_D, data = SATFRUIT)

cat("\nInitial Model D with smallarea:\n")
summary(modelD_initial)

# Remove non-significant variables (α = 0.10)
modelD <- step(modelD_initial, direction = "backward", 
               k = qchisq(0.10, 1, lower.tail = FALSE),
               trace = 0)

cat("\nFinal Model D Summary:\n")
summary(modelD)
```

#### (ii.) Compute CVn for modelD. Set the seed to 5 and compute CV5 for modelD.

```{r}
# Cross-validation for Model D
modelD_glm <- glm(formula(modelD), data = SATFRUIT)
cv_n_D <- cv.glm(data = SATFRUIT, glmfit = modelD_glm)$delta[1]
set.seed(5)
cv_5_D <- cv.glm(data = SATFRUIT, glmfit = modelD_glm, K = 5)$delta[1]

cat("\n--- Model D Cross-Validation ---\n")
cat("CV_n (LOOCV):", cv_n_D, "\n")
cat("CV_5 (5-fold):", cv_5_D, "\n")
```

#### (iii.) Compute R2, R2a, the AIC, and the BIC for Model (D). What is the proportion of total variability explained by Model (D)?

```{r}
# Model D statistics
summary_D <- summary(modelD)
R2_D <- summary_D$r.squared
R2a_D <- summary_D$adj.r.squared
AIC_D <- AIC(modelD)
BIC_D <- BIC(modelD)

cat("\n--- Model D Statistics ---\n")
cat("R²:", R2_D, "\n")
cat("Adjusted R²:", R2a_D, "\n")
cat("AIC:", AIC_D, "\n")
cat("BIC:", BIC_D, "\n")
```

#### (iv.) Does Model (D) have a smaller cross-validation error than the cross-validation error for either Model (A) or Model (C)?

```{r}
# Compare CV errors
cat("\n--- CV Error Comparison ---\n")
cat("Model A CV_n:", CVn_A, "\n")
cat("Model C CV_n:", cv_n_C, "\n")
cat("Model D CV_n:", cv_n_D, "\n")
cat("\nDoes Model D have smaller CV error than both A and C?", 
    cv_n_D < min(CVn_A, cv_n_C), "\n")
```

#### (v.) Plot the Cook distances, the studentized residuals, the diagonal elements of the hat matrix, the DFFITS, and DFBETAS1 of Model (D) versus the index.

```{r}
par(mfrow = c(2, 3))

# Cook's distance
cooks_d <- cooks.distance(modelD)
plot(cooks_d, type = "h", 
     main = "Cook's Distance", ylab = "Cook's D", xlab = "Index")
abline(h = 4/nrow(SATFRUIT), col = "red", lty = 2)
text(x = which(cooks_d > 4/nrow(SATFRUIT)), 
     y = cooks_d[cooks_d > 4/nrow(SATFRUIT)],
     labels = which(cooks_d > 4/nrow(SATFRUIT)), pos = 3, cex = 0.7)

# Studentized residuals
rstud <- rstudent(modelD)
plot(rstud, type = "h",
     main = "Studentized Residuals", ylab = "Studentized Residuals", xlab = "Index")
abline(h = c(-2, 2), col = "red", lty = 2)
text(x = which(abs(rstud) > 2), 
     y = rstud[abs(rstud) > 2],
     labels = which(abs(rstud) > 2), pos = 3, cex = 0.7)

# Hat values
hat_vals <- hatvalues(modelD)
leverage_threshold <- 2 * length(coef(modelD)) / nrow(SATFRUIT)
plot(hat_vals, type = "h",
     main = "Hat Values (Leverage)", ylab = "Hat Values", xlab = "Index")
abline(h = leverage_threshold, col = "red", lty = 2)
text(x = which(hat_vals > leverage_threshold), 
     y = hat_vals[hat_vals > leverage_threshold],
     labels = which(hat_vals > leverage_threshold), pos = 3, cex = 0.7)

# DFFITS
dffits_vals <- dffits(modelD)
dffits_threshold <- 2 * sqrt(length(coef(modelD)) / nrow(SATFRUIT))
plot(dffits_vals, type = "h",
     main = "DFFITS", ylab = "DFFITS", xlab = "Index")
abline(h = c(-dffits_threshold, dffits_threshold), col = "red", lty = 2)

# DFBETAS for first predictor (fruit coefficient)
dfbetas_vals <- dfbetas(modelD)[, 2]
dfbetas_threshold <- 2 / sqrt(nrow(SATFRUIT))
plot(dfbetas_vals, type = "h",
     main = "DFBETAS (fruit)", ylab = "DFBETAS", xlab = "Index")
abline(h = c(-dfbetas_threshold, dfbetas_threshold), col = "red", lty = 2)
```

#### (vi.) Are there any leverage points? Justify the answer given.

```{r}
leverage_points <- which(hat_vals > leverage_threshold)
cat("Leverage threshold (2p/n):", leverage_threshold, "\n")
cat("Number of leverage points:", length(leverage_points), "\n")
cat("Leverage points (observations):", leverage_points, "\n")
if(length(leverage_points) > 0) {
  cat("\nJustification: These observations have hat values exceeding 2p/n =", 
      round(leverage_threshold, 4), "\n")
}
```

#### (vii.) Are there any outliers? Justify the answer given.

```{r}
outliers <- which(abs(rstud) > 2)
cat("Number of outliers (|rstudent| > 2):", length(outliers), "\n")
cat("Outliers (observations):", outliers, "\n")
if(length(outliers) > 0) {
  cat("\nJustification: These observations have studentized residuals with absolute value > 2\n")
  cat("Studentized residuals for outliers:\n")
  print(rstud[outliers])
}
```

#### (viii) Check normality and homoscedasticity for Model (D) using graphics and hypothesis tests.

```{r}
par(mfrow = c(2, 2))
plot(modelD)

# Shapiro-Wilk test for normality
shapiro_test <- shapiro.test(residuals(modelD))
cat("\nShapiro-Wilk test for normality of residuals:\n")
cat("W =", shapiro_test$statistic, ", p-value =", shapiro_test$p.value, "\n")
if(shapiro_test$p.value > 0.05) {
  cat("Conclusion: Fail to reject null hypothesis. Residuals appear normally distributed (α=0.05).\n")
} else {
  cat("Conclusion: Reject null hypothesis. Evidence of non-normality in residuals (α=0.05).\n")
}

# Breusch-Pagan test for homoscedasticity
bp_test <- ncvTest(modelD)
cat("\nBreusch-Pagan test for homoscedasticity:\n")
cat("Chi-square =", bp_test$ChiSquare, ", df =", bp_test$Df, ", p-value =", bp_test$p, "\n")
if(bp_test$p > 0.05) {
  cat("Conclusion: Fail to reject null hypothesis. No evidence of heteroscedasticity (α=0.05).\n")
} else {
  cat("Conclusion: Reject null hypothesis. Evidence of heteroscedasticity (α=0.05).\n")
}
```

#### (ix.) Calculate a 95% confidence interval for the fruit coefficient.

```{r}
ci_fruit <- confint(modelD, "fruit", level = 0.95)
cat("95% Confidence Interval for fruit coefficient:\n")
print(ci_fruit)
cat("\nInterpretation: We are 95% confident that the true coefficient for fruit is between",
    round(ci_fruit[1], 4), "and", round(ci_fruit[2], 4), "\n")
```

### (h) How many hectares of observed fruits are expected to be incremented if the classified hectares of fruit trees by the satellite are increased by 10,000 m2 (1 ha)?

```{r}
fruit_coef <- coef(modelD)["fruit"]
increase_m2 <- fruit_coef * 10000
increase_ha <- increase_m2 / 10000

cat("Fruit coefficient:", fruit_coef, "\n")
cat("Expected increase in observed for 10,000 m² increase in classified fruit:", 
    increase_m2, "m²\n")
cat("In hectares:", increase_ha, "ha\n")
```

### (i) Suppose the total classified fruits by the satellite in area R63 is 97,044.28 m2, in area R67 is 4,878,603.43 m2, and in area R68 is 2,883,488.24 m2. Predict the total area of fruit trees by small areas.

```{r}
# Total classified fruits by area
total_classified <- data.frame(
  smallarea = factor(c("R63", "R67", "R68"), levels = levels(SATFRUIT$smallarea)),
  fruit = c(97044.28, 4878603.43, 2883488.24)
)

predictions <- predict(modelD, newdata = total_classified)
cat("\nPredicted total observed area by small area:\n")
for(i in 1:3) {
  cat(total_classified$smallarea[i], ":", round(predictions[i], 2), "m² (",
      round(predictions[i]/10000, 2), "ha)\n")
}
```

### (j) Create a plot of observed versus fruit with the points color coded according to small area. Superimpose the corresponding regression lines for each small area.

```{r}
p_scatter <- ggplot(SATFRUIT, aes(x = fruit, y = observed, color = smallarea)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
  labs(title = "Observed vs Classified Fruit Surface by Small Area",
       x = "Classified Fruit (m²)", 
       y = "Observed Fruit (m²)",
       color = "Small Area") +
  theme_minimal() +
  theme(legend.position = "bottom")

print(p_scatter)
```

### (k) Plot the individual predictions for model D versus the observed data. Add a diagonal line to the plot.

```{r}
pred_D <- predict(modelD)
par(mfrow = c(1, 1))
plot(pred_D, SATFRUIT$observed, 
     main = "Predicted vs Observed (Model D)",
     xlab = "Predicted", ylab = "Observed",
     pch = 19, col = as.numeric(SATFRUIT$smallarea))
abline(a = 0, b = 1, col = "red", lwd = 2, lty = 2)
legend("topleft", legend = levels(SATFRUIT$smallarea), 
       col = 1:3, pch = 19, title = "Small Area")

# Add R² to plot
text(x = min(pred_D), y = max(SATFRUIT$observed),
     labels = paste("R² =", round(R2_D, 3)), pos = 4)
```

### (l) Create a bar plot that displays the predicted area occupied by fruit trees based on model D for each small area and the direct estimates of the area occupied by fruit trees by small area knowing that the total number of classified segments in areas R63, R67, and R68 are 119, 703, and 564, respectively.

```{r}
# Total segments by area
total_segments <- data.frame(
  smallarea = c("R63", "R67", "R68"),
  n_segments = c(119, 703, 564)
)

# Direct estimates
direct_estimates <- SATFRUIT %>%
  group_by(smallarea) %>%
  summarise(mean_observed = mean(observed)) %>%
  left_join(total_segments, by = "smallarea") %>%
  mutate(total_direct = mean_observed * n_segments)

# Model D predictions (total for each area)
model_predictions <- data.frame(
  smallarea = c("R63", "R67", "R68"),
  total_predicted = predictions
)

comparison <- left_join(direct_estimates, model_predictions, by = "smallarea")

cat("\nComparison of Direct vs Model D Estimates:\n")
print(comparison)
```

```{r}
# Bar plot
barplot_data <- rbind(comparison$total_direct, comparison$total_predicted)
colnames(barplot_data) <- comparison$smallarea

par(mfrow = c(1, 1))
bp <- barplot(barplot_data, beside = TRUE, 
        names.arg = comparison$smallarea,
        col = c("steelblue", "coral"),
        main = "Direct vs Model D Predictions by Small Area",
        ylab = "Total Area (m²)",
        xlab = "Small Area",
        legend.text = c("Direct Estimate", "Model D Prediction"),
        args.legend = list(x = "topright", bty = "n"),
        ylim = c(0, max(barplot_data) * 1.15))

# Add values on bars
text(x = bp, y = barplot_data, 
     labels = format(round(barplot_data, 0), big.mark = ","),
     pos = 3, cex = 0.8)
```

# Case Study 3: Real Estate

*Data and ideas for this case study come from (Militino et al., 2004).*

The goal of this case study is to walk the user through the creation of a parsimonious multiple linear regression model that can be used to predict the total price (`totalprice`) of apartments by their hedonic (structural) characteristics. The data frame `VIT2005` contains several variables, and further description of the data can be found in the help file.

```{r}
# Load required packages
library(car)
library(boot)
library(MASS)
library(leaps)
library(spuRs)

# Load data
data(VIT2005)
```

### (a) Characterize the shape, center, and spread of the variable `totalprice`.

```{r}
summary(VIT2005$totalprice)
cat("\nStandard Deviation:", sd(VIT2005$totalprice), "\n")
cat("Variance:", var(VIT2005$totalprice), "\n")
cat("IQR:", IQR(VIT2005$totalprice), "\n")

# Visualize distribution
par(mfrow = c(1, 2))
hist(VIT2005$totalprice, main = "Histogram of Total Price", 
     xlab = "Total Price (euros)", col = "lightblue", breaks = 15)
boxplot(VIT2005$totalprice, main = "Boxplot of Total Price", 
        ylab = "Total Price (euros)", col = "lightgreen")
par(mfrow = c(1, 1))
```

### (b) Use `scatterplotMatrix()` from the `car` package or `pairs()` to explore the relationships between `totalprice` and the numerical explanatory variables: `area`, `age`, `floor`, `rooms`, `toilets`, `garage`, `elevator`, and `storage`.

```{r}
scatterplotMatrix(VIT2005[, c("totalprice", "area", "age", "floor", "rooms", 
                               "toilets", "garage", "elevator", "storage")], 
                  smooth = FALSE,
                  main = "Scatterplot Matrix")
```

### (c) Compute the correlation between `totalprice` and all of the other numerical variables. List the three variables in order along with their correlation coefficients that have the highest correlation with `totalprice`.

```{r}
num_vars <- c("area", "age", "floor", "rooms", "toilets", "garage", 
              "elevator", "storage")
correlations <- sapply(num_vars, function(var) {
  cor(VIT2005$totalprice, VIT2005[[var]], use = "complete.obs")
})

# Sort by absolute correlation
sorted_cors <- sort(abs(correlations), decreasing = TRUE)
cat("\nTop 3 variables by correlation with totalprice:\n")
for(i in 1:3) {
  var_name <- names(sorted_cors)[i]
  cat(i, ".", var_name, ": r =", correlations[var_name], "\n")
}
```

## Model (A)

Use backward elimination to develop a model that predicts `totalprice` using the data frame `VIT2005`. Use a “p-value to remove” of 5%. Store the final model in the object `modelA`.

```{r}
# Start with full model
full_model <- lm(totalprice ~ ., data = VIT2005)

# Backward elimination - step() with default k=2 approximates p=0.05
modelA <- step(full_model, direction = "backward", trace = 1)
cat("\nModel A Formula:", deparse(formula(modelA)), "\n")
summary(modelA)
```

#### (i) Compute $CV_n$, the leave-one-out cross validation error, for `modelA`. Set the seed to 5 and compute $CV_5$, the five-fold cross validation error, for `modelA`. The cross validation error for a generalized linear model can be computed using the `cv.glm()` function from the `boot` package. Using the function `glm()` without passing a family argument is the same as using the function `lm()`. R Code 2 provides a template of how to use the `cv.glm()` function. Note that $CV_n$ is returned with `cv.error$delta[1]`. To compute $CV_5$, pass the value 5 to the argument $K$ inside the `cv.glm()` function.

```         
– R Code 2
> mod.glm <- glm(y ~ x1 + x2, data = DF)
> library(boot)
> cv.error <- cv.glm(data = DF, glmfit = mod.glm)
> cv.error$delta[1]
```

```{r}
modelA_glm <- glm(formula(modelA), data = VIT2005)

# CV_n (leave-one-out)
cv_n_A <- cv.glm(data = VIT2005, glmfit = modelA_glm)
cat("CV_n (LOOCV):", cv_n_A$delta[1], "\n")

# CV_5 (5-fold)
set.seed(5)
cv_5_A <- cv.glm(data = VIT2005, glmfit = modelA_glm, K = 5)
cat("CV_5:", cv_5_A$delta[1], "\n")
```

#### (ii) Compute $R^2, R^2_a$, the AIC, and the BIC for Model (A). What is the proportion of total variability explained by Model (A)?

```{r}
summary_A <- summary(modelA)
cat("\n--- Model A Metrics ---\n")
cat("R-squared:", summary_A$r.squared, "\n")
cat("Adjusted R-squared:", summary_A$adj.r.squared, "\n")
cat("AIC:", AIC(modelA), "\n")
cat("BIC:", BIC(modelA), "\n")
cat("Proportion of variability explained:", summary_A$r.squared, "\n")
```

## Model (B)

Use the criterion-based procedure AIC, which for linear regression is equivalent to Mallow’s Cp, to develop a model that predicts `totalprice` using the variables in `VIT2005`. Store the model in the object `modelB`.

```{r}
# Use stepAIC for AIC-based selection (equivalent to Cp for linear regression)
modelB <- stepAIC(full_model, direction = "both", trace = 1, k = 2)
cat("\nModel B Formula:", deparse(formula(modelB)), "\n")
summary(modelB)
```

#### (i) Compute $CV_n$ for `modelB`. Set the seed to 5 and compute $CV_5$ for `modelB`.

```{r}
# (i) Cross-validation for Model B
cat("\n--- Model B Cross-Validation ---\n")
modelB_glm <- glm(formula(modelB), data = VIT2005)

cv_n_B <- cv.glm(data = VIT2005, glmfit = modelB_glm)
cat("CV_n (LOOCV):", cv_n_B$delta[1], "\n")

set.seed(5)
cv_5_B <- cv.glm(data = VIT2005, glmfit = modelB_glm, K = 5)
cat("CV_5:", cv_5_B$delta[1], "\n")
```

#### (ii) Compute $R^2, R^2_a$, the AIC, and the BIC for Model (B). What is the proportion of total variability explained by Model (B)?

```{r}
# (ii) Model metrics
summary_B <- summary(modelB)
cat("\n--- Model B Metrics ---\n")
cat("R-squared:", summary_B$r.squared, "\n")
cat("Adjusted R-squared:", summary_B$adj.r.squared, "\n")
cat("AIC:", AIC(modelB), "\n")
cat("BIC:", BIC(modelB), "\n")
cat("Proportion of variability explained:", summary_B$r.squared, "\n")
```

## Model (C)

Use the criterion-based procedure BIC to develop a model that predicts `totalprice` using the variables in `VIT2005`. Store the model in the object `modelC`.

```{r}
# Use stepAIC with k = log(n) for BIC
modelC <- stepAIC(full_model, direction = "both", 
                  k = log(nrow(VIT2005)), trace = 1)
cat("\nModel C Formula:", deparse(formula(modelC)), "\n")
summary(modelC)
```

#### (i) Compute $CV_n$ for `modelC`. Set the seed to 5 and compute $CV_5$ for `modelC`.

```{r}
# (i) Cross-validation for Model C
cat("\n--- Model C Cross-Validation ---\n")
modelC_glm <- glm(formula(modelC), data = VIT2005)

cv_n_C <- cv.glm(data = VIT2005, glmfit = modelC_glm)
cat("CV_n (LOOCV):", cv_n_C$delta[1], "\n")

set.seed(5)
cv_5_C <- cv.glm(data = VIT2005, glmfit = modelC_glm, K = 5)
cat("CV_5:", cv_5_C$delta[1], "\n")
```

#### (ii) Compute $R^2, R^2_a$, the AIC, and the BIC for Model (C). What is the proportion of total variability explained by Model (C)?

```{r}
# (ii) Model metrics
summary_C <- summary(modelC)
cat("\n--- Model C Metrics ---\n")
cat("R-squared:", summary_C$r.squared, "\n")
cat("Adjusted R-squared:", summary_C$adj.r.squared, "\n")
cat("AIC:", AIC(modelC), "\n")
cat("BIC:", BIC(modelC), "\n")
cat("Proportion of variability explained:", summary_C$r.squared, "\n")
```

## Model (D)

Use forward selection to develop a model that predicts `totalprice` using the variables in `VIT2005`. Use a “p-value to add” of 5%. Store the final model in the object `modelD`.

```{r}
# Start with intercept only
null_model <- lm(totalprice ~ 1, data = VIT2005)

# Forward selection
modelD <- step(null_model, 
               scope = formula(full_model), 
               direction = "forward", 
               trace = 1)
cat("\nModel D Formula:", deparse(formula(modelD)), "\n")
summary(modelD)
```

#### (i) Compute $CV_n$ for `modelD`. Set the seed to 5 and compute $CV_5$ for `modelD`.

```{r}
# (i) Cross-validation for Model D
cat("\n--- Model D Cross-Validation ---\n")
modelD_glm <- glm(formula(modelD), data = VIT2005)

cv_n_D <- cv.glm(data = VIT2005, glmfit = modelD_glm)
cat("CV_n (LOOCV):", cv_n_D$delta[1], "\n")

set.seed(5)
cv_5_D <- cv.glm(data = VIT2005, glmfit = modelD_glm, K = 5)
cat("CV_5:", cv_5_D$delta[1], "\n")
```

#### (ii) Compute the $R^2, R^2_a$, AIC, and the BIC for Model (D). What is the proportion of total variability explained by Model (D)?

```{r}
# (ii) Model metrics
summary_D <- summary(modelD)
cat("\n--- Model D Metrics ---\n")
cat("R-squared:", summary_D$r.squared, "\n")
cat("Adjusted R-squared:", summary_D$adj.r.squared, "\n")
cat("AIC:", AIC(modelD), "\n")
cat("BIC:", BIC(modelD), "\n")
cat("Proportion of variability explained:", summary_D$r.squared, "\n")
```

### (d) Explore the residuals of the Models (A), (B), (C), and (D) using the function `residualPlot()` or `residualPlots()` from the package `car`. Comment on the results.

```{r}
par(mfrow = c(2, 2))
plot(modelA, which = 1:4, main = "Model A")

par(mfrow = c(2, 2))
plot(modelB, which = 1:4, main = "Model B")

par(mfrow = c(2, 2))
plot(modelC, which = 1:4, main = "Model C")

par(mfrow = c(2, 2))
plot(modelD, which = 1:4, main = "Model D")

par(mfrow = c(1, 1))

cat("\nComment: Examine residual plots for patterns, non-constant variance,\n")
cat("and departures from normality.\n")
```

### (e) Use the function `boxCox()` from `car` to find a suitable transformation for `totalprice`.

```{r}
cat("\n\n=== PART (e): Box-Cox Transformation ===\n")
par(mfrow = c(1, 1))
bc <- boxCox(modelA)
lambda <- bc$x[which.max(bc$y)]
cat("Optimal lambda:", lambda, "\n")
cat("Interpretation: Lambda near 0 suggests log transformation is appropriate.\n")
```

## Model (E)

Use backward elimination to develop a model that predicts `log(totalprice)` using the data frame `VIT2005`. Use a “p-value to remove” of 5%. Store the final model in the object `modelE`.

```{r}
# Create a temporary dataset with log-transformed response
VIT2005_log <- VIT2005
VIT2005_log$log_totalprice <- log(VIT2005$totalprice)
VIT2005_log$totalprice <- NULL  # Remove original totalprice

# Create full model with all predictors
full_model_log <- lm(log_totalprice ~ ., data = VIT2005_log)

modelE <- step(full_model_log, direction = "backward", trace = 1)
cat("\nModel E Formula:", deparse(formula(modelE)), "\n")
summary(modelE)

# Update formula to use log(totalprice) for consistency
modelE_formula <- formula(modelE)
modelE_formula <- as.formula(gsub("log_totalprice", "log(totalprice)", 
                                   deparse(modelE_formula)))
modelE <- lm(modelE_formula, data = VIT2005)
```

#### (i) Compute $CV_n$ for `modelE`. Set the seed to 5 and compute $CV_5$ for `modelE`.

```{r}
# (i) Cross-validation for Model E
cat("\n--- Model E Cross-Validation ---\n")
modelE_glm <- glm(formula(modelE), data = VIT2005)

cv_n_E <- cv.glm(data = VIT2005, glmfit = modelE_glm)
cat("CV_n (LOOCV):", cv_n_E$delta[1], "\n")

set.seed(5)
cv_5_E <- cv.glm(data = VIT2005, glmfit = modelE_glm, K = 5)
cat("CV_5:", cv_5_E$delta[1], "\n")
```

#### (ii) Compute $R^2, R^2_a$, the AIC, and the BIC for Model (E). What is the proportion of total variability explained by Model (E)?

```{r}
# (ii) Model metrics
summary_E <- summary(modelE)
cat("\n--- Model E Metrics ---\n")
cat("R-squared:", summary_E$r.squared, "\n")
cat("Adjusted R-squared:", summary_E$adj.r.squared, "\n")
cat("AIC:", AIC(modelE), "\n")
cat("BIC:", BIC(modelE), "\n")
cat("Proportion of variability explained:", summary_E$r.squared, "\n")
```

## Model (F)

Use the criterion-based procedure AIC, which for linear regression is equivalent to Mallow’s Cp, to develop a model that predicts `log(totalprice)` using the variables in `VIT2005`. Store the model in the object `modelF`.

```{r}
# Use the cleaned dataset
full_model_log_F <- lm(log_totalprice ~ ., data = VIT2005_log)
modelF <- stepAIC(full_model_log_F, direction = "both", trace = 1, k = 2)

# Update formula to use log(totalprice)
modelF_formula <- as.formula(gsub("log_totalprice", "log(totalprice)", 
                                   deparse(formula(modelF))))
modelF <- lm(modelF_formula, data = VIT2005)
cat("\nModel F Formula:", deparse(formula(modelF)), "\n")
summary(modelF)
```

#### (i) Compute $CV_n$ for `modelF`. Set the seed to 5 and compute $CV_5$ for `modelF`.

```{r}
# (i) Cross-validation
cat("\n--- Model F Cross-Validation ---\n")
modelF_glm <- glm(formula(modelF), data = VIT2005)

cv_n_F <- cv.glm(data = VIT2005, glmfit = modelF_glm)
cat("CV_n (LOOCV):", cv_n_F$delta[1], "\n")

set.seed(5)
cv_5_F <- cv.glm(data = VIT2005, glmfit = modelF_glm, K = 5)
cat("CV_5:", cv_5_F$delta[1], "\n")
```

#### (ii) Compute $R^2, R^2_a$, the AIC, and the BIC for Model (F). What is the proportion of total variability explained by Model (F)?

```{r}
# (ii) Model metrics
summary_F <- summary(modelF)
cat("\n--- Model F Metrics ---\n")
cat("R-squared:", summary_F$r.squared, "\n")
cat("Adjusted R-squared:", summary_F$adj.r.squared, "\n")
cat("AIC:", AIC(modelF), "\n")
cat("BIC:", BIC(modelF), "\n")
cat("Proportion of variability explained:", summary_F$r.squared, "\n")
```

## Model (G)

Use the criterion-based procedure BIC to develop a model that predicts `log(totalprice)` using the variables in `VIT2005`. Store the model in the object `modelG`.

```{r}
# Use the cleaned dataset
full_model_log_G <- lm(log_totalprice ~ ., data = VIT2005_log)
modelG <- stepAIC(full_model_log_G, direction = "both", 
                  k = log(nrow(VIT2005_log)), trace = 1)

# Update formula to use log(totalprice)
modelG_formula <- as.formula(gsub("log_totalprice", "log(totalprice)", 
                                   deparse(formula(modelG))))
modelG <- lm(modelG_formula, data = VIT2005)
cat("\nModel G Formula:", deparse(formula(modelG)), "\n")
summary(modelG)
```

#### (i) Compute $CV_n$ for `modelG`. Set the seed to 5 and compute $CV_5$ for `modelG`.

```{r}
# (i) Cross-validation
cat("\n--- Model G Cross-Validation ---\n")
modelG_glm <- glm(formula(modelG), data = VIT2005)

cv_n_G <- cv.glm(data = VIT2005, glmfit = modelG_glm)
cat("CV_n (LOOCV):", cv_n_G$delta[1], "\n")

set.seed(5)
cv_5_G <- cv.glm(data = VIT2005, glmfit = modelG_glm, K = 5)
cat("CV_5:", cv_5_G$delta[1], "\n")
```

#### (ii) Compute $R^2, R^2_a$, the AIC, and the BIC for Model (G). What is the proportion of total variability explained by Model (G)?

```{r}
# (ii) Model metrics
summary_G <- summary(modelG)
cat("\n--- Model G Metrics ---\n")
cat("R-squared:", summary_G$r.squared, "\n")
cat("Adjusted R-squared:", summary_G$adj.r.squared, "\n")
cat("AIC:", AIC(modelG), "\n")
cat("BIC:", BIC(modelG), "\n")
cat("Proportion of variability explained:", summary_G$r.squared, "\n")
```

## Model (H)

Use forward selection to develop a model that predicts log(`totalprice`) using the variables in `VIT2005`. Use a “p-value to add” of 5%. Store the final model in the object `modelH`.

```{r}
# Start with intercept only
null_model_log <- lm(log_totalprice ~ 1, data = VIT2005_log)
full_model_log_H <- lm(log_totalprice ~ ., data = VIT2005_log)

modelH <- step(null_model_log, 
               scope = formula(full_model_log_H), 
               direction = "forward", 
               trace = 1)

# Update formula to use log(totalprice)
modelH_formula <- as.formula(gsub("log_totalprice", "log(totalprice)", 
                                   deparse(formula(modelH))))
modelH <- lm(modelH_formula, data = VIT2005)
cat("\nModel H Formula:", deparse(formula(modelH)), "\n")
summary(modelH)
```

#### (i) Compute $CV_n$ for `modelH`. Set the seed to 5 and compute $CV_5$ for `modelH`.

```{r}
# (i) Cross-validation
cat("\n--- Model H Cross-Validation ---\n")
modelH_glm <- glm(formula(modelH), data = VIT2005)

cv_n_H <- cv.glm(data = VIT2005, glmfit = modelH_glm)
cat("CV_n (LOOCV):", cv_n_H$delta[1], "\n")

set.seed(5)
cv_5_H <- cv.glm(data = VIT2005, glmfit = modelH_glm, K = 5)
cat("CV_5:", cv_5_H$delta[1], "\n")
```

#### (ii) Compute $R^2, R_a^2$, the AIC, and the BIC for Model (H). What is the proportion of total variability explained by Model (H)?

```{r}
# (ii) Model metrics
summary_H <- summary(modelH)
cat("\n--- Model H Metrics ---\n")
cat("R-squared:", summary_H$r.squared, "\n")
cat("Adjusted R-squared:", summary_H$adj.r.squared, "\n")
cat("AIC:", AIC(modelH), "\n")
cat("BIC:", BIC(modelH), "\n")
cat("Proportion of variability explained:", summary_H$r.squared, "\n")
```

### (f) Which model has the smallest $CV_5$ as well as the smallest $CV_n$ error among Models (E), (F), (G), and (H)?

```{r}
cv_comparison <- data.frame(
  Model = c("E", "F", "G", "H"),
  CV_n = c(cv_n_E$delta[1], cv_n_F$delta[1], cv_n_G$delta[1], cv_n_H$delta[1]),
  CV_5 = c(cv_5_E$delta[1], cv_5_F$delta[1], cv_5_G$delta[1], cv_5_H$delta[1])
)
print(cv_comparison)

# Find model with smallest total
best_model_name <- cv_comparison$Model[which.min(cv_comparison$CV_n + cv_comparison$CV_5)]
cat("\nBest model (considering both CV_n and CV_5):", best_model_name, "\n")
```

### (g) Use the model selected from part (f) and explore its residuals using the function `residualPlots()` from `car`. Comment on the results.

```{r}
best_model <- get(paste0("model", best_model_name))

par(mfrow = c(2, 2))
plot(best_model)
par(mfrow = c(1, 1))
```

## Model (I)

Refer to the model selected in part (e) as `modelI`.

```{r}
cat("Using Model", best_model_name, "as Model I\n")

modelI <- best_model
```

#### (i) Plot the Cook distances, the studentized residuals, and the diagonal elements of the hat matrix of Model (I) versus the index. Based on the graphs, are there any outliers?

```{r}
# (i) Diagnostic plots
par(mfrow = c(2, 2))

# Cook's distances
cook_d <- cooks.distance(modelI)
plot(cook_d, type = "h", 
     main = "Cook's Distances", ylab = "Cook's D")
abline(h = 4/nrow(VIT2005), col = "red", lty = 2)

# Studentized residuals
stud_resid <- rstudent(modelI)
plot(stud_resid, type = "p", 
     main = "Studentized Residuals", ylab = "Studentized Residuals")
abline(h = c(-2, 2), col = "red", lty = 2)

# Hat values
hats <- hatvalues(modelI)
plot(hats, type = "h", 
     main = "Hat Values", ylab = "Leverage")
abline(h = 2 * length(coef(modelI))/nrow(VIT2005), col = "red", lty = 2)

par(mfrow = c(1, 1))
```

#### (ii) Create a bubble-plot of the studentized residuals versus the hat values with the function `influencePlot()`. Are any of the points influential?

```{r}
# (ii) Influence plot
cat("\n--- Influence Plot ---\n")
influencePlot(modelI, main = "Influence Plot")
```

#### (iii) The original researchers evaluated the apartments in rows 3 and 93 and decided they were not representative and decided to remove them from the study. Remove observations 3 and 93 from consideration in `modelI`.

```{r}
cat("\n--- Removing observations 3 and 93 ---\n")
VIT2005_clean <- VIT2005[-c(3, 93), ]
modelI <- lm(formula(modelI), data = VIT2005_clean)
cat("\nModel I Summary (after removing obs 3 and 93):\n")
summary(modelI)
```

#### (iv) Check normality and homoscedasticity for `modelI` using graphs and hypothesis tests.

```{r}
# Normality: Shapiro-Wilk test
shapiro_test <- shapiro.test(residuals(modelI))
cat("Shapiro-Wilk test:\n")
cat("  W =", shapiro_test$statistic, ", p-value =", shapiro_test$p.value, "\n")
if(shapiro_test$p.value > 0.05) {
  cat("  Conclusion: Residuals appear normally distributed.\n")
} else {
  cat("  Conclusion: Evidence against normality.\n")
}

# Q-Q plot
par(mfrow = c(1, 2))
qqPlot(modelI, main = "Q-Q Plot", id = FALSE)

# Homoscedasticity: Breusch-Pagan test
ncv_test <- ncvTest(modelI)
cat("\nBreusch-Pagan test:\n")
cat("  Chi-square =", ncv_test$ChiSquare, ", p-value =", ncv_test$p, "\n")
if(ncv_test$p > 0.05) {
  cat("  Conclusion: No evidence of heteroscedasticity.\n")
} else {
  cat("  Conclusion: Evidence of heteroscedasticity.\n")
}

# Residuals vs Fitted plot
plot(fitted(modelI), residuals(modelI), 
     main = "Residuals vs Fitted",
     xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, col = "red", lty = 2)

par(mfrow = c(1, 1))
```

#### (v) Find the variance inflation factors for Model (I). Is multicollinearity a problem?

```{r}
vif_values <- vif(modelI)
print(vif_values)
if(any(vif_values > 10)) {
  cat("\nMulticollinearity is a problem (VIF > 10 detected).\n")
} else if(any(vif_values > 5)) {
  cat("\nModerate multicollinearity detected (VIF > 5).\n")
} else {
  cat("\nMulticollinearity is not a problem (all VIF < 5).\n")
}
```

#### (vi) Find the parameter estimates, and compute 95% confidence intervals for the parameters of Model (I).

```{r}
print(summary(modelI)$coefficients)
cat("\n95% Confidence Intervals:\n")
print(confint(modelI, level = 0.95))
```

#### (vii) Find the relative contribution of the explanatory variables to explaining the variability of the prices in Model (I).

```{r}
# Use anova to get sequential SS
anova_result <- anova(modelI)
ss_total <- sum(anova_result$`Sum Sq`)
relative_contrib <- anova_result$`Sum Sq`[-nrow(anova_result)] / 
                    sum(anova_result$`Sum Sq`[-nrow(anova_result)])
names(relative_contrib) <- rownames(anova_result)[-nrow(anova_result)]

cat("\nRelative contributions:\n")
print(sort(relative_contrib, decreasing = TRUE))
```

#### (viii) What is the variable that explains the most variability in Model (I)?

```{r}
cat("\nVariable explaining most variability:", 
    names(which.max(relative_contrib)), "\n")
```

#### (ix) What variables jointly explain 80% of the total variability of `log(totalprice)`?

```{r}
cumulative_var <- cumsum(sort(relative_contrib, decreasing = TRUE))
vars_80_idx <- which(cumulative_var <= 0.80)
cat("\nVariables jointly explaining approximately 80% of variability:\n")
print(names(sort(relative_contrib, decreasing = TRUE))[vars_80_idx])
```

#### (x) Find the predictions of Model (I) with bias correction and without bias correction. The bias correction is obtained by means of the lognormal distribution: If $\hat{Y}_{pred}$ is the prediction of Model (I), the corrected (backtransformed) prediction $\tilde{Y}_{pred}$ of Model (I) is given by

$$
\tilde{Y}_{pred} = \exp(\hat{Y}_{pred}+\hat{\sigma}^2/2)
$$

where $\hat{\sigma}^2$ is the variance of the error term, and the confidence interval is given by

$$
l_{inf} = \exp (\hat{Y}_{pred}+\hat{\sigma}/2-z_{1-\alpha/2}\sqrt{\widehat{Var}(\hat{Y}_{pred})+\widehat{Var}(\hat{\sigma}^2/4)} )
$$

$$
l_{sup} = \exp (\hat{Y}_{pred}+\hat{\sigma}/2+z_{1-\alpha/2}\sqrt{\widehat{Var}(\hat{Y}_{pred})+\widehat{Var}(\hat{\sigma}^2/4)} )
$$

lsup = exp Ypred + ˆ σ2/2 + z1−α/2 Var Ypred + Var (ˆ σ2) /4

and

$$
\widehat{Var}(\hat{\sigma})=\frac{2\hat{\sigma}^4}{df_{residual}}
$$

```{r}
sigma_sq <- summary(modelI)$sigma^2
df_res <- df.residual(modelI)

cat("Residual variance (σ²):", sigma_sq, "\n")
cat("Bias correction factor: exp(σ²/2) =", exp(sigma_sq/2), "\n")
```

#### (xi) For Model (I),plot the predicted values (with and without bias correction) versus observed values. Comment on the results.

```{r}
# (xi) Plot predicted vs observed
par(mfrow = c(1, 2))
fitted_log <- fitted(modelI)
observed <- VIT2005_clean$totalprice

# Without bias correction
plot(observed, exp(fitted_log), 
     main = "Predicted vs Observed\n(No Bias Correction)",
     xlab = "Observed Total Price", ylab = "Predicted Total Price",
     pch = 19, col = "steelblue")
abline(0, 1, col = "red", lwd = 2)

# With bias correction
plot(observed, exp(fitted_log + sigma_sq/2), 
     main = "Predicted vs Observed\n(With Bias Correction)",
     xlab = "Observed Total Price", ylab = "Predicted Total Price",
     pch = 19, col = "darkgreen")
abline(0, 1, col = "red", lwd = 2)

par(mfrow = c(1, 1))
```

#### (xii) Show that in Model (I) an increment of $10 m^2$ in the area of a flat implies an increment of roughly 4% in the predicted total price. To verify this, find the predicted price of three apartments with areas of 80, 90, and $100m^2$, respectively, and keep the rest of the explanatory variables fixed. For example, assign the following values to the explanatory variables: `zone = Z32`, `elevator = 1`, `toilets = 1`, `garage = 1`, `category = 3B`, `out= E50`, `storage = 1`, `heating = 3A`, and `streetcategory = S3`. Compute the corresponding 90% prediction intervals.

```{r}
# Create prediction data for apartments with 80, 90, 100 m²
# Note: Adjust factor levels based on actual data
pred_data <- data.frame(
  area = c(80, 90, 100),
  zone = factor(rep("Z32", 3)),
  elevator = rep(1, 3),
  toilets = rep(1, 3),
  garage = rep(1, 3),
  category = factor(rep("3B", 3)),
  out = factor(rep("E50", 3)),
  storage = rep(1, 3),
  heating = factor(rep("3A", 3)),
  streetcategory = factor(rep("S3", 3))
)

# Make predictions
preds <- predict(modelI, newdata = pred_data, 
                 interval = "prediction", level = 0.90)

# Back-transform with bias correction
predicted_prices <- exp(preds[, "fit"] + sigma_sq/2)
lower_90 <- exp(preds[, "lwr"] + sigma_sq/2)
upper_90 <- exp(preds[, "upr"] + sigma_sq/2)

cat("\nPredicted prices for 80, 90, 100 m²:\n")
for(i in 1:3) {
  cat(sprintf("Area %d m²: €%.2f [90%% PI: €%.2f, €%.2f]\n",
              pred_data$area[i], predicted_prices[i], 
              lower_90[i], upper_90[i]))
}

# Calculate percentage changes
pct_change_80_90 <- (predicted_prices[2] - predicted_prices[1]) / 
                     predicted_prices[1] * 100
pct_change_90_100 <- (predicted_prices[3] - predicted_prices[2]) / 
                      predicted_prices[2] * 100

cat(sprintf("\nPercentage change (80 to 90 m²): %.2f%%\n", pct_change_80_90))
cat(sprintf("Percentage change (90 to 100 m²): %.2f%%\n", pct_change_90_100))
cat(sprintf("Average percentage change per 10 m²: ~%.2f%%\n", 
            mean(c(pct_change_80_90, pct_change_90_100))))
```

#### (xiii) What is the percentage change in the total price of an apartment when the number of garages changes from one to two?

```{r}
if("garage" %in% names(coef(modelI))) {
  garage_coef <- coef(modelI)["garage"]
  pct_change_garage <- (exp(garage_coef) - 1) * 100
  cat(sprintf("Percentage change when garage increases by 1: %.2f%%\n", 
              pct_change_garage))
} else {
  cat("Garage variable not in final model.\n")
}
```

#### (xiv) What is the percentage change in the total price of an apartment when the heating type changes from “1A” to “3B”?

```{r}
heating_coefs <- coef(modelI)[grep("heating", names(coef(modelI)))]
if(length(heating_coefs) > 0) {
  cat("Heating coefficients in model:\n")
  print(heating_coefs)
  cat("\nNote: Percentage change depends on reference category.\n")
  cat("Calculate as: exp(coef_3B - coef_1A) - 1 if both present,\n")
  cat("or exp(coef) - 1 for change from reference to specified level.\n")
} else {
  cat("Heating variable not in final model.\n")
}
```
